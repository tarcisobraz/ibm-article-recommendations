{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommendations with IBM\n",
    "\n",
    "In this notebook, you will be putting your recommendation skills to use on real data from the IBM Watson Studio platform. \n",
    "\n",
    "\n",
    "You may either submit your notebook through the workspace here, or you may work from your local machine and submit through the next page.  Either way assure that your code passes the project [RUBRIC](https://review.udacity.com/#!/rubrics/2322/view).  **Please save regularly.**\n",
    "\n",
    "By following the table of contents, you will build out a number of different methods for making recommendations that can be used for different situations. \n",
    "\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "I. [Exploratory Data Analysis](#Exploratory-Data-Analysis)<br>\n",
    "II. [Rank Based Recommendations](#Rank)<br>\n",
    "III. [User-User Based Collaborative Filtering](#User-User)<br>\n",
    "IV. [Content Based Recommendations (EXTRA - NOT REQUIRED)](#Content-Recs)<br>\n",
    "V. [Matrix Factorization](#Matrix-Fact)<br>\n",
    "VI. [Extras & Concluding](#conclusions)\n",
    "\n",
    "At the end of the notebook, you will find directions for how to submit your work.  Let's get started by importing the necessary libraries and reading in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>title</th>\n",
       "      <th>email</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1430.0</td>\n",
       "      <td>using pixiedust for fast, flexible, and easier...</td>\n",
       "      <td>ef5f11f77ba020cd36e1105a00ab868bbdbf7fe7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1314.0</td>\n",
       "      <td>healthcare python streaming application demo</td>\n",
       "      <td>083cbdfa93c8444beaa4c5f5e0f5f9198e4f9e0b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1429.0</td>\n",
       "      <td>use deep learning for image classification</td>\n",
       "      <td>b96a4f2e92d8572034b1e9b28f9ac673765cd074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1338.0</td>\n",
       "      <td>ml optimization using cognitive assistant</td>\n",
       "      <td>06485706b34a5c9bf2a0ecdac41daf7e7654ceb7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1276.0</td>\n",
       "      <td>deploy your python model as a restful api</td>\n",
       "      <td>f01220c46fc92c6e6b161b1849de11faacd7ccb2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   article_id                                              title  \\\n",
       "0      1430.0  using pixiedust for fast, flexible, and easier...   \n",
       "1      1314.0       healthcare python streaming application demo   \n",
       "2      1429.0         use deep learning for image classification   \n",
       "3      1338.0          ml optimization using cognitive assistant   \n",
       "4      1276.0          deploy your python model as a restful api   \n",
       "\n",
       "                                      email  \n",
       "0  ef5f11f77ba020cd36e1105a00ab868bbdbf7fe7  \n",
       "1  083cbdfa93c8444beaa4c5f5e0f5f9198e4f9e0b  \n",
       "2  b96a4f2e92d8572034b1e9b28f9ac673765cd074  \n",
       "3  06485706b34a5c9bf2a0ecdac41daf7e7654ceb7  \n",
       "4  f01220c46fc92c6e6b161b1849de11faacd7ccb2  "
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import test.project_tests as t\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "\n",
    "#Custom NLP Transformers and Estimators\n",
    "import nlp_estimators\n",
    "from nltk import WordNetLemmatizer\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "df = pd.read_csv('data/user-item-interactions.csv')\n",
    "df_content = pd.read_csv('data/articles_community.csv')\n",
    "del df['Unnamed: 0']\n",
    "del df_content['Unnamed: 0']\n",
    "\n",
    "# Show df to get an idea of the data\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_body</th>\n",
       "      <th>doc_description</th>\n",
       "      <th>doc_full_name</th>\n",
       "      <th>doc_status</th>\n",
       "      <th>article_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Skip navigation Sign in SearchLoading...\\r\\n\\r...</td>\n",
       "      <td>Detect bad readings in real time using Python ...</td>\n",
       "      <td>Detect Malfunctioning IoT Sensors with Streami...</td>\n",
       "      <td>Live</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>No Free Hunch Navigation * kaggle.com\\r\\n\\r\\n ...</td>\n",
       "      <td>See the forest, see the trees. Here lies the c...</td>\n",
       "      <td>Communicating data science: A guide to present...</td>\n",
       "      <td>Live</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>☰ * Login\\r\\n * Sign Up\\r\\n\\r\\n * Learning Pat...</td>\n",
       "      <td>Here’s this week’s news in Data Science and Bi...</td>\n",
       "      <td>This Week in Data Science (April 18, 2017)</td>\n",
       "      <td>Live</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DATALAYER: HIGH THROUGHPUT, LOW LATENCY AT SCA...</td>\n",
       "      <td>Learn how distributed DBs solve the problem of...</td>\n",
       "      <td>DataLayer Conference: Boost the performance of...</td>\n",
       "      <td>Live</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Skip navigation Sign in SearchLoading...\\r\\n\\r...</td>\n",
       "      <td>This video demonstrates the power of IBM DataS...</td>\n",
       "      <td>Analyze NY Restaurant data using Spark in DSX</td>\n",
       "      <td>Live</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            doc_body  \\\n",
       "0  Skip navigation Sign in SearchLoading...\\r\\n\\r...   \n",
       "1  No Free Hunch Navigation * kaggle.com\\r\\n\\r\\n ...   \n",
       "2  ☰ * Login\\r\\n * Sign Up\\r\\n\\r\\n * Learning Pat...   \n",
       "3  DATALAYER: HIGH THROUGHPUT, LOW LATENCY AT SCA...   \n",
       "4  Skip navigation Sign in SearchLoading...\\r\\n\\r...   \n",
       "\n",
       "                                     doc_description  \\\n",
       "0  Detect bad readings in real time using Python ...   \n",
       "1  See the forest, see the trees. Here lies the c...   \n",
       "2  Here’s this week’s news in Data Science and Bi...   \n",
       "3  Learn how distributed DBs solve the problem of...   \n",
       "4  This video demonstrates the power of IBM DataS...   \n",
       "\n",
       "                                       doc_full_name doc_status  article_id  \n",
       "0  Detect Malfunctioning IoT Sensors with Streami...       Live           0  \n",
       "1  Communicating data science: A guide to present...       Live           1  \n",
       "2         This Week in Data Science (April 18, 2017)       Live           2  \n",
       "3  DataLayer Conference: Boost the performance of...       Live           3  \n",
       "4      Analyze NY Restaurant data using Spark in DSX       Live           4  "
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show df_content to get an idea of the data\n",
    "df_content.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a class=\"anchor\" id=\"Exploratory-Data-Analysis\">Part I : Exploratory Data Analysis</a>\n",
    "\n",
    "Use the dictionary and cells below to provide some insight into the descriptive statistics of the data.\n",
    "\n",
    "`1.` What is the distribution of how many articles a user interacts with in the dataset?  Provide a visual and descriptive statistics to assist with giving a look at the number of times each user interacts with an article.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles_per_user = df.groupby('email').article_id.count().reset_index(name='num_articles')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>email</th>\n",
       "      <th>num_articles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000b6387a0366322d7fbfc6434af145adf7fed1</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>001055fc0bb67f71e8fa17002342b256a30254cd</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00148e4911c7e04eeff8def7bbbdaf1c59c2c621</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>001a852ecbd6cc12ab77a785efa137b2646505fe</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>001fc95b90da5c3cb12c501d201a915e4f093290</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      email  num_articles\n",
       "0  0000b6387a0366322d7fbfc6434af145adf7fed1            13\n",
       "1  001055fc0bb67f71e8fa17002342b256a30254cd             4\n",
       "2  00148e4911c7e04eeff8def7bbbdaf1c59c2c621             3\n",
       "3  001a852ecbd6cc12ab77a785efa137b2646505fe             6\n",
       "4  001fc95b90da5c3cb12c501d201a915e4f093290             2"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles_per_user.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_articles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5148.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>8.930847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>16.802267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>9.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>364.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       num_articles\n",
       "count   5148.000000\n",
       "mean       8.930847\n",
       "std       16.802267\n",
       "min        1.000000\n",
       "25%        1.000000\n",
       "50%        3.000000\n",
       "75%        9.000000\n",
       "max      364.000000"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles_per_user.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fb1bb211748>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "g = sns.distplot(articles_per_user.num_articles)\n",
    "g.set_xscale(\"log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill in the median and maximum number of user_article interactios below\n",
    "\n",
    "median_val = articles_per_user.describe().num_articles.loc['50%']# 50% of individuals interact with ____ number of articles or fewer.\n",
    "max_views_by_user = articles_per_user.describe().num_articles.loc['max']# The maximum number of user-article interactions by any 1 user is ______."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`2.` Explore and remove duplicate articles from the **df_content** dataframe.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find and explore duplicate articles\n",
    "duplicate_articles = df_content[df_content.duplicated(['article_id'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_body</th>\n",
       "      <th>doc_description</th>\n",
       "      <th>doc_full_name</th>\n",
       "      <th>doc_status</th>\n",
       "      <th>article_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>365</th>\n",
       "      <td>Follow Sign in / Sign up Home About Insight Da...</td>\n",
       "      <td>During the seven-week Insight Data Engineering...</td>\n",
       "      <td>Graph-based machine learning</td>\n",
       "      <td>Live</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>692</th>\n",
       "      <td>Homepage Follow Sign in / Sign up Homepage * H...</td>\n",
       "      <td>One of the earliest documented catalogs was co...</td>\n",
       "      <td>How smart catalogs can turn the big data flood...</td>\n",
       "      <td>Live</td>\n",
       "      <td>221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>761</th>\n",
       "      <td>Homepage Follow Sign in Get started Homepage *...</td>\n",
       "      <td>Today’s world of data science leverages data f...</td>\n",
       "      <td>Using Apache Spark as a parallel processing fr...</td>\n",
       "      <td>Live</td>\n",
       "      <td>398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>970</th>\n",
       "      <td>This video shows you how to construct queries ...</td>\n",
       "      <td>This video shows you how to construct queries ...</td>\n",
       "      <td>Use the Primary Index</td>\n",
       "      <td>Live</td>\n",
       "      <td>577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>971</th>\n",
       "      <td>Homepage Follow Sign in Get started * Home\\r\\n...</td>\n",
       "      <td>If you are like most data scientists, you are ...</td>\n",
       "      <td>Self-service data preparation with IBM Data Re...</td>\n",
       "      <td>Live</td>\n",
       "      <td>232</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              doc_body  \\\n",
       "365  Follow Sign in / Sign up Home About Insight Da...   \n",
       "692  Homepage Follow Sign in / Sign up Homepage * H...   \n",
       "761  Homepage Follow Sign in Get started Homepage *...   \n",
       "970  This video shows you how to construct queries ...   \n",
       "971  Homepage Follow Sign in Get started * Home\\r\\n...   \n",
       "\n",
       "                                       doc_description  \\\n",
       "365  During the seven-week Insight Data Engineering...   \n",
       "692  One of the earliest documented catalogs was co...   \n",
       "761  Today’s world of data science leverages data f...   \n",
       "970  This video shows you how to construct queries ...   \n",
       "971  If you are like most data scientists, you are ...   \n",
       "\n",
       "                                         doc_full_name doc_status  article_id  \n",
       "365                       Graph-based machine learning       Live          50  \n",
       "692  How smart catalogs can turn the big data flood...       Live         221  \n",
       "761  Using Apache Spark as a parallel processing fr...       Live         398  \n",
       "970                              Use the Primary Index       Live         577  \n",
       "971  Self-service data preparation with IBM Data Re...       Live         232  "
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(duplicate_articles.shape[0])\n",
    "duplicate_articles.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "# Remove any rows that have the same article_id - only keep the first\n",
    "clean_articles = df_content.drop_duplicates(['article_id'])\n",
    "clean_articles['doc_description'] = clean_articles['doc_description'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_body</th>\n",
       "      <th>doc_description</th>\n",
       "      <th>doc_full_name</th>\n",
       "      <th>doc_status</th>\n",
       "      <th>article_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Skip navigation Sign in SearchLoading...\\r\\n\\r...</td>\n",
       "      <td>Detect bad readings in real time using Python ...</td>\n",
       "      <td>Detect Malfunctioning IoT Sensors with Streami...</td>\n",
       "      <td>Live</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>No Free Hunch Navigation * kaggle.com\\r\\n\\r\\n ...</td>\n",
       "      <td>See the forest, see the trees. Here lies the c...</td>\n",
       "      <td>Communicating data science: A guide to present...</td>\n",
       "      <td>Live</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>☰ * Login\\r\\n * Sign Up\\r\\n\\r\\n * Learning Pat...</td>\n",
       "      <td>Here’s this week’s news in Data Science and Bi...</td>\n",
       "      <td>This Week in Data Science (April 18, 2017)</td>\n",
       "      <td>Live</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DATALAYER: HIGH THROUGHPUT, LOW LATENCY AT SCA...</td>\n",
       "      <td>Learn how distributed DBs solve the problem of...</td>\n",
       "      <td>DataLayer Conference: Boost the performance of...</td>\n",
       "      <td>Live</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Skip navigation Sign in SearchLoading...\\r\\n\\r...</td>\n",
       "      <td>This video demonstrates the power of IBM DataS...</td>\n",
       "      <td>Analyze NY Restaurant data using Spark in DSX</td>\n",
       "      <td>Live</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            doc_body  \\\n",
       "0  Skip navigation Sign in SearchLoading...\\r\\n\\r...   \n",
       "1  No Free Hunch Navigation * kaggle.com\\r\\n\\r\\n ...   \n",
       "2  ☰ * Login\\r\\n * Sign Up\\r\\n\\r\\n * Learning Pat...   \n",
       "3  DATALAYER: HIGH THROUGHPUT, LOW LATENCY AT SCA...   \n",
       "4  Skip navigation Sign in SearchLoading...\\r\\n\\r...   \n",
       "\n",
       "                                     doc_description  \\\n",
       "0  Detect bad readings in real time using Python ...   \n",
       "1  See the forest, see the trees. Here lies the c...   \n",
       "2  Here’s this week’s news in Data Science and Bi...   \n",
       "3  Learn how distributed DBs solve the problem of...   \n",
       "4  This video demonstrates the power of IBM DataS...   \n",
       "\n",
       "                                       doc_full_name doc_status  article_id  \n",
       "0  Detect Malfunctioning IoT Sensors with Streami...       Live           0  \n",
       "1  Communicating data science: A guide to present...       Live           1  \n",
       "2         This Week in Data Science (April 18, 2017)       Live           2  \n",
       "3  DataLayer Conference: Boost the performance of...       Live           3  \n",
       "4      Analyze NY Restaurant data using Spark in DSX       Live           4  "
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_articles.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`3.` Use the cells below to find:\n",
    "\n",
    "**a.** The number of unique articles that have an interaction with a user.  \n",
    "**b.** The number of unique articles in the dataset (whether they have any interactions or not).<br>\n",
    "**c.** The number of unique users in the dataset. (excluding null values) <br>\n",
    "**d.** The number of user-article interactions in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>num_interactions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.0</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8.0</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9.0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   article_id  num_interactions\n",
       "0         0.0                14\n",
       "1         2.0                58\n",
       "2         4.0                13\n",
       "3         8.0                85\n",
       "4         9.0                10"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interactions_per_article = df.groupby('article_id').email.count().reset_index(name='num_interactions')\n",
    "interactions_per_article = interactions_per_article[interactions_per_article['num_interactions'] > 0]\n",
    "interactions_per_article.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_articles = interactions_per_article.shape[0]# The number of unique articles that have at least one interaction\n",
    "total_articles = clean_articles.shape[0] # The number of unique articles on the IBM platform\n",
    "unique_users = df.email.dropna().unique().shape[0]# The number of unique users\n",
    "user_article_interactions = df.shape[0]# The number of user-article interactions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`4.` Use the cells below to find the most viewed **article_id**, as well as how often it was viewed.  After talking to the company leaders, the `email_mapper` function was deemed a reasonable way to map users to ids.  There were a small number of null values, and it was found that all of these null values likely belonged to a single user (which is how they are stored using the function below)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_viewed_article = interactions_per_article[interactions_per_article['num_interactions'] == interactions_per_article.num_interactions.max()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>num_interactions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>699</th>\n",
       "      <td>1429.0</td>\n",
       "      <td>937</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     article_id  num_interactions\n",
       "699      1429.0               937"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_viewed_article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_viewed_article_id = str(most_viewed_article.article_id.values[0])# The most viewed article in the dataset as a string with one value following the decimal \n",
    "max_views = most_viewed_article.num_interactions.values[0] # The most viewed article in the dataset was viewed how many times?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>title</th>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1430.0</td>\n",
       "      <td>using pixiedust for fast, flexible, and easier...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1314.0</td>\n",
       "      <td>healthcare python streaming application demo</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1429.0</td>\n",
       "      <td>use deep learning for image classification</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1338.0</td>\n",
       "      <td>ml optimization using cognitive assistant</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1276.0</td>\n",
       "      <td>deploy your python model as a restful api</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   article_id                                              title  user_id\n",
       "0      1430.0  using pixiedust for fast, flexible, and easier...        1\n",
       "1      1314.0       healthcare python streaming application demo        2\n",
       "2      1429.0         use deep learning for image classification        3\n",
       "3      1338.0          ml optimization using cognitive assistant        4\n",
       "4      1276.0          deploy your python model as a restful api        5"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## No need to change the code here - this will be helpful for later parts of the notebook\n",
    "# Run this cell to map the user email to a user_id column and remove the email column\n",
    "\n",
    "def email_mapper():\n",
    "    coded_dict = dict()\n",
    "    cter = 1\n",
    "    email_encoded = []\n",
    "    \n",
    "    for val in df['email']:\n",
    "        if val not in coded_dict:\n",
    "            coded_dict[val] = cter\n",
    "            cter+=1\n",
    "        \n",
    "        email_encoded.append(coded_dict[val])\n",
    "    return email_encoded\n",
    "\n",
    "email_encoded = email_mapper()\n",
    "del df['email']\n",
    "df['user_id'] = email_encoded\n",
    "\n",
    "# show header\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It looks like you have everything right here! Nice job!\n"
     ]
    }
   ],
   "source": [
    "## If you stored all your results in the variable names above, \n",
    "## you shouldn't need to change anything in this cell\n",
    "\n",
    "sol_1_dict = {\n",
    "    '`50% of individuals have _____ or fewer interactions.`': median_val,\n",
    "    '`The total number of user-article interactions in the dataset is ______.`': user_article_interactions,\n",
    "    '`The maximum number of user-article interactions by any 1 user is ______.`': max_views_by_user,\n",
    "    '`The most viewed article in the dataset was viewed _____ times.`': max_views,\n",
    "    '`The article_id of the most viewed article is ______.`': most_viewed_article_id,\n",
    "    '`The number of unique articles that have at least 1 rating ______.`': unique_articles,\n",
    "    '`The number of unique users in the dataset is ______`': unique_users,\n",
    "    '`The number of unique articles on the IBM platform`': total_articles\n",
    "}\n",
    "\n",
    "# Test your dictionary against the solution\n",
    "t.sol_1_test(sol_1_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "714"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_articles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a class=\"anchor\" id=\"Rank\">Part II: Rank-Based Recommendations</a>\n",
    "\n",
    "Unlike in the earlier lessons, we don't actually have ratings for whether a user liked an article or not.  We only know that a user has interacted with an article.  In these cases, the popularity of an article can really only be based on how often an article was interacted with.\n",
    "\n",
    "`1.` Fill in the function below to return the **n** top articles ordered with most interactions as the top. Test your function using the tests below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1429.,  1330.,  1431.,  1427.,  1364.])"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interactions_per_article.sort_values('num_interactions', ascending=False).article_id.values[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['use deep learning for image classification',\n",
       " 'insights from new york car accident reports',\n",
       " 'visualize car data with brunel',\n",
       " 'use xgboost, scikit-learn & ibm watson machine learning apis',\n",
       " 'predicting churn with the spss random tree algorithm']"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(['article_id','title']).user_id.count().reset_index(name='num_interactions').sort_values('num_interactions', \n",
    "                                                        ascending=False) \\\n",
    "                                            .title.values[:5].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_articles(n, df=df):\n",
    "    '''\n",
    "    INPUT:\n",
    "    n - (int) the number of top articles to return\n",
    "    df - (pandas dataframe) df as defined at the top of the notebook \n",
    "    \n",
    "    OUTPUT:\n",
    "    top_articles - (list) A list of the top 'n' article titles \n",
    "    \n",
    "    '''\n",
    "    interactions_per_article = df.groupby(['article_id','title']).user_id.count().reset_index(name='num_interactions')\n",
    "    top_articles = interactions_per_article.sort_values('num_interactions', \n",
    "                                                        ascending=False) \\\n",
    "                                            .title.values[:n].tolist()\n",
    "    \n",
    "    \n",
    "    \n",
    "    return top_articles # Return the top article titles from df (not df_content)\n",
    "\n",
    "def get_top_article_ids(n, df=df):\n",
    "    '''\n",
    "    INPUT:\n",
    "    n - (int) the number of top articles to return\n",
    "    df - (pandas dataframe) df as defined at the top of the notebook \n",
    "    \n",
    "    OUTPUT:\n",
    "    top_articles - (list) A list of the top 'n' article titles \n",
    "    \n",
    "    '''\n",
    "    interactions_per_article = df.assign(article_id = lambda x: x.article_id.astype(str)) \\\n",
    "                                .groupby(['article_id','title']).user_id.count() \\\n",
    "                                .reset_index(name='num_interactions')\n",
    "    top_articles = interactions_per_article.sort_values('num_interactions', \n",
    "                                                        ascending=False) \\\n",
    "                                            .article_id.values[:n].tolist()\n",
    " \n",
    "    return top_articles # Return the top article ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['use deep learning for image classification', 'insights from new york car accident reports', 'visualize car data with brunel', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'predicting churn with the spss random tree algorithm', 'healthcare python streaming application demo', 'finding optimal locations of new store using decision optimization', 'apache spark lab, part 1: basic concepts', 'analyze energy consumption in buildings', 'gosales transactions for logistic regression model']\n",
      "['1429.0', '1330.0', '1431.0', '1427.0', '1364.0', '1314.0', '1293.0', '1170.0', '1162.0', '1304.0']\n"
     ]
    }
   ],
   "source": [
    "print(get_top_articles(10))\n",
    "print(get_top_article_ids(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your top_5 looks like the solution list! Nice job.\n",
      "Your top_10 looks like the solution list! Nice job.\n",
      "Your top_20 looks like the solution list! Nice job.\n"
     ]
    }
   ],
   "source": [
    "# Test your function by returning the top 5, 10, and 20 articles\n",
    "top_5 = get_top_articles(5)\n",
    "top_10 = get_top_articles(10)\n",
    "top_20 = get_top_articles(20)\n",
    "\n",
    "# Test each of your three lists from above\n",
    "t.sol_2_test(get_top_articles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a class=\"anchor\" id=\"User-User\">Part III: User-User Based Collaborative Filtering</a>\n",
    "\n",
    "\n",
    "`1.` Use the function below to reformat the **df** dataframe to be shaped with users as the rows and articles as the columns.  \n",
    "\n",
    "* Each **user** should only appear in each **row** once.\n",
    "\n",
    "\n",
    "* Each **article** should only show up in one **column**.  \n",
    "\n",
    "\n",
    "* **If a user has interacted with an article, then place a 1 where the user-row meets for that article-column**.  It does not matter how many times a user has interacted with the article, all entries where a user has interacted with an article should be a 1.  \n",
    "\n",
    "\n",
    "* **If a user has not interacted with an item, then place a zero where the user-row meets for that article-column**. \n",
    "\n",
    "Use the tests to make sure the basic structure of your matrix matches what is expected by the solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>title</th>\n",
       "      <th>user_id</th>\n",
       "      <th>interaction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1430.0</td>\n",
       "      <td>using pixiedust for fast, flexible, and easier...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1314.0</td>\n",
       "      <td>healthcare python streaming application demo</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1429.0</td>\n",
       "      <td>use deep learning for image classification</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1338.0</td>\n",
       "      <td>ml optimization using cognitive assistant</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1276.0</td>\n",
       "      <td>deploy your python model as a restful api</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1432.0</td>\n",
       "      <td>visualize data with the matplotlib library</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1429.0</td>\n",
       "      <td>use deep learning for image classification</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>593.0</td>\n",
       "      <td>upload files to ibm data science experience us...</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1314.0</td>\n",
       "      <td>healthcare python streaming application demo</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1185.0</td>\n",
       "      <td>classify tumors with machine learning</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   article_id                                              title  user_id  \\\n",
       "0      1430.0  using pixiedust for fast, flexible, and easier...        1   \n",
       "1      1314.0       healthcare python streaming application demo        2   \n",
       "2      1429.0         use deep learning for image classification        3   \n",
       "3      1338.0          ml optimization using cognitive assistant        4   \n",
       "4      1276.0          deploy your python model as a restful api        5   \n",
       "5      1432.0         visualize data with the matplotlib library        6   \n",
       "6      1429.0         use deep learning for image classification        7   \n",
       "7       593.0  upload files to ibm data science experience us...        8   \n",
       "8      1314.0       healthcare python streaming application demo        9   \n",
       "9      1185.0              classify tumors with machine learning       10   \n",
       "\n",
       "   interaction  \n",
       "0            1  \n",
       "1            1  \n",
       "2            1  \n",
       "3            1  \n",
       "4            1  \n",
       "5            1  \n",
       "6            1  \n",
       "7            1  \n",
       "8            1  \n",
       "9            1  "
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = df.head(10)\n",
    "test_df['interaction'] = 1\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_mat = test_df.groupby(['user_id', 'article_id'])['interaction'].min().unstack().fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 8)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_mat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>article_id</th>\n",
       "      <th>593.0</th>\n",
       "      <th>1185.0</th>\n",
       "      <th>1276.0</th>\n",
       "      <th>1314.0</th>\n",
       "      <th>1338.0</th>\n",
       "      <th>1429.0</th>\n",
       "      <th>1430.0</th>\n",
       "      <th>1432.0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "article_id  593.0   1185.0  1276.0  1314.0  1338.0  1429.0  1430.0  1432.0\n",
       "user_id                                                                   \n",
       "1              0.0     0.0     0.0     0.0     0.0     0.0     1.0     0.0\n",
       "2              0.0     0.0     0.0     1.0     0.0     0.0     0.0     0.0\n",
       "3              0.0     0.0     0.0     0.0     0.0     1.0     0.0     0.0\n",
       "4              0.0     0.0     0.0     0.0     1.0     0.0     0.0     0.0\n",
       "5              0.0     0.0     1.0     0.0     0.0     0.0     0.0     0.0\n",
       "6              0.0     0.0     0.0     0.0     0.0     0.0     0.0     1.0\n",
       "7              0.0     0.0     0.0     0.0     0.0     1.0     0.0     0.0\n",
       "8              1.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0\n",
       "9              0.0     0.0     0.0     1.0     0.0     0.0     0.0     0.0\n",
       "10             0.0     1.0     0.0     0.0     0.0     0.0     0.0     0.0"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user_id\n",
       "1     1.0\n",
       "2     1.0\n",
       "3     1.0\n",
       "4     1.0\n",
       "5     1.0\n",
       "6     1.0\n",
       "7     1.0\n",
       "8     1.0\n",
       "9     1.0\n",
       "10    1.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_mat.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "article_id\n",
       "593.0     0.0\n",
       "1185.0    0.0\n",
       "1276.0    0.0\n",
       "1314.0    0.0\n",
       "1338.0    0.0\n",
       "1429.0    1.0\n",
       "1430.0    0.0\n",
       "1432.0    0.0\n",
       "Name: 3, dtype: float64"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_mat.iloc[2,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>user_id</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>article_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>593.0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1185.0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1276.0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1314.0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1338.0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1429.0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1430.0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1432.0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "user_id      1    2    3    4    5    6    7    8    9    10\n",
       "article_id                                                  \n",
       "593.0       0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0\n",
       "1185.0      0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0\n",
       "1276.0      0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0\n",
       "1314.0      0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0\n",
       "1338.0      0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       "1429.0      0.0  0.0  1.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0\n",
       "1430.0      1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       "1432.0      0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_mat.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.])"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sim = np.dot(test_mat.iloc[1,:],test_mat.T)\n",
    "test_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([8, 1, 9, 7, 6, 5, 4, 3, 2, 0])"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sim.argsort()[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the user-article matrix with 1's and 0's\n",
    "\n",
    "def create_user_item_matrix(df):\n",
    "    '''\n",
    "    INPUT:\n",
    "    df - pandas dataframe with article_id, title, user_id columns\n",
    "    \n",
    "    OUTPUT:\n",
    "    user_item - user item matrix \n",
    "    \n",
    "    Description:\n",
    "    Return a matrix with user ids as rows and article ids on the columns with 1 values where a user interacted with \n",
    "    an article and a 0 otherwise\n",
    "    '''\n",
    "    df['interaction'] = 1\n",
    "    user_item = df.groupby(['user_id', 'article_id'])['interaction'].min().unstack().fillna(0)\n",
    "    \n",
    "    return user_item # return the user_item matrix \n",
    "\n",
    "user_item = create_user_item_matrix(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You have passed our quick tests!  Please proceed!\n"
     ]
    }
   ],
   "source": [
    "## Tests: You should just need to run this cell.  Don't change the code.\n",
    "assert user_item.shape[0] == 5149, \"Oops!  The number of users in the user-article matrix doesn't look right.\"\n",
    "assert user_item.shape[1] == 714, \"Oops!  The number of articles in the user-article matrix doesn't look right.\"\n",
    "assert user_item.sum(axis=1)[1] == 36, \"Oops!  The number of articles seen by user 1 doesn't look right.\"\n",
    "print(\"You have passed our quick tests!  Please proceed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`2.` Complete the function below which should take a user_id and provide an ordered list of the most similar users to that user (from most similar to least similar).  The returned result should not contain the provided user_id, as we know that each user is similar to him/herself. Because the results for each user here are binary, it (perhaps) makes sense to compute similarity as the dot product of two users. \n",
    "\n",
    "Use the tests to test your function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_similarity = np.dot(user_item.iloc[0,:],user_item.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36.0"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_item.sum(axis=1)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5149,)\n",
      "<class 'numpy.ndarray'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 36.,   2.,   6., ...,   0.,   0.,   0.])"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(users_similarity.shape)\n",
    "print(type(users_similarity))\n",
    "users_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5149"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users_similarity[~np.isnan(users_similarity)].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   1, 3933,   23, ..., 2916, 2911, 2575])"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_similar_users = users_similarity.argsort()[::-1] + 1\n",
    "most_similar_users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   1,   23, 3782, ..., 2916, 2911, 2575])"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.delete(most_similar_users, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_similar_users(user_id, user_item=user_item):\n",
    "    '''\n",
    "    INPUT:\n",
    "    user_id - (int) a user_id\n",
    "    user_item - (pandas dataframe) matrix of users by articles: \n",
    "                1's when a user has interacted with an article, 0 otherwise\n",
    "    \n",
    "    OUTPUT:\n",
    "    similar_users - (list) an ordered list where the closest users (largest dot product users)\n",
    "                    are listed first\n",
    "    \n",
    "    Description:\n",
    "    Computes the similarity of every pair of users based on the dot product\n",
    "    Returns an ordered\n",
    "    \n",
    "    '''\n",
    "    # compute similarity of each user to the provided user\n",
    "    users_similarity = np.dot(user_item.iloc[user_id-1,:],user_item.T)\n",
    "\n",
    "    # sort by similarity\n",
    "    # create list of just the ids\n",
    "    most_similar_users = users_similarity.argsort()[::-1] + 1\n",
    "   \n",
    "    # remove the own user's id\n",
    "    most_similar_users = most_similar_users[most_similar_users != user_id]\n",
    "       \n",
    "    return most_similar_users # return a list of the users in order from most to least similar\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 10 most similar users to user 1 are: [3933   23 3782  203 4459  131 3870   46 4201 5041]\n",
      "The 5 most similar users to user 3933 are: [   1   23 3782 4459  203]\n",
      "The 3 most similar users to user 46 are: [4201   23 3782]\n"
     ]
    }
   ],
   "source": [
    "# Do a spot check of your function\n",
    "print(\"The 10 most similar users to user 1 are: {}\".format(find_similar_users(1)[:10]))\n",
    "print(\"The 5 most similar users to user 3933 are: {}\".format(find_similar_users(3933)[:5]))\n",
    "print(\"The 3 most similar users to user 46 are: {}\".format(find_similar_users(46)[:3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`3.` Now that you have a function that provides the most similar users to each user, you will want to use these users to find articles you can recommend.  Complete the functions below to return the articles you would recommend to each user. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   43.,   109.,   151.,   268.,   310.,   329.,   346.,   390.,\n",
       "         494.,   525.,   585.,   626.,   668.,   732.,   768.,   910.,\n",
       "         968.,   981.,  1052.,  1170.,  1183.,  1185.,  1232.,  1293.,\n",
       "        1305.,  1363.,  1368.,  1391.,  1400.,  1406.,  1427.,  1429.,\n",
       "        1430.,  1431.,  1436.,  1439.])"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_articles = user_item.iloc[0,:]\n",
    "user_articles[user_articles > 0].keys().values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1056.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>523.913826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>303.480641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>260.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>523.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>786.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1050.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        article_id\n",
       "count  1056.000000\n",
       "mean    523.913826\n",
       "std     303.480641\n",
       "min       0.000000\n",
       "25%     260.750000\n",
       "50%     523.500000\n",
       "75%     786.250000\n",
       "max    1050.000000"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_content.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>interaction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>45993.000000</td>\n",
       "      <td>45993.000000</td>\n",
       "      <td>45993.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>908.846477</td>\n",
       "      <td>2300.918314</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>486.647866</td>\n",
       "      <td>1712.658385</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>460.000000</td>\n",
       "      <td>621.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1151.000000</td>\n",
       "      <td>2330.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1336.000000</td>\n",
       "      <td>3835.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1444.000000</td>\n",
       "      <td>5149.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         article_id       user_id  interaction\n",
       "count  45993.000000  45993.000000      45993.0\n",
       "mean     908.846477   2300.918314          1.0\n",
       "std      486.647866   1712.658385          0.0\n",
       "min        0.000000      1.000000          1.0\n",
       "25%      460.000000    621.000000          1.0\n",
       "50%     1151.000000   2330.000000          1.0\n",
       "75%     1336.000000   3835.000000          1.0\n",
       "max     1444.000000   5149.000000          1.0"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_body</th>\n",
       "      <th>doc_description</th>\n",
       "      <th>doc_full_name</th>\n",
       "      <th>doc_status</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>article_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Skip navigation Sign in SearchLoading...\\r\\n\\r...</td>\n",
       "      <td>Detect bad readings in real time using Python ...</td>\n",
       "      <td>Detect Malfunctioning IoT Sensors with Streami...</td>\n",
       "      <td>Live</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>No Free Hunch Navigation * kaggle.com\\r\\n\\r\\n ...</td>\n",
       "      <td>See the forest, see the trees. Here lies the c...</td>\n",
       "      <td>Communicating data science: A guide to present...</td>\n",
       "      <td>Live</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>☰ * Login\\r\\n * Sign Up\\r\\n\\r\\n * Learning Pat...</td>\n",
       "      <td>Here’s this week’s news in Data Science and Bi...</td>\n",
       "      <td>This Week in Data Science (April 18, 2017)</td>\n",
       "      <td>Live</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DATALAYER: HIGH THROUGHPUT, LOW LATENCY AT SCA...</td>\n",
       "      <td>Learn how distributed DBs solve the problem of...</td>\n",
       "      <td>DataLayer Conference: Boost the performance of...</td>\n",
       "      <td>Live</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Skip navigation Sign in SearchLoading...\\r\\n\\r...</td>\n",
       "      <td>This video demonstrates the power of IBM DataS...</td>\n",
       "      <td>Analyze NY Restaurant data using Spark in DSX</td>\n",
       "      <td>Live</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Compose is all about immediacy. You want a new...</td>\n",
       "      <td>Using Compose's PostgreSQL data browser.</td>\n",
       "      <td>Browsing PostgreSQL Data with Compose</td>\n",
       "      <td>Live</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>UPGRADING YOUR POSTGRESQL TO 9.5Share on Twitt...</td>\n",
       "      <td>Upgrading your PostgreSQL deployment to versio...</td>\n",
       "      <td>Upgrading your PostgreSQL to 9.5</td>\n",
       "      <td>Live</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Follow Sign in / Sign up 135 8 * Share\\r\\n * 1...</td>\n",
       "      <td>For a company like Slack that strives to be as...</td>\n",
       "      <td>Data Wrangling at Slack</td>\n",
       "      <td>Live</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>* Host\\r\\n * Competitions\\r\\n * Datasets\\r\\n *...</td>\n",
       "      <td>Kaggle is your home for data science. Learn ne...</td>\n",
       "      <td>Data Science Bowl 2017</td>\n",
       "      <td>Live</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>THE GRADIENT FLOW\\r\\nDATA / TECHNOLOGY / CULTU...</td>\n",
       "      <td>[A version of this post appears on the O’Reill...</td>\n",
       "      <td>Using Apache Spark to predict attack vectors a...</td>\n",
       "      <td>Live</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>OFFLINE-FIRST IOS APPS WITH SWIFT &amp; PART 1: TH...</td>\n",
       "      <td>Apple's sample app, Food Tracker, taught you i...</td>\n",
       "      <td>Offline-First iOS Apps with Swift &amp; Cloudant S...</td>\n",
       "      <td>Live</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Warehousing data from Cloudant to dashDB great...</td>\n",
       "      <td>Replicating data to a relational dashDB databa...</td>\n",
       "      <td>Warehousing GeoJSON documents</td>\n",
       "      <td>Live</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Skip to main content IBM developerWorks / Deve...</td>\n",
       "      <td>This recipe showcases how one can analyze the ...</td>\n",
       "      <td>Timeseries Data Analysis of IoT events by usin...</td>\n",
       "      <td>Live</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Maureen McElaney Blocked Unblock Follow Follow...</td>\n",
       "      <td>There’s a reason you’ve been hearing a lot abo...</td>\n",
       "      <td>Bridging the Gap Between Python and Scala Jupy...</td>\n",
       "      <td>Live</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Raj Singh Blocked Unblock Follow Following Dev...</td>\n",
       "      <td>Who are those people lurking behind the statis...</td>\n",
       "      <td>Got zip code data? Prep it for analytics. – IB...</td>\n",
       "      <td>Live</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>* Home\\r\\n * Community\\r\\n * Projects\\r\\n * Bl...</td>\n",
       "      <td>Early methods to integrate machine learning us...</td>\n",
       "      <td>Apache Spark™ 2.0: Extend Structured Streaming...</td>\n",
       "      <td>Live</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>* Home\\r\\n * Research\\r\\n * Partnerships and C...</td>\n",
       "      <td>The performance of supervised predictive model...</td>\n",
       "      <td>Higher-order Logistic Regression for Large Dat...</td>\n",
       "      <td>Live</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Enterprise Pricing Articles Sign in Free 30-Da...</td>\n",
       "      <td>We've always considered MySQL as a potential C...</td>\n",
       "      <td>Compose for MySQL now for you</td>\n",
       "      <td>Live</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Homepage Follow Sign in / Sign up * Home\\r\\n *...</td>\n",
       "      <td>It has never been easier to build AI or machin...</td>\n",
       "      <td>The Greatest Public Datasets for AI – Startup ...</td>\n",
       "      <td>Live</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>METRICS MAVEN: MODE D'EMPLOI - FINDING THE MOD...</td>\n",
       "      <td>In our Metrics Maven series, Compose's data sc...</td>\n",
       "      <td>Finding the Mode in PostgreSQL</td>\n",
       "      <td>Live</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Homepage Follow Sign in / Sign up Homepage * H...</td>\n",
       "      <td>It is often useful to use RStudio for one piec...</td>\n",
       "      <td>Working interactively with RStudio and noteboo...</td>\n",
       "      <td>Live</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Raj Singh Blocked Unblock Follow Following Dev...</td>\n",
       "      <td>You’re doing your data a disservice if you don...</td>\n",
       "      <td>Mapping for Data Science with PixieDust and Ma...</td>\n",
       "      <td>Live</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>IMPORTING JSON DOCUMENTS WITH NOSQLIMPORT\\r\\nG...</td>\n",
       "      <td>Introducing nosqlimport, an npm module to help...</td>\n",
       "      <td>Move CSVs into different JSON doc stores</td>\n",
       "      <td>Live</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>This video shows you how to build and query a ...</td>\n",
       "      <td>This video shows you how to build and query a ...</td>\n",
       "      <td>Tutorial: How to build and query a Cloudant ge...</td>\n",
       "      <td>Live</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>THE CONVERSATIONAL INTERFACE IS THE NEW PARADI...</td>\n",
       "      <td>Botkit provides a simple framework to handle t...</td>\n",
       "      <td>The Conversational Interface is the New Paradigm</td>\n",
       "      <td>Live</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Skip navigation Upload Sign in SearchLoading.....</td>\n",
       "      <td>Want to learn more about how we created the Da...</td>\n",
       "      <td>Creating the Data Science Experience</td>\n",
       "      <td>Live</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>GOOGLE RESEARCH BLOG The latest news from Rese...</td>\n",
       "      <td>Much of driving is spent either stuck in traff...</td>\n",
       "      <td>Using Machine Learning to predict parking diff...</td>\n",
       "      <td>Live</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Skip navigation Upload Sign in SearchLoading.....</td>\n",
       "      <td>This talk assumes you have a basic understandi...</td>\n",
       "      <td>Getting The Best Performance With PySpark</td>\n",
       "      <td>Live</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>ACCESS DENIED\\r\\nSadly, your client does not s...</td>\n",
       "      <td>In this paper, we propose gcForest, a decision...</td>\n",
       "      <td>Deep Forest: Towards An Alternative to Deep Ne...</td>\n",
       "      <td>Live</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Homepage Follow Sign in / Sign up Homepage * H...</td>\n",
       "      <td>I’m very happy and proud to announce that IBM ...</td>\n",
       "      <td>Experience IoT with Coursera</td>\n",
       "      <td>Live</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1021</th>\n",
       "      <td>Enterprise Pricing Articles Sign in Free 30-Da...</td>\n",
       "      <td>Varun Singh, a software engineer at IBM's Wats...</td>\n",
       "      <td>Redis and MongoDB in the biomedical domain</td>\n",
       "      <td>Live</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1022</th>\n",
       "      <td>Skip navigation Sign in SearchLoading...\\r\\n\\r...</td>\n",
       "      <td>This video shows you how to create and adminis...</td>\n",
       "      <td>Create and administer a data catalog using IBM...</td>\n",
       "      <td>Live</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1023</th>\n",
       "      <td>Compose The Compose logo Articles Sign in Free...</td>\n",
       "      <td>With the latest 0.2.1 version of Transporter, ...</td>\n",
       "      <td>How to move data with Compose Transporter - Fr...</td>\n",
       "      <td>Live</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1024</th>\n",
       "      <td>Follow Sign in / Sign up * Home\\r\\n * About In...</td>\n",
       "      <td>Audio super-resolution aims to reconstruct a h...</td>\n",
       "      <td>Using Deep Learning to Reconstruct High-Resolu...</td>\n",
       "      <td>Live</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1025</th>\n",
       "      <td>Homepage Follow Sign in / Sign up Homepage * H...</td>\n",
       "      <td>Since then, this metric has been ubiquitously ...</td>\n",
       "      <td>Data tidying in Data Science Experience</td>\n",
       "      <td>Live</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1026</th>\n",
       "      <td>Develop in the cloud at the click of a button!...</td>\n",
       "      <td>Build a word game app and see how to manage an...</td>\n",
       "      <td>Build a simple word game app using Cloudant on...</td>\n",
       "      <td>Live</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1027</th>\n",
       "      <td>BLAZINGLY FAST GEOSPATIAL QUERIES WITH REDIS\\r...</td>\n",
       "      <td>Use Redis and and Python scripts to speed your...</td>\n",
       "      <td>Blazingly Fast Geospatial Queries with Redis</td>\n",
       "      <td>Live</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1028</th>\n",
       "      <td>Blog Home Dataquest.io Learn Data Science in Y...</td>\n",
       "      <td>In this post, you’ll learn to query, update, a...</td>\n",
       "      <td>Working with SQLite Databases using Python and...</td>\n",
       "      <td>Live</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1029</th>\n",
       "      <td>DATALAYER: MANAGING (OR NOT) THE DATA IN IMMUT...</td>\n",
       "      <td>Adron Hall of Thrashing Code and Home Depot, t...</td>\n",
       "      <td>DataLayer Conference: Managing (or not) the Da...</td>\n",
       "      <td>Live</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1030</th>\n",
       "      <td>Skip to contentWin-Vector Blog\\r\\n\\r\\nThe Win-...</td>\n",
       "      <td>Describes the use of Laplace noise in machine ...</td>\n",
       "      <td>Laplace noising versus simulated out of sample...</td>\n",
       "      <td>Live</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1031</th>\n",
       "      <td>This work is licensed under a Creative Commons...</td>\n",
       "      <td>A full guide to Elasticsearch, the real-time d...</td>\n",
       "      <td>The Definitive Guide</td>\n",
       "      <td>Live</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1032</th>\n",
       "      <td>NaN</td>\n",
       "      <td>See how quick and easy it is to set up a dashD...</td>\n",
       "      <td>Get started with dashDB on Bluemix</td>\n",
       "      <td>Live</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1033</th>\n",
       "      <td>The relational database has been the dominant ...</td>\n",
       "      <td>The relational database has been the dominant ...</td>\n",
       "      <td>The Many Flavors of NoSQL at That Conference</td>\n",
       "      <td>Live</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1034</th>\n",
       "      <td>Skip to main content IBM developerWorks / Deve...</td>\n",
       "      <td>Building your first data warehouse doesn’t hav...</td>\n",
       "      <td>Your First Data Warehouse Is Easy. Meet the ODS.</td>\n",
       "      <td>Live</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1035</th>\n",
       "      <td>Skip to contentDinesh Nirmal's Blog\\r\\n\\r\\nA b...</td>\n",
       "      <td>In my last blog “Business differentiation thro...</td>\n",
       "      <td>Machine Learning for the Enterprise.</td>\n",
       "      <td>Live</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1036</th>\n",
       "      <td>Compose The Compose logo Articles Sign in Free...</td>\n",
       "      <td>MongoDB's aggregation pipeline makes finding d...</td>\n",
       "      <td>Finding Duplicate Documents in MongoDB</td>\n",
       "      <td>Live</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1037</th>\n",
       "      <td>Glynn Bird Blocked Unblock Follow Following De...</td>\n",
       "      <td>Which write API endpoint is the right write ca...</td>\n",
       "      <td>Piecemeal, Bulk, or Batch? – IBM Watson Data L...</td>\n",
       "      <td>Live</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1038</th>\n",
       "      <td>MENU\\r\\nClose\\r\\nSubscribe SubscribeREDUCING O...</td>\n",
       "      <td>Nothing spoils a plot like (too much) data.</td>\n",
       "      <td>Reducing overplotting in scatterplots</td>\n",
       "      <td>Live</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1039</th>\n",
       "      <td>Homepage IBM Watson Data Lab Follow Sign in / ...</td>\n",
       "      <td>Getting started with custom visualizations, si...</td>\n",
       "      <td>You Too Can Make Magic (in Jupyter Notebooks w...</td>\n",
       "      <td>Live</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1040</th>\n",
       "      <td>Although it is built around a JavaScript engin...</td>\n",
       "      <td>Although it is built around a JavaScript engin...</td>\n",
       "      <td>How I Stopped Worrying &amp; Learned to Love the M...</td>\n",
       "      <td>Live</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1041</th>\n",
       "      <td>Margriet Groenendijk Blocked Unblock Follow Fo...</td>\n",
       "      <td>Last week I attended the GeoPython conference ...</td>\n",
       "      <td>Mapping All the Things with Python – IBM Watso...</td>\n",
       "      <td>Live</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1042</th>\n",
       "      <td>Homepage Follow Sign in / Sign up Homepage * H...</td>\n",
       "      <td>In this post, we will go through how to read a...</td>\n",
       "      <td>Use IBM Data Science Experience to Read and Wr...</td>\n",
       "      <td>Live</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1043</th>\n",
       "      <td>Homepage Follow Sign in Get started * Home\\r\\n...</td>\n",
       "      <td>As more devices become internet enabled, harne...</td>\n",
       "      <td>Use IoT data in Streams Designer for billing a...</td>\n",
       "      <td>Live</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1044</th>\n",
       "      <td>* \\r\\n * \\r\\n * \\r\\n * \\r\\n * \\r\\n * \\r\\n * \\r...</td>\n",
       "      <td>Continuing my previous work on exploring Arlin...</td>\n",
       "      <td>Mapping Points with Folium</td>\n",
       "      <td>Live</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1045</th>\n",
       "      <td>lA SPEED GUIDE TO REDIS LUA SCRIPTING\\r\\nShare...</td>\n",
       "      <td>Lua is a compact language which can be embedde...</td>\n",
       "      <td>A Speed Guide To Redis Lua Scripting</td>\n",
       "      <td>Live</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1046</th>\n",
       "      <td>PouchDB-find is a new API and syntax that allo...</td>\n",
       "      <td>PouchDB uses MapReduce as its default search m...</td>\n",
       "      <td>A look under the covers of PouchDB-find</td>\n",
       "      <td>Live</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1047</th>\n",
       "      <td>We compare discriminative and generative learn...</td>\n",
       "      <td>We compare discriminative and generative learn...</td>\n",
       "      <td>A comparison of logistic regression and naive ...</td>\n",
       "      <td>Live</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048</th>\n",
       "      <td>Essays about data, building products and boots...</td>\n",
       "      <td>In order to demystify some of the magic behind...</td>\n",
       "      <td>What I Learned Implementing a Classifier from ...</td>\n",
       "      <td>Live</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1049</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Learn how to use IBM dashDB as data store for ...</td>\n",
       "      <td>Use dashDB with Spark</td>\n",
       "      <td>Live</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1050</th>\n",
       "      <td>Homepage Follow Sign in / Sign up Homepage * H...</td>\n",
       "      <td>Once you get used to developing in a Notebook ...</td>\n",
       "      <td>Jupyter Notebooks with Scala, Python, or R Ker...</td>\n",
       "      <td>Live</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1051 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     doc_body  \\\n",
       "article_id                                                      \n",
       "0           Skip navigation Sign in SearchLoading...\\r\\n\\r...   \n",
       "1           No Free Hunch Navigation * kaggle.com\\r\\n\\r\\n ...   \n",
       "2           ☰ * Login\\r\\n * Sign Up\\r\\n\\r\\n * Learning Pat...   \n",
       "3           DATALAYER: HIGH THROUGHPUT, LOW LATENCY AT SCA...   \n",
       "4           Skip navigation Sign in SearchLoading...\\r\\n\\r...   \n",
       "5           Compose is all about immediacy. You want a new...   \n",
       "6           UPGRADING YOUR POSTGRESQL TO 9.5Share on Twitt...   \n",
       "7           Follow Sign in / Sign up 135 8 * Share\\r\\n * 1...   \n",
       "8           * Host\\r\\n * Competitions\\r\\n * Datasets\\r\\n *...   \n",
       "9           THE GRADIENT FLOW\\r\\nDATA / TECHNOLOGY / CULTU...   \n",
       "10          OFFLINE-FIRST IOS APPS WITH SWIFT & PART 1: TH...   \n",
       "11          Warehousing data from Cloudant to dashDB great...   \n",
       "12          Skip to main content IBM developerWorks / Deve...   \n",
       "13          Maureen McElaney Blocked Unblock Follow Follow...   \n",
       "14          Raj Singh Blocked Unblock Follow Following Dev...   \n",
       "15          * Home\\r\\n * Community\\r\\n * Projects\\r\\n * Bl...   \n",
       "16          * Home\\r\\n * Research\\r\\n * Partnerships and C...   \n",
       "17          Enterprise Pricing Articles Sign in Free 30-Da...   \n",
       "18          Homepage Follow Sign in / Sign up * Home\\r\\n *...   \n",
       "19          METRICS MAVEN: MODE D'EMPLOI - FINDING THE MOD...   \n",
       "20          Homepage Follow Sign in / Sign up Homepage * H...   \n",
       "21          Raj Singh Blocked Unblock Follow Following Dev...   \n",
       "22          IMPORTING JSON DOCUMENTS WITH NOSQLIMPORT\\r\\nG...   \n",
       "23          This video shows you how to build and query a ...   \n",
       "24          THE CONVERSATIONAL INTERFACE IS THE NEW PARADI...   \n",
       "25          Skip navigation Upload Sign in SearchLoading.....   \n",
       "26          GOOGLE RESEARCH BLOG The latest news from Rese...   \n",
       "27          Skip navigation Upload Sign in SearchLoading.....   \n",
       "28          ACCESS DENIED\\r\\nSadly, your client does not s...   \n",
       "29          Homepage Follow Sign in / Sign up Homepage * H...   \n",
       "...                                                       ...   \n",
       "1021        Enterprise Pricing Articles Sign in Free 30-Da...   \n",
       "1022        Skip navigation Sign in SearchLoading...\\r\\n\\r...   \n",
       "1023        Compose The Compose logo Articles Sign in Free...   \n",
       "1024        Follow Sign in / Sign up * Home\\r\\n * About In...   \n",
       "1025        Homepage Follow Sign in / Sign up Homepage * H...   \n",
       "1026        Develop in the cloud at the click of a button!...   \n",
       "1027        BLAZINGLY FAST GEOSPATIAL QUERIES WITH REDIS\\r...   \n",
       "1028        Blog Home Dataquest.io Learn Data Science in Y...   \n",
       "1029        DATALAYER: MANAGING (OR NOT) THE DATA IN IMMUT...   \n",
       "1030        Skip to contentWin-Vector Blog\\r\\n\\r\\nThe Win-...   \n",
       "1031        This work is licensed under a Creative Commons...   \n",
       "1032                                                      NaN   \n",
       "1033        The relational database has been the dominant ...   \n",
       "1034        Skip to main content IBM developerWorks / Deve...   \n",
       "1035        Skip to contentDinesh Nirmal's Blog\\r\\n\\r\\nA b...   \n",
       "1036        Compose The Compose logo Articles Sign in Free...   \n",
       "1037        Glynn Bird Blocked Unblock Follow Following De...   \n",
       "1038        MENU\\r\\nClose\\r\\nSubscribe SubscribeREDUCING O...   \n",
       "1039        Homepage IBM Watson Data Lab Follow Sign in / ...   \n",
       "1040        Although it is built around a JavaScript engin...   \n",
       "1041        Margriet Groenendijk Blocked Unblock Follow Fo...   \n",
       "1042        Homepage Follow Sign in / Sign up Homepage * H...   \n",
       "1043        Homepage Follow Sign in Get started * Home\\r\\n...   \n",
       "1044        * \\r\\n * \\r\\n * \\r\\n * \\r\\n * \\r\\n * \\r\\n * \\r...   \n",
       "1045        lA SPEED GUIDE TO REDIS LUA SCRIPTING\\r\\nShare...   \n",
       "1046        PouchDB-find is a new API and syntax that allo...   \n",
       "1047        We compare discriminative and generative learn...   \n",
       "1048        Essays about data, building products and boots...   \n",
       "1049                                                      NaN   \n",
       "1050        Homepage Follow Sign in / Sign up Homepage * H...   \n",
       "\n",
       "                                              doc_description  \\\n",
       "article_id                                                      \n",
       "0           Detect bad readings in real time using Python ...   \n",
       "1           See the forest, see the trees. Here lies the c...   \n",
       "2           Here’s this week’s news in Data Science and Bi...   \n",
       "3           Learn how distributed DBs solve the problem of...   \n",
       "4           This video demonstrates the power of IBM DataS...   \n",
       "5                    Using Compose's PostgreSQL data browser.   \n",
       "6           Upgrading your PostgreSQL deployment to versio...   \n",
       "7           For a company like Slack that strives to be as...   \n",
       "8           Kaggle is your home for data science. Learn ne...   \n",
       "9           [A version of this post appears on the O’Reill...   \n",
       "10          Apple's sample app, Food Tracker, taught you i...   \n",
       "11          Replicating data to a relational dashDB databa...   \n",
       "12          This recipe showcases how one can analyze the ...   \n",
       "13          There’s a reason you’ve been hearing a lot abo...   \n",
       "14          Who are those people lurking behind the statis...   \n",
       "15          Early methods to integrate machine learning us...   \n",
       "16          The performance of supervised predictive model...   \n",
       "17          We've always considered MySQL as a potential C...   \n",
       "18          It has never been easier to build AI or machin...   \n",
       "19          In our Metrics Maven series, Compose's data sc...   \n",
       "20          It is often useful to use RStudio for one piec...   \n",
       "21          You’re doing your data a disservice if you don...   \n",
       "22          Introducing nosqlimport, an npm module to help...   \n",
       "23          This video shows you how to build and query a ...   \n",
       "24          Botkit provides a simple framework to handle t...   \n",
       "25          Want to learn more about how we created the Da...   \n",
       "26          Much of driving is spent either stuck in traff...   \n",
       "27          This talk assumes you have a basic understandi...   \n",
       "28          In this paper, we propose gcForest, a decision...   \n",
       "29          I’m very happy and proud to announce that IBM ...   \n",
       "...                                                       ...   \n",
       "1021        Varun Singh, a software engineer at IBM's Wats...   \n",
       "1022        This video shows you how to create and adminis...   \n",
       "1023        With the latest 0.2.1 version of Transporter, ...   \n",
       "1024        Audio super-resolution aims to reconstruct a h...   \n",
       "1025        Since then, this metric has been ubiquitously ...   \n",
       "1026        Build a word game app and see how to manage an...   \n",
       "1027        Use Redis and and Python scripts to speed your...   \n",
       "1028        In this post, you’ll learn to query, update, a...   \n",
       "1029        Adron Hall of Thrashing Code and Home Depot, t...   \n",
       "1030        Describes the use of Laplace noise in machine ...   \n",
       "1031        A full guide to Elasticsearch, the real-time d...   \n",
       "1032        See how quick and easy it is to set up a dashD...   \n",
       "1033        The relational database has been the dominant ...   \n",
       "1034        Building your first data warehouse doesn’t hav...   \n",
       "1035        In my last blog “Business differentiation thro...   \n",
       "1036        MongoDB's aggregation pipeline makes finding d...   \n",
       "1037        Which write API endpoint is the right write ca...   \n",
       "1038              Nothing spoils a plot like (too much) data.   \n",
       "1039        Getting started with custom visualizations, si...   \n",
       "1040        Although it is built around a JavaScript engin...   \n",
       "1041        Last week I attended the GeoPython conference ...   \n",
       "1042        In this post, we will go through how to read a...   \n",
       "1043        As more devices become internet enabled, harne...   \n",
       "1044        Continuing my previous work on exploring Arlin...   \n",
       "1045        Lua is a compact language which can be embedde...   \n",
       "1046        PouchDB uses MapReduce as its default search m...   \n",
       "1047        We compare discriminative and generative learn...   \n",
       "1048        In order to demystify some of the magic behind...   \n",
       "1049        Learn how to use IBM dashDB as data store for ...   \n",
       "1050        Once you get used to developing in a Notebook ...   \n",
       "\n",
       "                                                doc_full_name doc_status  \n",
       "article_id                                                                \n",
       "0           Detect Malfunctioning IoT Sensors with Streami...       Live  \n",
       "1           Communicating data science: A guide to present...       Live  \n",
       "2                  This Week in Data Science (April 18, 2017)       Live  \n",
       "3           DataLayer Conference: Boost the performance of...       Live  \n",
       "4               Analyze NY Restaurant data using Spark in DSX       Live  \n",
       "5                       Browsing PostgreSQL Data with Compose       Live  \n",
       "6                            Upgrading your PostgreSQL to 9.5       Live  \n",
       "7                                     Data Wrangling at Slack       Live  \n",
       "8                                      Data Science Bowl 2017       Live  \n",
       "9           Using Apache Spark to predict attack vectors a...       Live  \n",
       "10          Offline-First iOS Apps with Swift & Cloudant S...       Live  \n",
       "11                              Warehousing GeoJSON documents       Live  \n",
       "12          Timeseries Data Analysis of IoT events by usin...       Live  \n",
       "13          Bridging the Gap Between Python and Scala Jupy...       Live  \n",
       "14          Got zip code data? Prep it for analytics. – IB...       Live  \n",
       "15          Apache Spark™ 2.0: Extend Structured Streaming...       Live  \n",
       "16          Higher-order Logistic Regression for Large Dat...       Live  \n",
       "17                              Compose for MySQL now for you       Live  \n",
       "18          The Greatest Public Datasets for AI – Startup ...       Live  \n",
       "19                             Finding the Mode in PostgreSQL       Live  \n",
       "20          Working interactively with RStudio and noteboo...       Live  \n",
       "21          Mapping for Data Science with PixieDust and Ma...       Live  \n",
       "22                   Move CSVs into different JSON doc stores       Live  \n",
       "23          Tutorial: How to build and query a Cloudant ge...       Live  \n",
       "24           The Conversational Interface is the New Paradigm       Live  \n",
       "25                       Creating the Data Science Experience       Live  \n",
       "26          Using Machine Learning to predict parking diff...       Live  \n",
       "27                  Getting The Best Performance With PySpark       Live  \n",
       "28          Deep Forest: Towards An Alternative to Deep Ne...       Live  \n",
       "29                               Experience IoT with Coursera       Live  \n",
       "...                                                       ...        ...  \n",
       "1021               Redis and MongoDB in the biomedical domain       Live  \n",
       "1022        Create and administer a data catalog using IBM...       Live  \n",
       "1023        How to move data with Compose Transporter - Fr...       Live  \n",
       "1024        Using Deep Learning to Reconstruct High-Resolu...       Live  \n",
       "1025                  Data tidying in Data Science Experience       Live  \n",
       "1026        Build a simple word game app using Cloudant on...       Live  \n",
       "1027             Blazingly Fast Geospatial Queries with Redis       Live  \n",
       "1028        Working with SQLite Databases using Python and...       Live  \n",
       "1029        DataLayer Conference: Managing (or not) the Da...       Live  \n",
       "1030        Laplace noising versus simulated out of sample...       Live  \n",
       "1031                                     The Definitive Guide       Live  \n",
       "1032                       Get started with dashDB on Bluemix       Live  \n",
       "1033             The Many Flavors of NoSQL at That Conference       Live  \n",
       "1034         Your First Data Warehouse Is Easy. Meet the ODS.       Live  \n",
       "1035                     Machine Learning for the Enterprise.       Live  \n",
       "1036                   Finding Duplicate Documents in MongoDB       Live  \n",
       "1037        Piecemeal, Bulk, or Batch? – IBM Watson Data L...       Live  \n",
       "1038                    Reducing overplotting in scatterplots       Live  \n",
       "1039        You Too Can Make Magic (in Jupyter Notebooks w...       Live  \n",
       "1040        How I Stopped Worrying & Learned to Love the M...       Live  \n",
       "1041        Mapping All the Things with Python – IBM Watso...       Live  \n",
       "1042        Use IBM Data Science Experience to Read and Wr...       Live  \n",
       "1043        Use IoT data in Streams Designer for billing a...       Live  \n",
       "1044                               Mapping Points with Folium       Live  \n",
       "1045                     A Speed Guide To Redis Lua Scripting       Live  \n",
       "1046                  A look under the covers of PouchDB-find       Live  \n",
       "1047        A comparison of logistic regression and naive ...       Live  \n",
       "1048        What I Learned Implementing a Classifier from ...       Live  \n",
       "1049                                    Use dashDB with Spark       Live  \n",
       "1050        Jupyter Notebooks with Scala, Python, or R Ker...       Live  \n",
       "\n",
       "[1051 rows x 4 columns]"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_articles.set_index('article_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Float64Index([   0.0,    2.0,    4.0,    8.0,    9.0,   12.0,   14.0,   15.0,\n",
       "                16.0,   18.0,\n",
       "              ...\n",
       "              1434.0, 1435.0, 1436.0, 1437.0, 1439.0, 1440.0, 1441.0, 1442.0,\n",
       "              1443.0, 1444.0],\n",
       "             dtype='float64', name='article_id', length=714)"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_item.iloc[0,:].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_articles = df[['article_id','title']].drop_duplicates() \\\n",
    "                        .assign(article_id = lambda x: x.astype(str)) \\\n",
    "                        .set_index('article_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>article_id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1430.0</th>\n",
       "      <td>using pixiedust for fast, flexible, and easier...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1314.0</th>\n",
       "      <td>healthcare python streaming application demo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1429.0</th>\n",
       "      <td>use deep learning for image classification</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1338.0</th>\n",
       "      <td>ml optimization using cognitive assistant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1276.0</th>\n",
       "      <td>deploy your python model as a restful api</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                        title\n",
       "article_id                                                   \n",
       "1430.0      using pixiedust for fast, flexible, and easier...\n",
       "1314.0           healthcare python streaming application demo\n",
       "1429.0             use deep learning for image classification\n",
       "1338.0              ml optimization using cognitive assistant\n",
       "1276.0              deploy your python model as a restful api"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_articles.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "article_ids = ['1024.0', '1176.0', '1305.0', '1314.0', '1422.0', '1427.0']\n",
    "article_names = unique_articles.loc[article_ids,:].title.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['using deep learning to reconstruct high-resolution audio',\n",
       "       'build a python app on the streaming analytics service',\n",
       "       'gosales transactions for naive bayes model',\n",
       "       'healthcare python streaming application demo',\n",
       "       'use r dataframes & ibm watson natural language understanding',\n",
       "       'use xgboost, scikit-learn & ibm watson machine learning apis'], dtype=object)"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_body</th>\n",
       "      <th>doc_description</th>\n",
       "      <th>doc_full_name</th>\n",
       "      <th>doc_status</th>\n",
       "      <th>article_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Skip navigation Sign in SearchLoading...\\r\\n\\r...</td>\n",
       "      <td>Detect bad readings in real time using Python ...</td>\n",
       "      <td>Detect Malfunctioning IoT Sensors with Streami...</td>\n",
       "      <td>Live</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>No Free Hunch Navigation * kaggle.com\\r\\n\\r\\n ...</td>\n",
       "      <td>See the forest, see the trees. Here lies the c...</td>\n",
       "      <td>Communicating data science: A guide to present...</td>\n",
       "      <td>Live</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>☰ * Login\\r\\n * Sign Up\\r\\n\\r\\n * Learning Pat...</td>\n",
       "      <td>Here’s this week’s news in Data Science and Bi...</td>\n",
       "      <td>This Week in Data Science (April 18, 2017)</td>\n",
       "      <td>Live</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DATALAYER: HIGH THROUGHPUT, LOW LATENCY AT SCA...</td>\n",
       "      <td>Learn how distributed DBs solve the problem of...</td>\n",
       "      <td>DataLayer Conference: Boost the performance of...</td>\n",
       "      <td>Live</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Skip navigation Sign in SearchLoading...\\r\\n\\r...</td>\n",
       "      <td>This video demonstrates the power of IBM DataS...</td>\n",
       "      <td>Analyze NY Restaurant data using Spark in DSX</td>\n",
       "      <td>Live</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Compose is all about immediacy. You want a new...</td>\n",
       "      <td>Using Compose's PostgreSQL data browser.</td>\n",
       "      <td>Browsing PostgreSQL Data with Compose</td>\n",
       "      <td>Live</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>UPGRADING YOUR POSTGRESQL TO 9.5Share on Twitt...</td>\n",
       "      <td>Upgrading your PostgreSQL deployment to versio...</td>\n",
       "      <td>Upgrading your PostgreSQL to 9.5</td>\n",
       "      <td>Live</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Follow Sign in / Sign up 135 8 * Share\\r\\n * 1...</td>\n",
       "      <td>For a company like Slack that strives to be as...</td>\n",
       "      <td>Data Wrangling at Slack</td>\n",
       "      <td>Live</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>* Host\\r\\n * Competitions\\r\\n * Datasets\\r\\n *...</td>\n",
       "      <td>Kaggle is your home for data science. Learn ne...</td>\n",
       "      <td>Data Science Bowl 2017</td>\n",
       "      <td>Live</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>THE GRADIENT FLOW\\r\\nDATA / TECHNOLOGY / CULTU...</td>\n",
       "      <td>[A version of this post appears on the O’Reill...</td>\n",
       "      <td>Using Apache Spark to predict attack vectors a...</td>\n",
       "      <td>Live</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>OFFLINE-FIRST IOS APPS WITH SWIFT &amp; PART 1: TH...</td>\n",
       "      <td>Apple's sample app, Food Tracker, taught you i...</td>\n",
       "      <td>Offline-First iOS Apps with Swift &amp; Cloudant S...</td>\n",
       "      <td>Live</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Warehousing data from Cloudant to dashDB great...</td>\n",
       "      <td>Replicating data to a relational dashDB databa...</td>\n",
       "      <td>Warehousing GeoJSON documents</td>\n",
       "      <td>Live</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Skip to main content IBM developerWorks / Deve...</td>\n",
       "      <td>This recipe showcases how one can analyze the ...</td>\n",
       "      <td>Timeseries Data Analysis of IoT events by usin...</td>\n",
       "      <td>Live</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Maureen McElaney Blocked Unblock Follow Follow...</td>\n",
       "      <td>There’s a reason you’ve been hearing a lot abo...</td>\n",
       "      <td>Bridging the Gap Between Python and Scala Jupy...</td>\n",
       "      <td>Live</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Raj Singh Blocked Unblock Follow Following Dev...</td>\n",
       "      <td>Who are those people lurking behind the statis...</td>\n",
       "      <td>Got zip code data? Prep it for analytics. – IB...</td>\n",
       "      <td>Live</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>* Home\\r\\n * Community\\r\\n * Projects\\r\\n * Bl...</td>\n",
       "      <td>Early methods to integrate machine learning us...</td>\n",
       "      <td>Apache Spark™ 2.0: Extend Structured Streaming...</td>\n",
       "      <td>Live</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>* Home\\r\\n * Research\\r\\n * Partnerships and C...</td>\n",
       "      <td>The performance of supervised predictive model...</td>\n",
       "      <td>Higher-order Logistic Regression for Large Dat...</td>\n",
       "      <td>Live</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Enterprise Pricing Articles Sign in Free 30-Da...</td>\n",
       "      <td>We've always considered MySQL as a potential C...</td>\n",
       "      <td>Compose for MySQL now for you</td>\n",
       "      <td>Live</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Homepage Follow Sign in / Sign up * Home\\r\\n *...</td>\n",
       "      <td>It has never been easier to build AI or machin...</td>\n",
       "      <td>The Greatest Public Datasets for AI – Startup ...</td>\n",
       "      <td>Live</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>METRICS MAVEN: MODE D'EMPLOI - FINDING THE MOD...</td>\n",
       "      <td>In our Metrics Maven series, Compose's data sc...</td>\n",
       "      <td>Finding the Mode in PostgreSQL</td>\n",
       "      <td>Live</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Homepage Follow Sign in / Sign up Homepage * H...</td>\n",
       "      <td>It is often useful to use RStudio for one piec...</td>\n",
       "      <td>Working interactively with RStudio and noteboo...</td>\n",
       "      <td>Live</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Raj Singh Blocked Unblock Follow Following Dev...</td>\n",
       "      <td>You’re doing your data a disservice if you don...</td>\n",
       "      <td>Mapping for Data Science with PixieDust and Ma...</td>\n",
       "      <td>Live</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>IMPORTING JSON DOCUMENTS WITH NOSQLIMPORT\\r\\nG...</td>\n",
       "      <td>Introducing nosqlimport, an npm module to help...</td>\n",
       "      <td>Move CSVs into different JSON doc stores</td>\n",
       "      <td>Live</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>This video shows you how to build and query a ...</td>\n",
       "      <td>This video shows you how to build and query a ...</td>\n",
       "      <td>Tutorial: How to build and query a Cloudant ge...</td>\n",
       "      <td>Live</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>THE CONVERSATIONAL INTERFACE IS THE NEW PARADI...</td>\n",
       "      <td>Botkit provides a simple framework to handle t...</td>\n",
       "      <td>The Conversational Interface is the New Paradigm</td>\n",
       "      <td>Live</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Skip navigation Upload Sign in SearchLoading.....</td>\n",
       "      <td>Want to learn more about how we created the Da...</td>\n",
       "      <td>Creating the Data Science Experience</td>\n",
       "      <td>Live</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>GOOGLE RESEARCH BLOG The latest news from Rese...</td>\n",
       "      <td>Much of driving is spent either stuck in traff...</td>\n",
       "      <td>Using Machine Learning to predict parking diff...</td>\n",
       "      <td>Live</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Skip navigation Upload Sign in SearchLoading.....</td>\n",
       "      <td>This talk assumes you have a basic understandi...</td>\n",
       "      <td>Getting The Best Performance With PySpark</td>\n",
       "      <td>Live</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>ACCESS DENIED\\r\\nSadly, your client does not s...</td>\n",
       "      <td>In this paper, we propose gcForest, a decision...</td>\n",
       "      <td>Deep Forest: Towards An Alternative to Deep Ne...</td>\n",
       "      <td>Live</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Homepage Follow Sign in / Sign up Homepage * H...</td>\n",
       "      <td>I’m very happy and proud to announce that IBM ...</td>\n",
       "      <td>Experience IoT with Coursera</td>\n",
       "      <td>Live</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1026</th>\n",
       "      <td>Enterprise Pricing Articles Sign in Free 30-Da...</td>\n",
       "      <td>Varun Singh, a software engineer at IBM's Wats...</td>\n",
       "      <td>Redis and MongoDB in the biomedical domain</td>\n",
       "      <td>Live</td>\n",
       "      <td>1021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1027</th>\n",
       "      <td>Skip navigation Sign in SearchLoading...\\r\\n\\r...</td>\n",
       "      <td>This video shows you how to create and adminis...</td>\n",
       "      <td>Create and administer a data catalog using IBM...</td>\n",
       "      <td>Live</td>\n",
       "      <td>1022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1028</th>\n",
       "      <td>Compose The Compose logo Articles Sign in Free...</td>\n",
       "      <td>With the latest 0.2.1 version of Transporter, ...</td>\n",
       "      <td>How to move data with Compose Transporter - Fr...</td>\n",
       "      <td>Live</td>\n",
       "      <td>1023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1029</th>\n",
       "      <td>Follow Sign in / Sign up * Home\\r\\n * About In...</td>\n",
       "      <td>Audio super-resolution aims to reconstruct a h...</td>\n",
       "      <td>Using Deep Learning to Reconstruct High-Resolu...</td>\n",
       "      <td>Live</td>\n",
       "      <td>1024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1030</th>\n",
       "      <td>Homepage Follow Sign in / Sign up Homepage * H...</td>\n",
       "      <td>Since then, this metric has been ubiquitously ...</td>\n",
       "      <td>Data tidying in Data Science Experience</td>\n",
       "      <td>Live</td>\n",
       "      <td>1025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1031</th>\n",
       "      <td>Develop in the cloud at the click of a button!...</td>\n",
       "      <td>Build a word game app and see how to manage an...</td>\n",
       "      <td>Build a simple word game app using Cloudant on...</td>\n",
       "      <td>Live</td>\n",
       "      <td>1026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1032</th>\n",
       "      <td>BLAZINGLY FAST GEOSPATIAL QUERIES WITH REDIS\\r...</td>\n",
       "      <td>Use Redis and and Python scripts to speed your...</td>\n",
       "      <td>Blazingly Fast Geospatial Queries with Redis</td>\n",
       "      <td>Live</td>\n",
       "      <td>1027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1033</th>\n",
       "      <td>Blog Home Dataquest.io Learn Data Science in Y...</td>\n",
       "      <td>In this post, you’ll learn to query, update, a...</td>\n",
       "      <td>Working with SQLite Databases using Python and...</td>\n",
       "      <td>Live</td>\n",
       "      <td>1028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1034</th>\n",
       "      <td>DATALAYER: MANAGING (OR NOT) THE DATA IN IMMUT...</td>\n",
       "      <td>Adron Hall of Thrashing Code and Home Depot, t...</td>\n",
       "      <td>DataLayer Conference: Managing (or not) the Da...</td>\n",
       "      <td>Live</td>\n",
       "      <td>1029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1035</th>\n",
       "      <td>Skip to contentWin-Vector Blog\\r\\n\\r\\nThe Win-...</td>\n",
       "      <td>Describes the use of Laplace noise in machine ...</td>\n",
       "      <td>Laplace noising versus simulated out of sample...</td>\n",
       "      <td>Live</td>\n",
       "      <td>1030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1036</th>\n",
       "      <td>This work is licensed under a Creative Commons...</td>\n",
       "      <td>A full guide to Elasticsearch, the real-time d...</td>\n",
       "      <td>The Definitive Guide</td>\n",
       "      <td>Live</td>\n",
       "      <td>1031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1037</th>\n",
       "      <td>NaN</td>\n",
       "      <td>See how quick and easy it is to set up a dashD...</td>\n",
       "      <td>Get started with dashDB on Bluemix</td>\n",
       "      <td>Live</td>\n",
       "      <td>1032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1038</th>\n",
       "      <td>The relational database has been the dominant ...</td>\n",
       "      <td>The relational database has been the dominant ...</td>\n",
       "      <td>The Many Flavors of NoSQL at That Conference</td>\n",
       "      <td>Live</td>\n",
       "      <td>1033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1039</th>\n",
       "      <td>Skip to main content IBM developerWorks / Deve...</td>\n",
       "      <td>Building your first data warehouse doesn’t hav...</td>\n",
       "      <td>Your First Data Warehouse Is Easy. Meet the ODS.</td>\n",
       "      <td>Live</td>\n",
       "      <td>1034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1040</th>\n",
       "      <td>Skip to contentDinesh Nirmal's Blog\\r\\n\\r\\nA b...</td>\n",
       "      <td>In my last blog “Business differentiation thro...</td>\n",
       "      <td>Machine Learning for the Enterprise.</td>\n",
       "      <td>Live</td>\n",
       "      <td>1035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1041</th>\n",
       "      <td>Compose The Compose logo Articles Sign in Free...</td>\n",
       "      <td>MongoDB's aggregation pipeline makes finding d...</td>\n",
       "      <td>Finding Duplicate Documents in MongoDB</td>\n",
       "      <td>Live</td>\n",
       "      <td>1036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1042</th>\n",
       "      <td>Glynn Bird Blocked Unblock Follow Following De...</td>\n",
       "      <td>Which write API endpoint is the right write ca...</td>\n",
       "      <td>Piecemeal, Bulk, or Batch? – IBM Watson Data L...</td>\n",
       "      <td>Live</td>\n",
       "      <td>1037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1043</th>\n",
       "      <td>MENU\\r\\nClose\\r\\nSubscribe SubscribeREDUCING O...</td>\n",
       "      <td>Nothing spoils a plot like (too much) data.</td>\n",
       "      <td>Reducing overplotting in scatterplots</td>\n",
       "      <td>Live</td>\n",
       "      <td>1038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1044</th>\n",
       "      <td>Homepage IBM Watson Data Lab Follow Sign in / ...</td>\n",
       "      <td>Getting started with custom visualizations, si...</td>\n",
       "      <td>You Too Can Make Magic (in Jupyter Notebooks w...</td>\n",
       "      <td>Live</td>\n",
       "      <td>1039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1045</th>\n",
       "      <td>Although it is built around a JavaScript engin...</td>\n",
       "      <td>Although it is built around a JavaScript engin...</td>\n",
       "      <td>How I Stopped Worrying &amp; Learned to Love the M...</td>\n",
       "      <td>Live</td>\n",
       "      <td>1040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1046</th>\n",
       "      <td>Margriet Groenendijk Blocked Unblock Follow Fo...</td>\n",
       "      <td>Last week I attended the GeoPython conference ...</td>\n",
       "      <td>Mapping All the Things with Python – IBM Watso...</td>\n",
       "      <td>Live</td>\n",
       "      <td>1041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1047</th>\n",
       "      <td>Homepage Follow Sign in / Sign up Homepage * H...</td>\n",
       "      <td>In this post, we will go through how to read a...</td>\n",
       "      <td>Use IBM Data Science Experience to Read and Wr...</td>\n",
       "      <td>Live</td>\n",
       "      <td>1042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048</th>\n",
       "      <td>Homepage Follow Sign in Get started * Home\\r\\n...</td>\n",
       "      <td>As more devices become internet enabled, harne...</td>\n",
       "      <td>Use IoT data in Streams Designer for billing a...</td>\n",
       "      <td>Live</td>\n",
       "      <td>1043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1049</th>\n",
       "      <td>* \\r\\n * \\r\\n * \\r\\n * \\r\\n * \\r\\n * \\r\\n * \\r...</td>\n",
       "      <td>Continuing my previous work on exploring Arlin...</td>\n",
       "      <td>Mapping Points with Folium</td>\n",
       "      <td>Live</td>\n",
       "      <td>1044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1050</th>\n",
       "      <td>lA SPEED GUIDE TO REDIS LUA SCRIPTING\\r\\nShare...</td>\n",
       "      <td>Lua is a compact language which can be embedde...</td>\n",
       "      <td>A Speed Guide To Redis Lua Scripting</td>\n",
       "      <td>Live</td>\n",
       "      <td>1045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1051</th>\n",
       "      <td>PouchDB-find is a new API and syntax that allo...</td>\n",
       "      <td>PouchDB uses MapReduce as its default search m...</td>\n",
       "      <td>A look under the covers of PouchDB-find</td>\n",
       "      <td>Live</td>\n",
       "      <td>1046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1052</th>\n",
       "      <td>We compare discriminative and generative learn...</td>\n",
       "      <td>We compare discriminative and generative learn...</td>\n",
       "      <td>A comparison of logistic regression and naive ...</td>\n",
       "      <td>Live</td>\n",
       "      <td>1047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1053</th>\n",
       "      <td>Essays about data, building products and boots...</td>\n",
       "      <td>In order to demystify some of the magic behind...</td>\n",
       "      <td>What I Learned Implementing a Classifier from ...</td>\n",
       "      <td>Live</td>\n",
       "      <td>1048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1054</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Learn how to use IBM dashDB as data store for ...</td>\n",
       "      <td>Use dashDB with Spark</td>\n",
       "      <td>Live</td>\n",
       "      <td>1049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1055</th>\n",
       "      <td>Homepage Follow Sign in / Sign up Homepage * H...</td>\n",
       "      <td>Once you get used to developing in a Notebook ...</td>\n",
       "      <td>Jupyter Notebooks with Scala, Python, or R Ker...</td>\n",
       "      <td>Live</td>\n",
       "      <td>1050</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1051 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               doc_body  \\\n",
       "0     Skip navigation Sign in SearchLoading...\\r\\n\\r...   \n",
       "1     No Free Hunch Navigation * kaggle.com\\r\\n\\r\\n ...   \n",
       "2     ☰ * Login\\r\\n * Sign Up\\r\\n\\r\\n * Learning Pat...   \n",
       "3     DATALAYER: HIGH THROUGHPUT, LOW LATENCY AT SCA...   \n",
       "4     Skip navigation Sign in SearchLoading...\\r\\n\\r...   \n",
       "5     Compose is all about immediacy. You want a new...   \n",
       "6     UPGRADING YOUR POSTGRESQL TO 9.5Share on Twitt...   \n",
       "7     Follow Sign in / Sign up 135 8 * Share\\r\\n * 1...   \n",
       "8     * Host\\r\\n * Competitions\\r\\n * Datasets\\r\\n *...   \n",
       "9     THE GRADIENT FLOW\\r\\nDATA / TECHNOLOGY / CULTU...   \n",
       "10    OFFLINE-FIRST IOS APPS WITH SWIFT & PART 1: TH...   \n",
       "11    Warehousing data from Cloudant to dashDB great...   \n",
       "12    Skip to main content IBM developerWorks / Deve...   \n",
       "13    Maureen McElaney Blocked Unblock Follow Follow...   \n",
       "14    Raj Singh Blocked Unblock Follow Following Dev...   \n",
       "15    * Home\\r\\n * Community\\r\\n * Projects\\r\\n * Bl...   \n",
       "16    * Home\\r\\n * Research\\r\\n * Partnerships and C...   \n",
       "17    Enterprise Pricing Articles Sign in Free 30-Da...   \n",
       "18    Homepage Follow Sign in / Sign up * Home\\r\\n *...   \n",
       "19    METRICS MAVEN: MODE D'EMPLOI - FINDING THE MOD...   \n",
       "20    Homepage Follow Sign in / Sign up Homepage * H...   \n",
       "21    Raj Singh Blocked Unblock Follow Following Dev...   \n",
       "22    IMPORTING JSON DOCUMENTS WITH NOSQLIMPORT\\r\\nG...   \n",
       "23    This video shows you how to build and query a ...   \n",
       "24    THE CONVERSATIONAL INTERFACE IS THE NEW PARADI...   \n",
       "25    Skip navigation Upload Sign in SearchLoading.....   \n",
       "26    GOOGLE RESEARCH BLOG The latest news from Rese...   \n",
       "27    Skip navigation Upload Sign in SearchLoading.....   \n",
       "28    ACCESS DENIED\\r\\nSadly, your client does not s...   \n",
       "29    Homepage Follow Sign in / Sign up Homepage * H...   \n",
       "...                                                 ...   \n",
       "1026  Enterprise Pricing Articles Sign in Free 30-Da...   \n",
       "1027  Skip navigation Sign in SearchLoading...\\r\\n\\r...   \n",
       "1028  Compose The Compose logo Articles Sign in Free...   \n",
       "1029  Follow Sign in / Sign up * Home\\r\\n * About In...   \n",
       "1030  Homepage Follow Sign in / Sign up Homepage * H...   \n",
       "1031  Develop in the cloud at the click of a button!...   \n",
       "1032  BLAZINGLY FAST GEOSPATIAL QUERIES WITH REDIS\\r...   \n",
       "1033  Blog Home Dataquest.io Learn Data Science in Y...   \n",
       "1034  DATALAYER: MANAGING (OR NOT) THE DATA IN IMMUT...   \n",
       "1035  Skip to contentWin-Vector Blog\\r\\n\\r\\nThe Win-...   \n",
       "1036  This work is licensed under a Creative Commons...   \n",
       "1037                                                NaN   \n",
       "1038  The relational database has been the dominant ...   \n",
       "1039  Skip to main content IBM developerWorks / Deve...   \n",
       "1040  Skip to contentDinesh Nirmal's Blog\\r\\n\\r\\nA b...   \n",
       "1041  Compose The Compose logo Articles Sign in Free...   \n",
       "1042  Glynn Bird Blocked Unblock Follow Following De...   \n",
       "1043  MENU\\r\\nClose\\r\\nSubscribe SubscribeREDUCING O...   \n",
       "1044  Homepage IBM Watson Data Lab Follow Sign in / ...   \n",
       "1045  Although it is built around a JavaScript engin...   \n",
       "1046  Margriet Groenendijk Blocked Unblock Follow Fo...   \n",
       "1047  Homepage Follow Sign in / Sign up Homepage * H...   \n",
       "1048  Homepage Follow Sign in Get started * Home\\r\\n...   \n",
       "1049  * \\r\\n * \\r\\n * \\r\\n * \\r\\n * \\r\\n * \\r\\n * \\r...   \n",
       "1050  lA SPEED GUIDE TO REDIS LUA SCRIPTING\\r\\nShare...   \n",
       "1051  PouchDB-find is a new API and syntax that allo...   \n",
       "1052  We compare discriminative and generative learn...   \n",
       "1053  Essays about data, building products and boots...   \n",
       "1054                                                NaN   \n",
       "1055  Homepage Follow Sign in / Sign up Homepage * H...   \n",
       "\n",
       "                                        doc_description  \\\n",
       "0     Detect bad readings in real time using Python ...   \n",
       "1     See the forest, see the trees. Here lies the c...   \n",
       "2     Here’s this week’s news in Data Science and Bi...   \n",
       "3     Learn how distributed DBs solve the problem of...   \n",
       "4     This video demonstrates the power of IBM DataS...   \n",
       "5              Using Compose's PostgreSQL data browser.   \n",
       "6     Upgrading your PostgreSQL deployment to versio...   \n",
       "7     For a company like Slack that strives to be as...   \n",
       "8     Kaggle is your home for data science. Learn ne...   \n",
       "9     [A version of this post appears on the O’Reill...   \n",
       "10    Apple's sample app, Food Tracker, taught you i...   \n",
       "11    Replicating data to a relational dashDB databa...   \n",
       "12    This recipe showcases how one can analyze the ...   \n",
       "13    There’s a reason you’ve been hearing a lot abo...   \n",
       "14    Who are those people lurking behind the statis...   \n",
       "15    Early methods to integrate machine learning us...   \n",
       "16    The performance of supervised predictive model...   \n",
       "17    We've always considered MySQL as a potential C...   \n",
       "18    It has never been easier to build AI or machin...   \n",
       "19    In our Metrics Maven series, Compose's data sc...   \n",
       "20    It is often useful to use RStudio for one piec...   \n",
       "21    You’re doing your data a disservice if you don...   \n",
       "22    Introducing nosqlimport, an npm module to help...   \n",
       "23    This video shows you how to build and query a ...   \n",
       "24    Botkit provides a simple framework to handle t...   \n",
       "25    Want to learn more about how we created the Da...   \n",
       "26    Much of driving is spent either stuck in traff...   \n",
       "27    This talk assumes you have a basic understandi...   \n",
       "28    In this paper, we propose gcForest, a decision...   \n",
       "29    I’m very happy and proud to announce that IBM ...   \n",
       "...                                                 ...   \n",
       "1026  Varun Singh, a software engineer at IBM's Wats...   \n",
       "1027  This video shows you how to create and adminis...   \n",
       "1028  With the latest 0.2.1 version of Transporter, ...   \n",
       "1029  Audio super-resolution aims to reconstruct a h...   \n",
       "1030  Since then, this metric has been ubiquitously ...   \n",
       "1031  Build a word game app and see how to manage an...   \n",
       "1032  Use Redis and and Python scripts to speed your...   \n",
       "1033  In this post, you’ll learn to query, update, a...   \n",
       "1034  Adron Hall of Thrashing Code and Home Depot, t...   \n",
       "1035  Describes the use of Laplace noise in machine ...   \n",
       "1036  A full guide to Elasticsearch, the real-time d...   \n",
       "1037  See how quick and easy it is to set up a dashD...   \n",
       "1038  The relational database has been the dominant ...   \n",
       "1039  Building your first data warehouse doesn’t hav...   \n",
       "1040  In my last blog “Business differentiation thro...   \n",
       "1041  MongoDB's aggregation pipeline makes finding d...   \n",
       "1042  Which write API endpoint is the right write ca...   \n",
       "1043        Nothing spoils a plot like (too much) data.   \n",
       "1044  Getting started with custom visualizations, si...   \n",
       "1045  Although it is built around a JavaScript engin...   \n",
       "1046  Last week I attended the GeoPython conference ...   \n",
       "1047  In this post, we will go through how to read a...   \n",
       "1048  As more devices become internet enabled, harne...   \n",
       "1049  Continuing my previous work on exploring Arlin...   \n",
       "1050  Lua is a compact language which can be embedde...   \n",
       "1051  PouchDB uses MapReduce as its default search m...   \n",
       "1052  We compare discriminative and generative learn...   \n",
       "1053  In order to demystify some of the magic behind...   \n",
       "1054  Learn how to use IBM dashDB as data store for ...   \n",
       "1055  Once you get used to developing in a Notebook ...   \n",
       "\n",
       "                                          doc_full_name doc_status  article_id  \n",
       "0     Detect Malfunctioning IoT Sensors with Streami...       Live           0  \n",
       "1     Communicating data science: A guide to present...       Live           1  \n",
       "2            This Week in Data Science (April 18, 2017)       Live           2  \n",
       "3     DataLayer Conference: Boost the performance of...       Live           3  \n",
       "4         Analyze NY Restaurant data using Spark in DSX       Live           4  \n",
       "5                 Browsing PostgreSQL Data with Compose       Live           5  \n",
       "6                      Upgrading your PostgreSQL to 9.5       Live           6  \n",
       "7                               Data Wrangling at Slack       Live           7  \n",
       "8                                Data Science Bowl 2017       Live           8  \n",
       "9     Using Apache Spark to predict attack vectors a...       Live           9  \n",
       "10    Offline-First iOS Apps with Swift & Cloudant S...       Live          10  \n",
       "11                        Warehousing GeoJSON documents       Live          11  \n",
       "12    Timeseries Data Analysis of IoT events by usin...       Live          12  \n",
       "13    Bridging the Gap Between Python and Scala Jupy...       Live          13  \n",
       "14    Got zip code data? Prep it for analytics. – IB...       Live          14  \n",
       "15    Apache Spark™ 2.0: Extend Structured Streaming...       Live          15  \n",
       "16    Higher-order Logistic Regression for Large Dat...       Live          16  \n",
       "17                        Compose for MySQL now for you       Live          17  \n",
       "18    The Greatest Public Datasets for AI – Startup ...       Live          18  \n",
       "19                       Finding the Mode in PostgreSQL       Live          19  \n",
       "20    Working interactively with RStudio and noteboo...       Live          20  \n",
       "21    Mapping for Data Science with PixieDust and Ma...       Live          21  \n",
       "22             Move CSVs into different JSON doc stores       Live          22  \n",
       "23    Tutorial: How to build and query a Cloudant ge...       Live          23  \n",
       "24     The Conversational Interface is the New Paradigm       Live          24  \n",
       "25                 Creating the Data Science Experience       Live          25  \n",
       "26    Using Machine Learning to predict parking diff...       Live          26  \n",
       "27            Getting The Best Performance With PySpark       Live          27  \n",
       "28    Deep Forest: Towards An Alternative to Deep Ne...       Live          28  \n",
       "29                         Experience IoT with Coursera       Live          29  \n",
       "...                                                 ...        ...         ...  \n",
       "1026         Redis and MongoDB in the biomedical domain       Live        1021  \n",
       "1027  Create and administer a data catalog using IBM...       Live        1022  \n",
       "1028  How to move data with Compose Transporter - Fr...       Live        1023  \n",
       "1029  Using Deep Learning to Reconstruct High-Resolu...       Live        1024  \n",
       "1030            Data tidying in Data Science Experience       Live        1025  \n",
       "1031  Build a simple word game app using Cloudant on...       Live        1026  \n",
       "1032       Blazingly Fast Geospatial Queries with Redis       Live        1027  \n",
       "1033  Working with SQLite Databases using Python and...       Live        1028  \n",
       "1034  DataLayer Conference: Managing (or not) the Da...       Live        1029  \n",
       "1035  Laplace noising versus simulated out of sample...       Live        1030  \n",
       "1036                               The Definitive Guide       Live        1031  \n",
       "1037                 Get started with dashDB on Bluemix       Live        1032  \n",
       "1038       The Many Flavors of NoSQL at That Conference       Live        1033  \n",
       "1039   Your First Data Warehouse Is Easy. Meet the ODS.       Live        1034  \n",
       "1040               Machine Learning for the Enterprise.       Live        1035  \n",
       "1041             Finding Duplicate Documents in MongoDB       Live        1036  \n",
       "1042  Piecemeal, Bulk, or Batch? – IBM Watson Data L...       Live        1037  \n",
       "1043              Reducing overplotting in scatterplots       Live        1038  \n",
       "1044  You Too Can Make Magic (in Jupyter Notebooks w...       Live        1039  \n",
       "1045  How I Stopped Worrying & Learned to Love the M...       Live        1040  \n",
       "1046  Mapping All the Things with Python – IBM Watso...       Live        1041  \n",
       "1047  Use IBM Data Science Experience to Read and Wr...       Live        1042  \n",
       "1048  Use IoT data in Streams Designer for billing a...       Live        1043  \n",
       "1049                         Mapping Points with Folium       Live        1044  \n",
       "1050               A Speed Guide To Redis Lua Scripting       Live        1045  \n",
       "1051            A look under the covers of PouchDB-find       Live        1046  \n",
       "1052  A comparison of logistic regression and naive ...       Live        1047  \n",
       "1053  What I Learned Implementing a Classifier from ...       Live        1048  \n",
       "1054                              Use dashDB with Spark       Live        1049  \n",
       "1055  Jupyter Notebooks with Scala, Python, or R Ker...       Live        1050  \n",
       "\n",
       "[1051 rows x 5 columns]"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>article_id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1430.0</th>\n",
       "      <td>using pixiedust for fast, flexible, and easier...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1314.0</th>\n",
       "      <td>healthcare python streaming application demo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1429.0</th>\n",
       "      <td>use deep learning for image classification</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1338.0</th>\n",
       "      <td>ml optimization using cognitive assistant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1276.0</th>\n",
       "      <td>deploy your python model as a restful api</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1432.0</th>\n",
       "      <td>visualize data with the matplotlib library</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>593.0</th>\n",
       "      <td>upload files to ibm data science experience us...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1185.0</th>\n",
       "      <td>classify tumors with machine learning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>993.0</th>\n",
       "      <td>configuring the apache spark sql context</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14.0</th>\n",
       "      <td>got zip code data? prep it for analytics. – ib...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1395.0</th>\n",
       "      <td>the unit commitment problem</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1170.0</th>\n",
       "      <td>apache spark lab, part 1: basic concepts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>542.0</th>\n",
       "      <td>getting started with python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12.0</th>\n",
       "      <td>timeseries data analysis of iot events by usin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173.0</th>\n",
       "      <td>10 must attend data science, ml and ai confere...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1320.0</th>\n",
       "      <td>housing (2015): united states demographic meas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1052.0</th>\n",
       "      <td>access db2 warehouse on cloud and db2 with python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1393.0</th>\n",
       "      <td>the nurse assignment problem</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362.0</th>\n",
       "      <td>dsx: hybrid mode</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1364.0</th>\n",
       "      <td>predicting churn with the spss random tree alg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194.0</th>\n",
       "      <td>data science for real-time streaming analytics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1162.0</th>\n",
       "      <td>analyze energy consumption in buildings</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1324.0</th>\n",
       "      <td>ibm watson facebook posts for 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>460.0</th>\n",
       "      <td>web picks - dataminingapps</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1431.0</th>\n",
       "      <td>visualize car data with brunel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189.0</th>\n",
       "      <td>common excel tasks demonstrated in pandas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1164.0</th>\n",
       "      <td>analyze open data sets with pandas dataframes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1427.0</th>\n",
       "      <td>use xgboost, scikit-learn &amp; ibm watson machine...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1332.0</th>\n",
       "      <td>intents &amp; examples for ibm watson conversation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1172.0</th>\n",
       "      <td>apache spark lab, part 3: machine learning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1167.0</th>\n",
       "      <td>annual % inflation by country</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384.0</th>\n",
       "      <td>continuous learning on watson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319.0</th>\n",
       "      <td>using shell scripts to control data flows crea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363.0</th>\n",
       "      <td>66855    migration from ibm bluemix data conne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>446.0</th>\n",
       "      <td>what’s new in data refinery?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>870.0</th>\n",
       "      <td>stacking multiple custom models in watson visu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1390.0</th>\n",
       "      <td>style transfer experiments with watson machine...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1235.0</th>\n",
       "      <td>country statistics: merchant marine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1303.0</th>\n",
       "      <td>geographic coordinates of world locations</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>675.0</th>\n",
       "      <td>webinar: april 11 - thinking inside the box: y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297.0</th>\n",
       "      <td>dimensionality reduction algorithms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>662.0</th>\n",
       "      <td>build deep learning architectures with neural ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1051.0</th>\n",
       "      <td>a tensorflow regression model to predict house...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1421.0</th>\n",
       "      <td>use pmml to predict iris species</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1247.0</th>\n",
       "      <td>country statistics: railways</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1086.0</th>\n",
       "      <td>airbnb data for analytics: chicago reviews</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1371.0</th>\n",
       "      <td>refugees</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1372.0</th>\n",
       "      <td>refugees, worldwide, 2003 - 2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145.0</th>\n",
       "      <td>68879    don’t throw more data at the problem!...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567.0</th>\n",
       "      <td>you could be looking at it all wrong</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1135.0</th>\n",
       "      <td>airbnb data for analytics: seattle calendar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>881.0</th>\n",
       "      <td>web picks (week of 2 october 2017)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183.0</th>\n",
       "      <td>data science expert interview: holden karau</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>655.0</th>\n",
       "      <td>create a project for watson machine learning i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1233.0</th>\n",
       "      <td>country statistics: market value of publicly t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1156.0</th>\n",
       "      <td>airbnb data for analytics: washington d.c. cal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>555.0</th>\n",
       "      <td>build a naive-bayes model with wml &amp; dsx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>708.0</th>\n",
       "      <td>load and analyze public data sets in dsx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>575.0</th>\n",
       "      <td>the new builders ep. 13: all the data that’s f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>972.0</th>\n",
       "      <td>create a project in dsx</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>714 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                        title\n",
       "article_id                                                   \n",
       "1430.0      using pixiedust for fast, flexible, and easier...\n",
       "1314.0           healthcare python streaming application demo\n",
       "1429.0             use deep learning for image classification\n",
       "1338.0              ml optimization using cognitive assistant\n",
       "1276.0              deploy your python model as a restful api\n",
       "1432.0             visualize data with the matplotlib library\n",
       "593.0       upload files to ibm data science experience us...\n",
       "1185.0                  classify tumors with machine learning\n",
       "993.0                configuring the apache spark sql context\n",
       "14.0        got zip code data? prep it for analytics. – ib...\n",
       "1395.0                            the unit commitment problem\n",
       "1170.0               apache spark lab, part 1: basic concepts\n",
       "542.0                             getting started with python\n",
       "12.0        timeseries data analysis of iot events by usin...\n",
       "173.0       10 must attend data science, ml and ai confere...\n",
       "1320.0      housing (2015): united states demographic meas...\n",
       "1052.0      access db2 warehouse on cloud and db2 with python\n",
       "1393.0                           the nurse assignment problem\n",
       "362.0                                        dsx: hybrid mode\n",
       "1364.0      predicting churn with the spss random tree alg...\n",
       "194.0          data science for real-time streaming analytics\n",
       "1162.0                analyze energy consumption in buildings\n",
       "1324.0                     ibm watson facebook posts for 2015\n",
       "460.0                              web picks - dataminingapps\n",
       "1431.0                         visualize car data with brunel\n",
       "189.0               common excel tasks demonstrated in pandas\n",
       "1164.0          analyze open data sets with pandas dataframes\n",
       "1427.0      use xgboost, scikit-learn & ibm watson machine...\n",
       "1332.0         intents & examples for ibm watson conversation\n",
       "1172.0             apache spark lab, part 3: machine learning\n",
       "...                                                       ...\n",
       "1167.0                          annual % inflation by country\n",
       "384.0                           continuous learning on watson\n",
       "319.0       using shell scripts to control data flows crea...\n",
       "363.0       66855    migration from ibm bluemix data conne...\n",
       "446.0                            what’s new in data refinery?\n",
       "870.0       stacking multiple custom models in watson visu...\n",
       "1390.0      style transfer experiments with watson machine...\n",
       "1235.0                    country statistics: merchant marine\n",
       "1303.0              geographic coordinates of world locations\n",
       "675.0       webinar: april 11 - thinking inside the box: y...\n",
       "297.0                     dimensionality reduction algorithms\n",
       "662.0       build deep learning architectures with neural ...\n",
       "1051.0      a tensorflow regression model to predict house...\n",
       "1421.0                       use pmml to predict iris species\n",
       "1247.0                           country statistics: railways\n",
       "1086.0             airbnb data for analytics: chicago reviews\n",
       "1371.0                                               refugees\n",
       "1372.0                       refugees, worldwide, 2003 - 2013\n",
       "145.0       68879    don’t throw more data at the problem!...\n",
       "567.0                    you could be looking at it all wrong\n",
       "1135.0            airbnb data for analytics: seattle calendar\n",
       "881.0                      web picks (week of 2 october 2017)\n",
       "183.0             data science expert interview: holden karau\n",
       "655.0       create a project for watson machine learning i...\n",
       "1233.0      country statistics: market value of publicly t...\n",
       "1156.0      airbnb data for analytics: washington d.c. cal...\n",
       "555.0                build a naive-bayes model with wml & dsx\n",
       "708.0                load and analyze public data sets in dsx\n",
       "575.0       the new builders ep. 13: all the data that’s f...\n",
       "972.0                                 create a project in dsx\n",
       "\n",
       "[714 rows x 1 columns]"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ '1448    i ranked every intro to data science course on...\\nName: title, dtype: object',\n",
       "       'using deep learning to reconstruct high-resolution audio'], dtype=object)"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_articles.loc[['1014.0','1024.0'],:].title.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_article_names(article_ids, df=df):\n",
    "    '''\n",
    "    INPUT:\n",
    "    article_ids - (list) a list of article ids\n",
    "    df - (pandas dataframe) df as defined at the top of the notebook\n",
    "    \n",
    "    OUTPUT:\n",
    "    article_names - (list) a list of article names associated with the list of article ids \n",
    "                    (this is identified by the title column)\n",
    "    '''\n",
    "    \n",
    "    unique_articles = df[['article_id','title']].drop_duplicates() \\\n",
    "                        .assign(article_id = lambda x: x.article_id.astype(str)) \\\n",
    "                        .set_index('article_id')\n",
    "    article_names = unique_articles.loc[article_ids,:].title.values\n",
    "    \n",
    "    return article_names # Return the article names associated with list of article ids\n",
    "\n",
    "\n",
    "def get_user_articles(user_id, user_item=user_item):\n",
    "    '''\n",
    "    INPUT:\n",
    "    user_id - (int) a user id\n",
    "    user_item - (pandas dataframe) matrix of users by articles: \n",
    "                1's when a user has interacted with an article, 0 otherwise\n",
    "    \n",
    "    OUTPUT:\n",
    "    article_ids - (list) a list of the article ids seen by the user\n",
    "    article_names - (list) a list of article names associated with the list of article ids \n",
    "                    (this is identified by the doc_full_name column in df_content)\n",
    "    \n",
    "    Description:\n",
    "    Provides a list of the article_ids and article titles that have been seen by a user\n",
    "    '''\n",
    "    user_row = user_item.iloc[user_id - 1,:]\n",
    "    article_ids = user_row[user_row > 0].keys().astype(str).values\n",
    "    article_names = get_article_names(article_ids)\n",
    "    \n",
    "    return article_ids, article_names # return the ids and names\n",
    "\n",
    "\n",
    "def user_user_recs(user_id, m=10):\n",
    "    '''\n",
    "    INPUT:\n",
    "    user_id - (int) a user id\n",
    "    m - (int) the number of recommendations you want for the user\n",
    "    \n",
    "    OUTPUT:\n",
    "    recs - (list) a list of recommendations for the user\n",
    "    \n",
    "    Description:\n",
    "    Loops through the users based on closeness to the input user_id\n",
    "    For each user - finds articles the user hasn't seen before and provides them as recs\n",
    "    Does this until m recommendations are found\n",
    "    \n",
    "    Notes:\n",
    "    Users who are the same closeness are chosen arbitrarily as the 'next' user\n",
    "    \n",
    "    For the user where the number of recommended articles starts below m \n",
    "    and ends exceeding m, the last items are chosen arbitrarily\n",
    "    \n",
    "    '''\n",
    "    recs = np.array([])\n",
    "    user_seen_ids = get_user_articles(user_id)[0]\n",
    "    most_similar_users = find_similar_users(user_id)\n",
    "    for similar_user in most_similar_users:\n",
    "        sim_user_seen_ids = get_user_articles(similar_user)[0]\n",
    "        sim_user_recs = np.setdiff1d(sim_user_seen_ids,user_seen_ids,assume_unique=True)\n",
    "        recs = np.unique(np.concatenate([recs,sim_user_recs]))\n",
    "    \n",
    "        if (len(recs) > m):\n",
    "            recs = recs[:m]\n",
    "            break\n",
    "    \n",
    "    return recs # return your recommendations for this user_id    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['recommender systems: approaches & algorithms',\n",
       "       '1448    i ranked every intro to data science course on...\\nName: title, dtype: object',\n",
       "       'data tidying in data science experience',\n",
       "       'a tensorflow regression model to predict house values',\n",
       "       '520    using notebooks with pixiedust for fast, flexi...\\nName: title, dtype: object',\n",
       "       'airbnb data for analytics: mallorca reviews',\n",
       "       'airbnb data for analytics: vancouver listings',\n",
       "       'analyze facebook data using ibm watson and watson studio',\n",
       "       'analyze accident reports on amazon emr spark',\n",
       "       'analyze energy consumption in buildings'], dtype=object)"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check Results\n",
    "get_article_names(user_user_recs(1, 10)) # Return 10 recommendations for user 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If this is all you see, you passed all of our tests!  Nice job!\n"
     ]
    }
   ],
   "source": [
    "# Test your functions here - No need to change this code - just run this cell\n",
    "assert set(get_article_names(['1024.0', '1176.0', '1305.0', '1314.0', '1422.0', '1427.0'])) == set(['using deep learning to reconstruct high-resolution audio', 'build a python app on the streaming analytics service', 'gosales transactions for naive bayes model', 'healthcare python streaming application demo', 'use r dataframes & ibm watson natural language understanding', 'use xgboost, scikit-learn & ibm watson machine learning apis']), \"Oops! Your the get_article_names function doesn't work quite how we expect.\"\n",
    "assert set(get_article_names(['1320.0', '232.0', '844.0'])) == set(['housing (2015): united states demographic measures','self-service data preparation with ibm data refinery','use the cloudant-spark connector in python notebook']), \"Oops! Your the get_article_names function doesn't work quite how we expect.\"\n",
    "assert set(get_user_articles(20)[0]) == set(['1320.0', '232.0', '844.0'])\n",
    "assert set(get_user_articles(20)[1]) == set(['housing (2015): united states demographic measures', 'self-service data preparation with ibm data refinery','use the cloudant-spark connector in python notebook'])\n",
    "assert set(get_user_articles(2)[0]) == set(['1024.0', '1176.0', '1305.0', '1314.0', '1422.0', '1427.0'])\n",
    "assert set(get_user_articles(2)[1]) == set(['using deep learning to reconstruct high-resolution audio', 'build a python app on the streaming analytics service', 'gosales transactions for naive bayes model', 'healthcare python streaming application demo', 'use r dataframes & ibm watson natural language understanding', 'use xgboost, scikit-learn & ibm watson machine learning apis'])\n",
    "print(\"If this is all you see, you passed all of our tests!  Nice job!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`4.` Now we are going to improve the consistency of the **user_user_recs** function from above.  \n",
    "\n",
    "* Instead of arbitrarily choosing when we obtain users who are all the same closeness to a given user - choose the users that have the most total article interactions before choosing those with fewer article interactions.\n",
    "\n",
    "\n",
    "* Instead of arbitrarily choosing articles from the user where the number of recommended articles starts below m and ends exceeding m, choose articles with the articles with the most total interactions before choosing those with fewer total interactions. This ranking should be  what would be obtained from the **top_articles** function you wrote earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 36.,   2.,   6., ...,   0.,   0.,   0.])"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users_similarity = np.dot(user_item.iloc[0,:],user_item.T)\n",
    "users_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([   1,    2,    3,    4,    5,    6,    7,    8,    9,   10,\n",
       "            ...\n",
       "            5140, 5141, 5142, 5143, 5144, 5145, 5146, 5147, 5148, 5149],\n",
       "           dtype='int64', name='user_id', length=5149)"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_item.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>title</th>\n",
       "      <th>user_id</th>\n",
       "      <th>interaction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1430.0</td>\n",
       "      <td>using pixiedust for fast, flexible, and easier...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1314.0</td>\n",
       "      <td>healthcare python streaming application demo</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1429.0</td>\n",
       "      <td>use deep learning for image classification</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1338.0</td>\n",
       "      <td>ml optimization using cognitive assistant</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1276.0</td>\n",
       "      <td>deploy your python model as a restful api</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   article_id                                              title  user_id  \\\n",
       "0      1430.0  using pixiedust for fast, flexible, and easier...        1   \n",
       "1      1314.0       healthcare python streaming application demo        2   \n",
       "2      1429.0         use deep learning for image classification        3   \n",
       "3      1338.0          ml optimization using cognitive assistant        4   \n",
       "4      1276.0          deploy your python model as a restful api        5   \n",
       "\n",
       "   interaction  \n",
       "0            1  \n",
       "1            1  \n",
       "2            1  \n",
       "3            1  \n",
       "4            1  "
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>neighbor_id</th>\n",
       "      <th>num_interactions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   neighbor_id  num_interactions\n",
       "0            1                47\n",
       "1            2                 6\n",
       "2            3                82\n",
       "3            4                45\n",
       "4            5                 5"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users_interactions = df.groupby('user_id').interaction.sum().reset_index() \\\n",
    ".rename(index=str, columns={'interaction':'num_interactions','user_id':'neighbor_id'})\n",
    "users_interactions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_id = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>neighbor_id</th>\n",
       "      <th>similarity</th>\n",
       "      <th>num_interactions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3932</th>\n",
       "      <td>3933</td>\n",
       "      <td>35.0</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>17.0</td>\n",
       "      <td>364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3781</th>\n",
       "      <td>3782</td>\n",
       "      <td>17.0</td>\n",
       "      <td>363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>203</td>\n",
       "      <td>15.0</td>\n",
       "      <td>160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4458</th>\n",
       "      <td>4459</td>\n",
       "      <td>15.0</td>\n",
       "      <td>158</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      neighbor_id  similarity  num_interactions\n",
       "3932         3933        35.0                45\n",
       "22             23        17.0               364\n",
       "3781         3782        17.0               363\n",
       "202           203        15.0               160\n",
       "4458         4459        15.0               158"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neighbors_df = pd.DataFrame({'neighbor_id' : user_item.index, \n",
    "              'similarity' : users_similarity}) \\\n",
    "    .merge(users_interactions, on='neighbor_id') \\\n",
    "    .sort_values(['similarity','num_interactions'], ascending=False) \\\n",
    "    .query('neighbor_id != @user_id')\n",
    "neighbors_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "interactions_per_article = df.groupby(['article_id','title']).user_id.count().reset_index(name='num_interactions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>title</th>\n",
       "      <th>num_interactions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>detect malfunctioning iot sensors with streami...</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>this week in data science (april 18, 2017)</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.0</td>\n",
       "      <td>analyze ny restaurant data using spark in dsx</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8.0</td>\n",
       "      <td>data science bowl 2017</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9.0</td>\n",
       "      <td>3992    using apache spark to predict attack v...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   article_id                                              title  \\\n",
       "0         0.0  detect malfunctioning iot sensors with streami...   \n",
       "1         2.0         this week in data science (april 18, 2017)   \n",
       "2         4.0      analyze ny restaurant data using spark in dsx   \n",
       "3         8.0                             data science bowl 2017   \n",
       "4         9.0  3992    using apache spark to predict attack v...   \n",
       "\n",
       "   num_interactions  \n",
       "0                14  \n",
       "1                58  \n",
       "2                13  \n",
       "3                85  \n",
       "4                10  "
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interactions_per_article.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "article_id          float64\n",
       "title                object\n",
       "num_interactions      int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interactions_per_article.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_article_ids = [0,2,4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>title</th>\n",
       "      <th>num_interactions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>this week in data science (april 18, 2017)</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>detect malfunctioning iot sensors with streami...</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.0</td>\n",
       "      <td>analyze ny restaurant data using spark in dsx</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   article_id                                              title  \\\n",
       "1         2.0         this week in data science (april 18, 2017)   \n",
       "0         0.0  detect malfunctioning iot sensors with streami...   \n",
       "2         4.0      analyze ny restaurant data using spark in dsx   \n",
       "\n",
       "   num_interactions  \n",
       "1                58  \n",
       "0                14  \n",
       "2                13  "
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interactions_per_article[interactions_per_article['article_id'].isin(test_article_ids)].sort_values('num_interactions', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_sorted_users(user_id, df=df, user_item=user_item):\n",
    "    '''\n",
    "    INPUT:\n",
    "    user_id - (int)\n",
    "    df - (pandas dataframe) df as defined at the top of the notebook \n",
    "    user_item - (pandas dataframe) matrix of users by articles: \n",
    "            1's when a user has interacted with an article, 0 otherwise\n",
    "    \n",
    "            \n",
    "    OUTPUT:\n",
    "    neighbors_df - (pandas dataframe) a dataframe with:\n",
    "                    neighbor_id - is a neighbor user_id\n",
    "                    similarity - measure of the similarity of each user to the provided user_id\n",
    "                    num_interactions - the number of articles viewed by the user - if a u\n",
    "                    \n",
    "    Other Details - sort the neighbors_df by the similarity and then by number of interactions where \n",
    "                    highest of each is higher in the dataframe\n",
    "     \n",
    "    '''\n",
    "    # compute similarity of each user to the provided user\n",
    "    neighbors_ids = user_item.index\n",
    "    users_similarity = np.dot(user_item.iloc[user_id-1,:],user_item.T)\n",
    "    users_interactions = df.groupby('user_id').interaction.sum() \\\n",
    "                            .reset_index() \\\n",
    "                            .rename(index=str, \n",
    "                                    columns={'interaction':'num_interactions',\n",
    "                                             'user_id':'neighbor_id'})\n",
    "\n",
    "    # create dataframe with neighbor ids, similarity and number of interactions\n",
    "    # sort by similarity and number of interactions\n",
    "    # remove the own user's id\n",
    "    neighbors_df = pd.DataFrame({'neighbor_id' : user_item.index, \n",
    "              'similarity' : users_similarity}) \\\n",
    "                    .merge(users_interactions, on='neighbor_id') \\\n",
    "                    .sort_values(['similarity','num_interactions'], ascending=False) \\\n",
    "                    .query('neighbor_id != @user_id') \n",
    "   \n",
    "    return neighbors_df # Return the dataframe specified in the doc_string\n",
    "\n",
    "\n",
    "def user_user_recs_part2(user_id, m=10, verbose=False):\n",
    "    '''\n",
    "    INPUT:\n",
    "    user_id - (int) a user id\n",
    "    m - (int) the number of recommendations you want for the user\n",
    "    verbose - (boolean) whether the output should be verbose (print logs)\n",
    "    \n",
    "    OUTPUT:\n",
    "    recs - (list) a list of recommendations for the user by article id\n",
    "    rec_names - (list) a list of recommendations for the user by article title\n",
    "    \n",
    "    Description:\n",
    "    Loops through the users based on closeness to the input user_id\n",
    "    For each user - finds articles the user hasn't seen before and provides them as recs\n",
    "    Does this until m recommendations are found\n",
    "    \n",
    "    Notes:\n",
    "    * Choose the users that have the most total article interactions \n",
    "    before choosing those with fewer article interactions.\n",
    "\n",
    "    * Choose articles with the articles with the most total interactions \n",
    "    before choosing those with fewer total interactions. \n",
    "   \n",
    "    '''\n",
    "    recs = np.array([])\n",
    "    interactions_per_article = df.groupby(['article_id','title']).user_id.count() \\\n",
    "                                .reset_index(name='num_interactions') \\\n",
    "                                .assign(article_id = lambda x: x.article_id.astype(str))\n",
    "    user_seen_ids = get_user_articles(user_id)[0]\n",
    "    most_similar_users = get_top_sorted_users(user_id).neighbor_id\n",
    "    for similar_user in most_similar_users:\n",
    "        if verbose: print('similar_user:', similar_user)\n",
    "        sim_user_seen_ids = get_user_articles(similar_user)[0]\n",
    "        sim_user_recs = np.setdiff1d(sim_user_seen_ids,\n",
    "                                     np.concatenate([user_seen_ids,recs]),assume_unique=True)\n",
    "        if verbose: print('sim_user_recs', sim_user_recs, sim_user_recs.shape[0])\n",
    "        ordered_sim_user_recs = interactions_per_article[interactions_per_article['article_id']\\\n",
    "                                                         .isin(sim_user_recs)]\\\n",
    "                                    .sort_values('num_interactions', ascending=False).article_id.values\n",
    "        if verbose: print('ordered_sim_user_recs', ordered_sim_user_recs, ordered_sim_user_recs.shape[0])\n",
    "        if verbose: print('recs before', recs, recs.shape[0])\n",
    "        recs = pd.unique(np.concatenate([recs,ordered_sim_user_recs]))\n",
    "        if verbose: print('recs after', recs, recs.shape[0])\n",
    "    \n",
    "        if (len(recs) > m):\n",
    "            recs = recs[:m]\n",
    "            break\n",
    "            \n",
    "    rec_names = get_article_names(recs)\n",
    "    \n",
    "    return recs, rec_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "similar_user: 170\n",
      "sim_user_recs ['12.0' '109.0' '125.0' '142.0' '164.0' '205.0' '302.0' '336.0' '362.0'\n",
      " '465.0' '555.0' '651.0' '681.0' '686.0' '730.0' '761.0' '793.0' '880.0'\n",
      " '911.0' '939.0' '981.0' '1024.0' '1085.0' '1150.0' '1151.0' '1152.0'\n",
      " '1153.0' '1154.0' '1157.0' '1160.0' '1162.0' '1163.0' '1166.0' '1170.0'\n",
      " '1172.0' '1176.0' '1276.0' '1278.0' '1296.0' '1304.0' '1324.0' '1329.0'\n",
      " '1330.0' '1331.0' '1335.0' '1336.0' '1338.0' '1346.0' '1351.0' '1354.0'\n",
      " '1356.0' '1357.0' '1360.0' '1364.0' '1367.0' '1368.0' '1386.0' '1391.0'\n",
      " '1396.0' '1407.0' '1409.0' '1410.0' '1411.0' '1420.0' '1424.0' '1426.0'\n",
      " '1427.0' '1433.0' '1444.0'] 69\n",
      "ordered_sim_user_recs ['1330.0' '1427.0' '1364.0' '1170.0' '1162.0' '1304.0' '1351.0' '1160.0'\n",
      " '1354.0' '1368.0' '1338.0' '1336.0' '1172.0' '1276.0' '1163.0' '164.0'\n",
      " '681.0' '1360.0' '1396.0' '109.0' '1296.0' '1166.0' '1391.0' '1386.0'\n",
      " '1367.0' '1324.0' '1176.0' '12.0' '730.0' '1426.0' '939.0' '1424.0'\n",
      " '981.0' '125.0' '1357.0' '1420.0' '1410.0' '651.0' '1433.0' '880.0'\n",
      " '1278.0' '336.0' '362.0' '1024.0' '205.0' '761.0' '1409.0' '911.0' '465.0'\n",
      " '1157.0' '142.0' '1411.0' '1356.0' '1329.0' '793.0' '302.0' '1331.0'\n",
      " '1150.0' '1407.0' '686.0' '1152.0' '1154.0' '1153.0' '1151.0' '1085.0'\n",
      " '1444.0' '555.0' '1346.0' '1335.0'] 69\n",
      "recs before [] 0\n",
      "recs after ['1330.0' '1427.0' '1364.0' '1170.0' '1162.0' '1304.0' '1351.0' '1160.0'\n",
      " '1354.0' '1368.0' '1338.0' '1336.0' '1172.0' '1276.0' '1163.0' '164.0'\n",
      " '681.0' '1360.0' '1396.0' '109.0' '1296.0' '1166.0' '1391.0' '1386.0'\n",
      " '1367.0' '1324.0' '1176.0' '12.0' '730.0' '1426.0' '939.0' '1424.0'\n",
      " '981.0' '125.0' '1357.0' '1420.0' '1410.0' '651.0' '1433.0' '880.0'\n",
      " '1278.0' '336.0' '362.0' '1024.0' '205.0' '761.0' '1409.0' '911.0' '465.0'\n",
      " '1157.0' '142.0' '1411.0' '1356.0' '1329.0' '793.0' '302.0' '1331.0'\n",
      " '1150.0' '1407.0' '686.0' '1152.0' '1154.0' '1153.0' '1151.0' '1085.0'\n",
      " '1444.0' '555.0' '1346.0' '1335.0'] 69\n",
      "similar_user: 3169\n",
      "sim_user_recs [] 0\n",
      "ordered_sim_user_recs [] 0\n",
      "recs before ['1330.0' '1427.0' '1364.0' '1170.0' '1162.0' '1304.0' '1351.0' '1160.0'\n",
      " '1354.0' '1368.0' '1338.0' '1336.0' '1172.0' '1276.0' '1163.0' '164.0'\n",
      " '681.0' '1360.0' '1396.0' '109.0' '1296.0' '1166.0' '1391.0' '1386.0'\n",
      " '1367.0' '1324.0' '1176.0' '12.0' '730.0' '1426.0' '939.0' '1424.0'\n",
      " '981.0' '125.0' '1357.0' '1420.0' '1410.0' '651.0' '1433.0' '880.0'\n",
      " '1278.0' '336.0' '362.0' '1024.0' '205.0' '761.0' '1409.0' '911.0' '465.0'\n",
      " '1157.0' '142.0' '1411.0' '1356.0' '1329.0' '793.0' '302.0' '1331.0'\n",
      " '1150.0' '1407.0' '686.0' '1152.0' '1154.0' '1153.0' '1151.0' '1085.0'\n",
      " '1444.0' '555.0' '1346.0' '1335.0'] 69\n",
      "recs after ['1330.0' '1427.0' '1364.0' '1170.0' '1162.0' '1304.0' '1351.0' '1160.0'\n",
      " '1354.0' '1368.0' '1338.0' '1336.0' '1172.0' '1276.0' '1163.0' '164.0'\n",
      " '681.0' '1360.0' '1396.0' '109.0' '1296.0' '1166.0' '1391.0' '1386.0'\n",
      " '1367.0' '1324.0' '1176.0' '12.0' '730.0' '1426.0' '939.0' '1424.0'\n",
      " '981.0' '125.0' '1357.0' '1420.0' '1410.0' '651.0' '1433.0' '880.0'\n",
      " '1278.0' '336.0' '362.0' '1024.0' '205.0' '761.0' '1409.0' '911.0' '465.0'\n",
      " '1157.0' '142.0' '1411.0' '1356.0' '1329.0' '793.0' '302.0' '1331.0'\n",
      " '1150.0' '1407.0' '686.0' '1152.0' '1154.0' '1153.0' '1151.0' '1085.0'\n",
      " '1444.0' '555.0' '1346.0' '1335.0'] 69\n",
      "similar_user: 204\n",
      "sim_user_recs ['14.0' '29.0' '33.0' '43.0' '51.0' '111.0' '130.0' '151.0' '153.0' '162.0'\n",
      " '221.0' '237.0' '244.0' '253.0' '273.0' '315.0' '316.0' '347.0' '379.0'\n",
      " '382.0' '390.0' '415.0' '464.0' '468.0' '491.0' '547.0' '607.0' '609.0'\n",
      " '692.0' '763.0' '813.0' '857.0' '858.0' '876.0' '933.0' '967.0' '990.0'\n",
      " '1014.0' '1059.0' '1164.0' '1186.0' '1271.0' '1293.0' '1305.0' '1314.0'\n",
      " '1332.0' '1422.0' '1429.0' '1432.0'] 49\n",
      "ordered_sim_user_recs ['1429.0' '1314.0' '1293.0' '1271.0' '43.0' '1305.0' '151.0' '1432.0'\n",
      " '390.0' '1164.0' '1332.0' '237.0' '1422.0' '415.0' '162.0' '1186.0' '33.0'\n",
      " '51.0' '1014.0' '221.0' '933.0' '316.0' '14.0' '153.0' '29.0' '379.0'\n",
      " '111.0' '692.0' '1059.0' '315.0' '464.0' '547.0' '130.0' '491.0' '253.0'\n",
      " '607.0' '967.0' '382.0' '609.0' '813.0' '244.0' '858.0' '990.0' '273.0'\n",
      " '347.0' '468.0' '876.0' '857.0' '763.0'] 49\n",
      "recs before ['1330.0' '1427.0' '1364.0' '1170.0' '1162.0' '1304.0' '1351.0' '1160.0'\n",
      " '1354.0' '1368.0' '1338.0' '1336.0' '1172.0' '1276.0' '1163.0' '164.0'\n",
      " '681.0' '1360.0' '1396.0' '109.0' '1296.0' '1166.0' '1391.0' '1386.0'\n",
      " '1367.0' '1324.0' '1176.0' '12.0' '730.0' '1426.0' '939.0' '1424.0'\n",
      " '981.0' '125.0' '1357.0' '1420.0' '1410.0' '651.0' '1433.0' '880.0'\n",
      " '1278.0' '336.0' '362.0' '1024.0' '205.0' '761.0' '1409.0' '911.0' '465.0'\n",
      " '1157.0' '142.0' '1411.0' '1356.0' '1329.0' '793.0' '302.0' '1331.0'\n",
      " '1150.0' '1407.0' '686.0' '1152.0' '1154.0' '1153.0' '1151.0' '1085.0'\n",
      " '1444.0' '555.0' '1346.0' '1335.0'] 69\n",
      "recs after ['1330.0' '1427.0' '1364.0' '1170.0' '1162.0' '1304.0' '1351.0' '1160.0'\n",
      " '1354.0' '1368.0' '1338.0' '1336.0' '1172.0' '1276.0' '1163.0' '164.0'\n",
      " '681.0' '1360.0' '1396.0' '109.0' '1296.0' '1166.0' '1391.0' '1386.0'\n",
      " '1367.0' '1324.0' '1176.0' '12.0' '730.0' '1426.0' '939.0' '1424.0'\n",
      " '981.0' '125.0' '1357.0' '1420.0' '1410.0' '651.0' '1433.0' '880.0'\n",
      " '1278.0' '336.0' '362.0' '1024.0' '205.0' '761.0' '1409.0' '911.0' '465.0'\n",
      " '1157.0' '142.0' '1411.0' '1356.0' '1329.0' '793.0' '302.0' '1331.0'\n",
      " '1150.0' '1407.0' '686.0' '1152.0' '1154.0' '1153.0' '1151.0' '1085.0'\n",
      " '1444.0' '555.0' '1346.0' '1335.0' '1429.0' '1314.0' '1293.0' '1271.0'\n",
      " '43.0' '1305.0' '151.0' '1432.0' '390.0' '1164.0' '1332.0' '237.0'\n",
      " '1422.0' '415.0' '162.0' '1186.0' '33.0' '51.0' '1014.0' '221.0' '933.0'\n",
      " '316.0' '14.0' '153.0' '29.0' '379.0' '111.0' '692.0' '1059.0' '315.0'\n",
      " '464.0' '547.0' '130.0' '491.0' '253.0' '607.0' '967.0' '382.0' '609.0'\n",
      " '813.0' '244.0' '858.0' '990.0' '273.0' '347.0' '468.0' '876.0' '857.0'\n",
      " '763.0'] 118\n",
      "The top 10 recommendations for user 20 are the following article ids:\n",
      "['1330.0' '1427.0' '1364.0' '1170.0' '1162.0' '1304.0' '1351.0' '1160.0'\n",
      " '1354.0' '1368.0' '1338.0' '1336.0' '1172.0' '1276.0' '1163.0' '164.0'\n",
      " '681.0' '1360.0' '1396.0' '109.0' '1296.0' '1166.0' '1391.0' '1386.0'\n",
      " '1367.0' '1324.0' '1176.0' '12.0' '730.0' '1426.0' '939.0' '1424.0'\n",
      " '981.0' '125.0' '1357.0' '1420.0' '1410.0' '651.0' '1433.0' '880.0'\n",
      " '1278.0' '336.0' '362.0' '1024.0' '205.0' '761.0' '1409.0' '911.0' '465.0'\n",
      " '1157.0' '142.0' '1411.0' '1356.0' '1329.0' '793.0' '302.0' '1331.0'\n",
      " '1150.0' '1407.0' '686.0' '1152.0' '1154.0' '1153.0' '1151.0' '1085.0'\n",
      " '1444.0' '555.0' '1346.0' '1335.0' '1429.0' '1314.0' '1293.0' '1271.0'\n",
      " '43.0' '1305.0' '151.0' '1432.0' '390.0' '1164.0' '1332.0' '237.0'\n",
      " '1422.0' '415.0' '162.0' '1186.0' '33.0' '51.0' '1014.0' '221.0' '933.0'\n",
      " '316.0' '14.0' '153.0' '29.0' '379.0' '111.0' '692.0' '1059.0' '315.0'\n",
      " '464.0']\n",
      "\n",
      "The top 10 recommendations for user 20 are the following article names:\n",
      "['insights from new york car accident reports'\n",
      " 'use xgboost, scikit-learn & ibm watson machine learning apis'\n",
      " 'predicting churn with the spss random tree algorithm'\n",
      " 'apache spark lab, part 1: basic concepts'\n",
      " 'analyze energy consumption in buildings'\n",
      " 'gosales transactions for logistic regression model'\n",
      " 'model bike sharing data with spss'\n",
      " 'analyze accident reports on amazon emr spark'\n",
      " 'movie recommender system with spark machine learning'\n",
      " 'putting a human face on machine learning'\n",
      " 'ml optimization using cognitive assistant'\n",
      " 'learn basics about notebooks and apache spark'\n",
      " 'apache spark lab, part 3: machine learning'\n",
      " 'deploy your python model as a restful api'\n",
      " 'analyze open data sets with spark & pixiedust'\n",
      " 'learn tensorflow and deep learning together and now!'\n",
      " 'real-time sentiment analysis of twitter hashtags with spark (+ pixiedust)'\n",
      " 'pixieapp for outlier detection' 'times world university ranking analysis'\n",
      " 'tensorflow quick tips' 'fortune 100 companies'\n",
      " 'analyzing data by using the sparkling.data library features' 'sudoku'\n",
      " 'small steps to tensorflow'\n",
      " 'programmatic evaluation using watson conversation'\n",
      " 'ibm watson facebook posts for 2015'\n",
      " 'build a python app on the streaming analytics service'\n",
      " 'timeseries data analysis of iot events by using jupyter notebook'\n",
      " 'developing for the ibm streaming analytics service'\n",
      " 'use spark for scala to load data and run sql queries'\n",
      " 'deep learning from scratch i: computational graphs'\n",
      " 'use spark for python to load data and run sql queries'\n",
      " 'super fast string matching in python' 'statistics for hackers'\n",
      " 'overlapping co-cluster recommendation algorithm (ocular)'\n",
      " 'use apache systemml and spark for machine learning'\n",
      " 'uci: sms spam collection' 'analyzing streaming data from kafka topics'\n",
      " 'visualize the 1854 london cholera outbreak'\n",
      " 'probabilistic graphical models tutorial\\u200a—\\u200apart 1 – stats and bots'\n",
      " 'develop a scala spark model on chicago building violations'\n",
      " 'challenges in deep learning' 'dsx: hybrid mode'\n",
      " 'using deep learning to reconstruct high-resolution audio'\n",
      " \"a beginner's guide to variational methods\"\n",
      " 'variational auto-encoder for \"frey faces\" using keras'\n",
      " 'uci: red wine quality'\n",
      " 'using machine learning to predict baseball injuries'\n",
      " 'introduction to neural networks, advantages and applications'\n",
      " 'airbnb data for analytics: washington d.c. listings'\n",
      " 'neural networks for beginners: popular types and applications'\n",
      " 'uci: white wine quality'\n",
      " 'occupation (2015): united states demographic measures'\n",
      " 'ingest data from message hub in a streams flow'\n",
      " '10 powerful features on watson data platform, no coding necessary'\n",
      " 'accelerate your workflow with dsx'\n",
      " 'intentional homicide, number and rate per 100,000 population, by country'\n",
      " 'airbnb data for analytics: venice calendar'\n",
      " 'uci: poker hand - testing data set'\n",
      " 'score a predictive model built with ibm spss modeler, wml & dsx'\n",
      " 'airbnb data for analytics: venice reviews'\n",
      " 'airbnb data for analytics: vienna listings'\n",
      " 'airbnb data for analytics: vienna calendar'\n",
      " 'airbnb data for analytics: venice listings'\n",
      " 'airbnb data for analytics: chicago listings'\n",
      " 'worldwide fuel oil consumption by household (in 1000 metric tons)'\n",
      " 'build a naive-bayes model with wml & dsx'\n",
      " 'military expenditure as % of gdp by country' 'labor'\n",
      " 'use deep learning for image classification'\n",
      " 'healthcare python streaming application demo'\n",
      " 'finding optimal locations of new store using decision optimization'\n",
      " 'customer demographics and sales'\n",
      " 'deep learning with tensorflow course by big data university'\n",
      " 'gosales transactions for naive bayes model' 'jupyter notebook tutorial'\n",
      " 'visualize data with the matplotlib library'\n",
      " 'introducing ibm watson studio '\n",
      " 'analyze open data sets with pandas dataframes'\n",
      " 'intents & examples for ibm watson conversation'\n",
      " 'deep learning with data science experience'\n",
      " 'use r dataframes & ibm watson natural language understanding'\n",
      " 'using machine learning to predict value of homes on airbnb'\n",
      " 'an introduction to stock market data analysis with r (part 1)'\n",
      " 'connect to db2 warehouse on cloud and db2 using scala'\n",
      " 'using brunel in ipython/jupyter notebooks'\n",
      " 'modern machine learning algorithms'\n",
      " '1448    i ranked every intro to data science course on...\\nName: title, dtype: object'\n",
      " 'how smart catalogs can turn the big data flood into an ocean of opportunity'\n",
      " 'workflow in r'\n",
      " 'leverage python, scikit, and text classification for behavioral profiling'\n",
      " 'got zip code data? prep it for analytics. – ibm watson data lab – medium'\n",
      " 'predicting flight cancellations using weather data, part 3'\n",
      " 'experience iot with coursera'\n",
      " 'data structures related to machine learning algorithms'\n",
      " 'tidy up your jupyter notebooks with scripts' '15 page tutorial for r'\n",
      " 'airbnb data for analytics: amsterdam calendar' 'neurally embedded emojis'\n",
      " 'use ibm data science experience to detect time series anomalies']\n"
     ]
    }
   ],
   "source": [
    "# Quick spot check - don't change this code - just use it to test your functions\n",
    "rec_ids, rec_names = user_user_recs_part2(20, 100, True)\n",
    "print(\"The top 10 recommendations for user 20 are the following article ids:\")\n",
    "print(rec_ids)\n",
    "print()\n",
    "print(\"The top 10 recommendations for user 20 are the following article names:\")\n",
    "print(rec_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`5.` Use your functions from above to correctly fill in the solutions to the dictionary below.  Then test your dictionary against the solution.  Provide the code you need to answer each following the comments below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Tests with a dictionary of results\n",
    "\n",
    "user1_most_sim = get_top_sorted_users(1).neighbor_id.values[0]# Find the user that is most similar to user 1 \n",
    "user131_10th_sim = get_top_sorted_users(131).neighbor_id.values[9]# Find the 10th most similar user to user 131"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This all looks good!  Nice job!\n"
     ]
    }
   ],
   "source": [
    "## Dictionary Test Here\n",
    "sol_5_dict = {\n",
    "    'The user that is most similar to user 1.': user1_most_sim, \n",
    "    'The user that is the 10th most similar to user 131': user131_10th_sim,\n",
    "}\n",
    "\n",
    "t.sol_5_test(sol_5_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`6.` If we were given a new user, which of the above functions would you be able to use to make recommendations?  Explain.  Can you think of a better way we might make recommendations?  Use the cell below to explain a better method for new users."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For new users, we cannot use the user_user recommendation functions as they rely on user similarity which is calculated based on previous user-article interactions. As the new user has no previous interaction with articles, they will not work for him.\n",
    "\n",
    "A better way to make recommendations to such users is to recommend the top articles, based on overall user-article interactions, using the function get_top_articles()."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`7.` Using your existing functions, provide the top 10 recommended articles you would provide for the a new user below.  You can test your function against our thoughts to make sure we are all on the same page with how we might make a recommendation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_user = '0.0'\n",
    "\n",
    "# What would your recommendations be for this new user '0.0'?  As a new user, they have no observed articles.\n",
    "# Provide a list of the top 10 article ids you would give to \n",
    "new_user_recs = get_top_article_ids(n=10)# Your recommendations here\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "That's right!  Nice job!\n"
     ]
    }
   ],
   "source": [
    "assert set(new_user_recs) == set(['1314.0','1429.0','1293.0','1427.0','1162.0','1364.0','1304.0','1170.0','1431.0','1330.0']), \"Oops!  It makes sense that in this case we would want to recommend the most popular articles, because we don't know anything about these users.\"\n",
    "\n",
    "print(\"That's right!  Nice job!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a class=\"anchor\" id=\"Content-Recs\">Part IV: Content Based Recommendations (EXTRA - NOT REQUIRED)</a>\n",
    "\n",
    "Another method we might use to make recommendations is to perform a ranking of the highest ranked articles associated with some term.  You might consider content to be the **doc_body**, **doc_description**, or **doc_full_name**.  There isn't one way to create a content based recommendation, especially considering that each of these columns hold content related information.  \n",
    "\n",
    "`1.` Use the function body below to create a content based recommender.  Since there isn't one right answer for this recommendation tactic, no test functions are provided.  Feel free to change the function inputs if you decide you want to try a method that requires more input values.  The input values are currently set with one idea in mind that you may use to make content based recommendations.  One additional idea is that you might want to choose the most popular recommendations that meet your 'content criteria', but again, there is a lot of flexibility in how you might make these recommendations.\n",
    "\n",
    "### This part is NOT REQUIRED to pass this project.  However, you may choose to take this on as an extra way to show off your skills."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_body</th>\n",
       "      <th>doc_description</th>\n",
       "      <th>doc_full_name</th>\n",
       "      <th>doc_status</th>\n",
       "      <th>article_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Skip navigation Sign in SearchLoading...\\r\\n\\r...</td>\n",
       "      <td>Detect bad readings in real time using Python ...</td>\n",
       "      <td>Detect Malfunctioning IoT Sensors with Streami...</td>\n",
       "      <td>Live</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>No Free Hunch Navigation * kaggle.com\\r\\n\\r\\n ...</td>\n",
       "      <td>See the forest, see the trees. Here lies the c...</td>\n",
       "      <td>Communicating data science: A guide to present...</td>\n",
       "      <td>Live</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>☰ * Login\\r\\n * Sign Up\\r\\n\\r\\n * Learning Pat...</td>\n",
       "      <td>Here’s this week’s news in Data Science and Bi...</td>\n",
       "      <td>This Week in Data Science (April 18, 2017)</td>\n",
       "      <td>Live</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DATALAYER: HIGH THROUGHPUT, LOW LATENCY AT SCA...</td>\n",
       "      <td>Learn how distributed DBs solve the problem of...</td>\n",
       "      <td>DataLayer Conference: Boost the performance of...</td>\n",
       "      <td>Live</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Skip navigation Sign in SearchLoading...\\r\\n\\r...</td>\n",
       "      <td>This video demonstrates the power of IBM DataS...</td>\n",
       "      <td>Analyze NY Restaurant data using Spark in DSX</td>\n",
       "      <td>Live</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            doc_body  \\\n",
       "0  Skip navigation Sign in SearchLoading...\\r\\n\\r...   \n",
       "1  No Free Hunch Navigation * kaggle.com\\r\\n\\r\\n ...   \n",
       "2  ☰ * Login\\r\\n * Sign Up\\r\\n\\r\\n * Learning Pat...   \n",
       "3  DATALAYER: HIGH THROUGHPUT, LOW LATENCY AT SCA...   \n",
       "4  Skip navigation Sign in SearchLoading...\\r\\n\\r...   \n",
       "\n",
       "                                     doc_description  \\\n",
       "0  Detect bad readings in real time using Python ...   \n",
       "1  See the forest, see the trees. Here lies the c...   \n",
       "2  Here’s this week’s news in Data Science and Bi...   \n",
       "3  Learn how distributed DBs solve the problem of...   \n",
       "4  This video demonstrates the power of IBM DataS...   \n",
       "\n",
       "                                       doc_full_name doc_status  article_id  \n",
       "0  Detect Malfunctioning IoT Sensors with Streami...       Live           0  \n",
       "1  Communicating data science: A guide to present...       Live           1  \n",
       "2         This Week in Data Science (April 18, 2017)       Live           2  \n",
       "3  DataLayer Conference: Boost the performance of...       Live           3  \n",
       "4      Analyze NY Restaurant data using Spark in DSX       Live           4  "
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_content.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "doc_description    Detect bad readings in real time using Python ...\n",
       "doc_full_name      Detect Malfunctioning IoT Sensors with Streami...\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_content.loc[0,['doc_description','doc_full_name']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detect bad readings in real time using Python and Streaming Analytics.\n",
      "Detect Malfunctioning IoT Sensors with Streaming Analytics\n",
      "See the forest, see the trees. Here lies the challenge in both performing and presenting an analysis. As data scientists, analysts, and machine learning engineers faced with fulfilling business obj…\n",
      "Communicating data science: A guide to presenting your work\n",
      "Here’s this week’s news in Data Science and Big Data.\n",
      "This Week in Data Science (April 18, 2017)\n",
      "Learn how distributed DBs solve the problem of scaling persistent storage, but introduce latency as data size increases and become I/O bound.\n",
      "DataLayer Conference: Boost the performance of your distributed database\n",
      "This video demonstrates the power of IBM DataScience Experience using a simple New York State Restaurant Inspections data scenario. \n",
      "Analyze NY Restaurant data using Spark in DSX\n",
      "Using Compose's PostgreSQL data browser.\n",
      "Browsing PostgreSQL Data with Compose\n",
      "Upgrading your PostgreSQL deployment to version 9.5 is now possible through the Compose console. Working out how to perform this upgrade safely and reliably has been an interesting process because from version 9.4 to 9.5 is a PostgreSQL major upgrade.\n",
      "Upgrading your PostgreSQL to 9.5\n",
      "For a company like Slack that strives to be as data-driven as possible, understanding how our users use our product is essential. The Data Engineering team at Slack works to provide an ecosystem to…\n",
      "Data Wrangling at Slack\n",
      "Kaggle is your home for data science. Learn new skills, build your career, collaborate with other data scientists, and compete in world-class machine learning challenges.\n",
      "Data Science Bowl 2017\n",
      "[A version of this post appears on the O’Reilly Radar.] The O’Reilly Data Show podcast: Fang Yu on data science in security, unsupervised learning, and Apache Spark. Subscribe to the O’Reilly…\n",
      "Using Apache Spark to predict attack vectors among billions of users and trillions of events\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(df_content.doc_description[i])\n",
    "    print(df_content.doc_full_name[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>article_id</th>\n",
       "      <th>interaction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>33681</th>\n",
       "      <td>5149</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33680</th>\n",
       "      <td>5148</td>\n",
       "      <td>1160.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33679</th>\n",
       "      <td>5147</td>\n",
       "      <td>233.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33676</th>\n",
       "      <td>5146</td>\n",
       "      <td>1324.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33672</th>\n",
       "      <td>5146</td>\n",
       "      <td>142.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       user_id  article_id  interaction\n",
       "33681     5149        16.0            1\n",
       "33680     5148      1160.0            1\n",
       "33679     5147       233.0            1\n",
       "33676     5146      1324.0            3\n",
       "33672     5146       142.0            1"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_articles_interactions = df.groupby(['user_id','article_id']).interaction.count().reset_index().sort_values(['user_id','interaction'],ascending=False)\n",
    "user_articles_interactions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['doc_body', 'doc_description', 'doc_full_name', 'doc_status',\n",
       "       'article_id'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_articles.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/pandas/core/indexing.py:362: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[key] = _infer_fill_value(value)\n",
      "/opt/conda/lib/python3.6/site-packages/pandas/core/indexing.py:543: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n"
     ]
    }
   ],
   "source": [
    "# Build Similarity Matrix\n",
    "\n",
    "# Tokenize article descriptions\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "articles_tokens = clean_articles[['article_id','doc_description']]\n",
    "\n",
    "articles_tokens.loc[:,'tokens_str'] = articles_tokens.doc_description.apply(\n",
    "    lambda x: nlp_estimators.tokenize_to_str(x, lemmatizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Detect bad readings in real time using Python ...\n",
       "1    See the forest, see the trees. Here lies the c...\n",
       "2    Here’s this week’s news in Data Science and Bi...\n",
       "3    Learn how distributed DBs solve the problem of...\n",
       "4    This video demonstrates the power of IBM DataS...\n",
       "Name: doc_description, dtype: object"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles_tokens.doc_description.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>doc_description</th>\n",
       "      <th>tokens_str</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Detect bad readings in real time using Python ...</td>\n",
       "      <td>detect bad reading real time using python stre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>See the forest, see the trees. Here lies the c...</td>\n",
       "      <td>see forest see tree lie challenge performing p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Here’s this week’s news in Data Science and Bi...</td>\n",
       "      <td>week news data science big data</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Learn how distributed DBs solve the problem of...</td>\n",
       "      <td>learn distributed db solve problem scaling per...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>This video demonstrates the power of IBM DataS...</td>\n",
       "      <td>video demonstrates power ibm datascience exper...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>Using Compose's PostgreSQL data browser.</td>\n",
       "      <td>using compose postgresql data browser</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>Upgrading your PostgreSQL deployment to versio...</td>\n",
       "      <td>upgrading postgresql deployment version 9 5 po...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>For a company like Slack that strives to be as...</td>\n",
       "      <td>company like slack strives data driven possibl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>Kaggle is your home for data science. Learn ne...</td>\n",
       "      <td>kaggle home data science learn new skill build...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>[A version of this post appears on the O’Reill...</td>\n",
       "      <td>version post appears reilly radar reilly data ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>Apple's sample app, Food Tracker, taught you i...</td>\n",
       "      <td>apple sample app food tracker taught io take s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>Replicating data to a relational dashDB databa...</td>\n",
       "      <td>replicating data relational dashdb database gr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>This recipe showcases how one can analyze the ...</td>\n",
       "      <td>recipe showcase one analyze historical time se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>There’s a reason you’ve been hearing a lot abo...</td>\n",
       "      <td>reason hearing lot data science notebook latel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>Who are those people lurking behind the statis...</td>\n",
       "      <td>people lurking behind statistic data whether l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>Early methods to integrate machine learning us...</td>\n",
       "      <td>early method integrate machine learning using ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>The performance of supervised predictive model...</td>\n",
       "      <td>performance supervised predictive model charac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>We've always considered MySQL as a potential C...</td>\n",
       "      <td>always considered mysql potential compose data...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>It has never been easier to build AI or machin...</td>\n",
       "      <td>never easier build ai machine learning based s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>In our Metrics Maven series, Compose's data sc...</td>\n",
       "      <td>metric maven series compose data scientist sha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>It is often useful to use RStudio for one piec...</td>\n",
       "      <td>often useful use rstudio one piece analysis no...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>You’re doing your data a disservice if you don...</td>\n",
       "      <td>data disservice use map nearly data spatial co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>Introducing nosqlimport, an npm module to help...</td>\n",
       "      <td>introducing nosqlimport npm module help import...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>This video shows you how to build and query a ...</td>\n",
       "      <td>video show build query cloudant geospatial ind...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>Botkit provides a simple framework to handle t...</td>\n",
       "      <td>botkit provides simple framework handle basic ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>Want to learn more about how we created the Da...</td>\n",
       "      <td>want learn created data science experience int...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>Much of driving is spent either stuck in traff...</td>\n",
       "      <td>much driving spent either stuck traffic lookin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>This talk assumes you have a basic understandi...</td>\n",
       "      <td>talk assumes basic understanding spark take u ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28</td>\n",
       "      <td>In this paper, we propose gcForest, a decision...</td>\n",
       "      <td>paper propose gcforest decision tree ensemble ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29</td>\n",
       "      <td>I’m very happy and proud to announce that IBM ...</td>\n",
       "      <td>happy proud announce ibm first non academic su...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1026</th>\n",
       "      <td>1021</td>\n",
       "      <td>Varun Singh, a software engineer at IBM's Wats...</td>\n",
       "      <td>varun singh software engineer ibm watson healt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1027</th>\n",
       "      <td>1022</td>\n",
       "      <td>This video shows you how to create and adminis...</td>\n",
       "      <td>video show create administer data catalog wats...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1028</th>\n",
       "      <td>1023</td>\n",
       "      <td>With the latest 0.2.1 version of Transporter, ...</td>\n",
       "      <td>latest 0 2 1 version transporter making open s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1029</th>\n",
       "      <td>1024</td>\n",
       "      <td>Audio super-resolution aims to reconstruct a h...</td>\n",
       "      <td>audio super resolution aim reconstruct high re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1030</th>\n",
       "      <td>1025</td>\n",
       "      <td>Since then, this metric has been ubiquitously ...</td>\n",
       "      <td>since metric ubiquitously quoted accurate data...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1031</th>\n",
       "      <td>1026</td>\n",
       "      <td>Build a word game app and see how to manage an...</td>\n",
       "      <td>build word game app see manage deploy bluemix ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1032</th>\n",
       "      <td>1027</td>\n",
       "      <td>Use Redis and and Python scripts to speed your...</td>\n",
       "      <td>use redis python script speed geospatial query</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1033</th>\n",
       "      <td>1028</td>\n",
       "      <td>In this post, you’ll learn to query, update, a...</td>\n",
       "      <td>post learn query update create sqlite database...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1034</th>\n",
       "      <td>1029</td>\n",
       "      <td>Adron Hall of Thrashing Code and Home Depot, t...</td>\n",
       "      <td>adron hall thrashing code home depot talk prob...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1035</th>\n",
       "      <td>1030</td>\n",
       "      <td>Describes the use of Laplace noise in machine ...</td>\n",
       "      <td>describes use laplace noise machine learning m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1036</th>\n",
       "      <td>1031</td>\n",
       "      <td>A full guide to Elasticsearch, the real-time d...</td>\n",
       "      <td>full guide elasticsearch real time distributed...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1037</th>\n",
       "      <td>1032</td>\n",
       "      <td>See how quick and easy it is to set up a dashD...</td>\n",
       "      <td>see quick easy set dashdb instance ibm bluemix...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1038</th>\n",
       "      <td>1033</td>\n",
       "      <td>The relational database has been the dominant ...</td>\n",
       "      <td>relational database dominant model persisting ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1039</th>\n",
       "      <td>1034</td>\n",
       "      <td>Building your first data warehouse doesn’t hav...</td>\n",
       "      <td>building first data warehouse enterprise scary...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1040</th>\n",
       "      <td>1035</td>\n",
       "      <td>In my last blog “Business differentiation thro...</td>\n",
       "      <td>last blog business differentiation machine lea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1041</th>\n",
       "      <td>1036</td>\n",
       "      <td>MongoDB's aggregation pipeline makes finding d...</td>\n",
       "      <td>mongodb aggregation pipeline make finding dupl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1042</th>\n",
       "      <td>1037</td>\n",
       "      <td>Which write API endpoint is the right write ca...</td>\n",
       "      <td>write api endpoint right write call</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1043</th>\n",
       "      <td>1038</td>\n",
       "      <td>Nothing spoils a plot like (too much) data.</td>\n",
       "      <td>nothing spoil plot like much data</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1044</th>\n",
       "      <td>1039</td>\n",
       "      <td>Getting started with custom visualizations, si...</td>\n",
       "      <td>getting started custom visualization simple ta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1045</th>\n",
       "      <td>1040</td>\n",
       "      <td>Although it is built around a JavaScript engin...</td>\n",
       "      <td>although built around javascript engine many p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1046</th>\n",
       "      <td>1041</td>\n",
       "      <td>Last week I attended the GeoPython conference ...</td>\n",
       "      <td>last week attended geopython conference basel ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1047</th>\n",
       "      <td>1042</td>\n",
       "      <td>In this post, we will go through how to read a...</td>\n",
       "      <td>post go read write data amazon s3 using python...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048</th>\n",
       "      <td>1043</td>\n",
       "      <td>As more devices become internet enabled, harne...</td>\n",
       "      <td>device become internet enabled harnessing data...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1049</th>\n",
       "      <td>1044</td>\n",
       "      <td>Continuing my previous work on exploring Arlin...</td>\n",
       "      <td>continuing previous work exploring arlington b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1050</th>\n",
       "      <td>1045</td>\n",
       "      <td>Lua is a compact language which can be embedde...</td>\n",
       "      <td>lua compact language embedded application dive...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1051</th>\n",
       "      <td>1046</td>\n",
       "      <td>PouchDB uses MapReduce as its default search m...</td>\n",
       "      <td>pouchdb us mapreduce default search mechanism ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1052</th>\n",
       "      <td>1047</td>\n",
       "      <td>We compare discriminative and generative learn...</td>\n",
       "      <td>compare discriminative generative learning typ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1053</th>\n",
       "      <td>1048</td>\n",
       "      <td>In order to demystify some of the magic behind...</td>\n",
       "      <td>order demystify magic behind machine learning ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1054</th>\n",
       "      <td>1049</td>\n",
       "      <td>Learn how to use IBM dashDB as data store for ...</td>\n",
       "      <td>learn use ibm dashdb data store apache spark s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1055</th>\n",
       "      <td>1050</td>\n",
       "      <td>Once you get used to developing in a Notebook ...</td>\n",
       "      <td>get used developing notebook environment painf...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1051 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      article_id                                    doc_description  \\\n",
       "0              0  Detect bad readings in real time using Python ...   \n",
       "1              1  See the forest, see the trees. Here lies the c...   \n",
       "2              2  Here’s this week’s news in Data Science and Bi...   \n",
       "3              3  Learn how distributed DBs solve the problem of...   \n",
       "4              4  This video demonstrates the power of IBM DataS...   \n",
       "5              5           Using Compose's PostgreSQL data browser.   \n",
       "6              6  Upgrading your PostgreSQL deployment to versio...   \n",
       "7              7  For a company like Slack that strives to be as...   \n",
       "8              8  Kaggle is your home for data science. Learn ne...   \n",
       "9              9  [A version of this post appears on the O’Reill...   \n",
       "10            10  Apple's sample app, Food Tracker, taught you i...   \n",
       "11            11  Replicating data to a relational dashDB databa...   \n",
       "12            12  This recipe showcases how one can analyze the ...   \n",
       "13            13  There’s a reason you’ve been hearing a lot abo...   \n",
       "14            14  Who are those people lurking behind the statis...   \n",
       "15            15  Early methods to integrate machine learning us...   \n",
       "16            16  The performance of supervised predictive model...   \n",
       "17            17  We've always considered MySQL as a potential C...   \n",
       "18            18  It has never been easier to build AI or machin...   \n",
       "19            19  In our Metrics Maven series, Compose's data sc...   \n",
       "20            20  It is often useful to use RStudio for one piec...   \n",
       "21            21  You’re doing your data a disservice if you don...   \n",
       "22            22  Introducing nosqlimport, an npm module to help...   \n",
       "23            23  This video shows you how to build and query a ...   \n",
       "24            24  Botkit provides a simple framework to handle t...   \n",
       "25            25  Want to learn more about how we created the Da...   \n",
       "26            26  Much of driving is spent either stuck in traff...   \n",
       "27            27  This talk assumes you have a basic understandi...   \n",
       "28            28  In this paper, we propose gcForest, a decision...   \n",
       "29            29  I’m very happy and proud to announce that IBM ...   \n",
       "...          ...                                                ...   \n",
       "1026        1021  Varun Singh, a software engineer at IBM's Wats...   \n",
       "1027        1022  This video shows you how to create and adminis...   \n",
       "1028        1023  With the latest 0.2.1 version of Transporter, ...   \n",
       "1029        1024  Audio super-resolution aims to reconstruct a h...   \n",
       "1030        1025  Since then, this metric has been ubiquitously ...   \n",
       "1031        1026  Build a word game app and see how to manage an...   \n",
       "1032        1027  Use Redis and and Python scripts to speed your...   \n",
       "1033        1028  In this post, you’ll learn to query, update, a...   \n",
       "1034        1029  Adron Hall of Thrashing Code and Home Depot, t...   \n",
       "1035        1030  Describes the use of Laplace noise in machine ...   \n",
       "1036        1031  A full guide to Elasticsearch, the real-time d...   \n",
       "1037        1032  See how quick and easy it is to set up a dashD...   \n",
       "1038        1033  The relational database has been the dominant ...   \n",
       "1039        1034  Building your first data warehouse doesn’t hav...   \n",
       "1040        1035  In my last blog “Business differentiation thro...   \n",
       "1041        1036  MongoDB's aggregation pipeline makes finding d...   \n",
       "1042        1037  Which write API endpoint is the right write ca...   \n",
       "1043        1038        Nothing spoils a plot like (too much) data.   \n",
       "1044        1039  Getting started with custom visualizations, si...   \n",
       "1045        1040  Although it is built around a JavaScript engin...   \n",
       "1046        1041  Last week I attended the GeoPython conference ...   \n",
       "1047        1042  In this post, we will go through how to read a...   \n",
       "1048        1043  As more devices become internet enabled, harne...   \n",
       "1049        1044  Continuing my previous work on exploring Arlin...   \n",
       "1050        1045  Lua is a compact language which can be embedde...   \n",
       "1051        1046  PouchDB uses MapReduce as its default search m...   \n",
       "1052        1047  We compare discriminative and generative learn...   \n",
       "1053        1048  In order to demystify some of the magic behind...   \n",
       "1054        1049  Learn how to use IBM dashDB as data store for ...   \n",
       "1055        1050  Once you get used to developing in a Notebook ...   \n",
       "\n",
       "                                             tokens_str  \n",
       "0     detect bad reading real time using python stre...  \n",
       "1     see forest see tree lie challenge performing p...  \n",
       "2                       week news data science big data  \n",
       "3     learn distributed db solve problem scaling per...  \n",
       "4     video demonstrates power ibm datascience exper...  \n",
       "5                 using compose postgresql data browser  \n",
       "6     upgrading postgresql deployment version 9 5 po...  \n",
       "7     company like slack strives data driven possibl...  \n",
       "8     kaggle home data science learn new skill build...  \n",
       "9     version post appears reilly radar reilly data ...  \n",
       "10    apple sample app food tracker taught io take s...  \n",
       "11    replicating data relational dashdb database gr...  \n",
       "12    recipe showcase one analyze historical time se...  \n",
       "13    reason hearing lot data science notebook latel...  \n",
       "14    people lurking behind statistic data whether l...  \n",
       "15    early method integrate machine learning using ...  \n",
       "16    performance supervised predictive model charac...  \n",
       "17    always considered mysql potential compose data...  \n",
       "18    never easier build ai machine learning based s...  \n",
       "19    metric maven series compose data scientist sha...  \n",
       "20    often useful use rstudio one piece analysis no...  \n",
       "21    data disservice use map nearly data spatial co...  \n",
       "22    introducing nosqlimport npm module help import...  \n",
       "23    video show build query cloudant geospatial ind...  \n",
       "24    botkit provides simple framework handle basic ...  \n",
       "25    want learn created data science experience int...  \n",
       "26    much driving spent either stuck traffic lookin...  \n",
       "27    talk assumes basic understanding spark take u ...  \n",
       "28    paper propose gcforest decision tree ensemble ...  \n",
       "29    happy proud announce ibm first non academic su...  \n",
       "...                                                 ...  \n",
       "1026  varun singh software engineer ibm watson healt...  \n",
       "1027  video show create administer data catalog wats...  \n",
       "1028  latest 0 2 1 version transporter making open s...  \n",
       "1029  audio super resolution aim reconstruct high re...  \n",
       "1030  since metric ubiquitously quoted accurate data...  \n",
       "1031  build word game app see manage deploy bluemix ...  \n",
       "1032     use redis python script speed geospatial query  \n",
       "1033  post learn query update create sqlite database...  \n",
       "1034  adron hall thrashing code home depot talk prob...  \n",
       "1035  describes use laplace noise machine learning m...  \n",
       "1036  full guide elasticsearch real time distributed...  \n",
       "1037  see quick easy set dashdb instance ibm bluemix...  \n",
       "1038  relational database dominant model persisting ...  \n",
       "1039  building first data warehouse enterprise scary...  \n",
       "1040  last blog business differentiation machine lea...  \n",
       "1041  mongodb aggregation pipeline make finding dupl...  \n",
       "1042                write api endpoint right write call  \n",
       "1043                  nothing spoil plot like much data  \n",
       "1044  getting started custom visualization simple ta...  \n",
       "1045  although built around javascript engine many p...  \n",
       "1046  last week attended geopython conference basel ...  \n",
       "1047  post go read write data amazon s3 using python...  \n",
       "1048  device become internet enabled harnessing data...  \n",
       "1049  continuing previous work exploring arlington b...  \n",
       "1050  lua compact language embedded application dive...  \n",
       "1051  pouchdb us mapreduce default search mechanism ...  \n",
       "1052  compare discriminative generative learning typ...  \n",
       "1053  order demystify magic behind machine learning ...  \n",
       "1054  learn use ibm dashdb data store apache spark s...  \n",
       "1055  get used developing notebook environment painf...  \n",
       "\n",
       "[1051 rows x 3 columns]"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1051, 3)\n"
     ]
    }
   ],
   "source": [
    "print(articles_tokens.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_articles_model = nlp_estimators.TfidfEmbeddingTrainVectorizer(num_dims=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfEmbeddingTrainVectorizer(num_dims=300,\n",
       "               word2vec_model=<gensim.models.word2vec.Word2Vec object at 0x7fb1ac2621d0>)"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_articles_model.fit(articles_tokens.tokens_str.values, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles_embeddings = w2v_articles_model.transform(articles_tokens.tokens_str.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1051, 300)"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  2.60708999e-04,  -2.75875820e-04,  -1.51128552e-04,\n",
       "         1.75917303e-04,  -2.62617414e-05,   4.93781234e-04,\n",
       "        -2.13221996e-04,   2.88512470e-04,  -2.67978874e-04,\n",
       "         1.78049057e-04,   1.22651778e-04,  -1.76579095e-04,\n",
       "         4.21499833e-04,  -3.24343389e-04,  -1.07824846e-04,\n",
       "        -3.77950382e-05,  -2.93885212e-04,  -3.26366280e-04,\n",
       "         1.60570853e-05,  -1.40737786e-04,  -1.94948560e-04,\n",
       "        -1.55786882e-04,  -9.15642086e-05,  -3.17094236e-04,\n",
       "        -4.14331502e-04,  -1.33498415e-05,   2.31759084e-04,\n",
       "         3.26631671e-05,  -2.34192499e-04,  -2.28763340e-04,\n",
       "         3.49463226e-04,   2.25231095e-04,  -6.33277887e-05,\n",
       "        -4.46521823e-04,   2.79126834e-05,   2.45643809e-04,\n",
       "        -4.30247776e-04,  -1.44359410e-05,  -3.40813393e-04,\n",
       "        -3.10753763e-04,   1.44841673e-04,   2.48528289e-04,\n",
       "         2.14781816e-04,   1.83456024e-04,  -5.40669571e-05,\n",
       "         2.69239739e-04,  -2.13408293e-05,  -3.38686339e-04,\n",
       "         2.05914475e-04,  -1.21536927e-04,   4.29649081e-04,\n",
       "        -8.50420620e-05,  -1.39591226e-04,  -1.08654574e-04,\n",
       "         2.96971906e-04,  -7.54236098e-05,  -6.40410930e-04,\n",
       "        -4.54187306e-04,  -4.29475731e-05,  -3.92169641e-05,\n",
       "        -3.35368852e-04,  -1.14273171e-04,  -1.13628303e-04,\n",
       "         1.44503967e-04,   1.35919081e-05,   1.80566582e-04,\n",
       "         1.82862292e-04,   2.82340661e-05,   2.02284191e-05,\n",
       "        -3.28535098e-04,   3.02586210e-04,   1.71524996e-04,\n",
       "         3.21095809e-04,  -8.29888086e-05,   2.34337218e-04,\n",
       "         5.13740815e-04,  -9.00276282e-05,  -1.94703651e-04,\n",
       "        -8.05412128e-05,   3.52817005e-04,  -1.30807402e-05,\n",
       "        -2.26725911e-04,   2.87114846e-04,   5.21100301e-05,\n",
       "        -3.74311116e-04,   2.42875409e-04,   9.30950046e-05,\n",
       "         1.80060699e-04,  -2.90201104e-04,  -3.07899696e-04,\n",
       "        -2.71904544e-04,   3.03965528e-04,  -2.19264446e-04,\n",
       "         9.62353151e-05,   1.05069172e-04,   2.05019707e-04,\n",
       "         9.76458468e-05,   9.76122974e-05,   1.05451189e-04,\n",
       "        -5.04169730e-04,  -2.19882466e-04,  -1.94011751e-04,\n",
       "         2.86991242e-04,   1.77154507e-04,  -5.57247404e-05,\n",
       "         1.23124162e-04,   1.14007795e-04,   1.83208704e-06,\n",
       "        -4.30054497e-04,  -9.30181341e-05,   2.84822367e-04,\n",
       "        -3.95256124e-04,   4.33909954e-05,   3.70067755e-05,\n",
       "        -1.61486198e-04,   4.83833748e-04,  -6.01709617e-05,\n",
       "        -2.73637415e-04,  -4.23585996e-04,  -1.05120365e-04,\n",
       "         2.43295784e-04,  -2.18401488e-04,  -2.38491004e-04,\n",
       "        -1.85187644e-04,  -2.60115194e-04,   4.27317485e-04,\n",
       "         1.49820233e-04,  -3.15817480e-04,  -1.26965955e-04,\n",
       "         4.70310420e-04,  -2.67791998e-04,   1.33442780e-04,\n",
       "         2.81923567e-04,   5.82121720e-05,  -4.76072659e-04,\n",
       "        -1.87024925e-04,   4.41217067e-04,  -1.23064849e-04,\n",
       "        -2.27639786e-04,   2.70861288e-04,   1.25604754e-04,\n",
       "        -7.38002564e-05,  -3.48348927e-04,   6.14489472e-05,\n",
       "        -2.96889251e-04,   9.66161770e-06,  -1.90061197e-04,\n",
       "         5.61931265e-05,  -1.12848184e-05,  -2.40051289e-04,\n",
       "        -3.19258579e-05,   4.81218740e-04,  -2.12032683e-04,\n",
       "        -5.95711026e-05,  -2.93920439e-05,  -1.40383127e-04,\n",
       "         9.31810337e-06,  -2.35404077e-04,  -2.27958211e-04,\n",
       "        -4.07758576e-04,  -3.30354349e-04,  -7.88847683e-06,\n",
       "        -2.52088998e-04,  -4.82866017e-04,  -5.49167162e-04,\n",
       "         3.47392561e-05,   3.23129672e-04,  -6.44028187e-04,\n",
       "         3.04290326e-04,  -3.38573700e-05,   5.51595527e-04,\n",
       "         1.37830270e-04,   5.02730487e-04,  -7.29293151e-06,\n",
       "        -1.73016102e-04,  -2.96346275e-06,  -7.70854967e-05,\n",
       "        -5.63309222e-05,   5.49858123e-05,   6.01336869e-05,\n",
       "        -3.40358645e-04,  -1.75393070e-04,  -2.40142006e-04,\n",
       "        -3.98106466e-04,  -8.40361608e-05,  -6.53956363e-07,\n",
       "         3.84799001e-04,   3.04309197e-05,   1.84286691e-05,\n",
       "        -1.72371929e-05,  -2.25867683e-04,  -2.91597942e-04,\n",
       "        -7.48170423e-05,   3.85882129e-04,   9.29640373e-05,\n",
       "        -1.62538083e-04,   7.93833635e-04,   5.63567410e-05,\n",
       "        -4.27339459e-04,  -2.43724149e-04,   4.46323611e-05,\n",
       "        -3.11766926e-04,  -2.93212652e-04,   5.96797918e-06,\n",
       "        -2.35284781e-04,  -2.07213569e-04,  -4.12537447e-05,\n",
       "         2.02353665e-04,  -6.75509102e-04,  -1.26934348e-04,\n",
       "         9.69088360e-05,  -3.51378898e-04,  -3.26151785e-04,\n",
       "         6.32781594e-05,   2.58499902e-04,   2.58335785e-04,\n",
       "         8.31658908e-05,   2.70637160e-04,   2.45734671e-04,\n",
       "         2.64228001e-04,  -3.99950513e-05,   3.77451302e-04,\n",
       "         4.04473918e-04,  -2.19689289e-04,   3.42621061e-04,\n",
       "         2.84448266e-04,  -1.62392011e-04,  -2.05154502e-05,\n",
       "        -3.46149427e-05,  -2.89206801e-04,  -1.88736565e-04,\n",
       "        -4.22571873e-04,  -2.33990228e-04,  -4.61386371e-04,\n",
       "        -1.05573919e-04,  -1.52524008e-04,  -2.00688955e-04,\n",
       "         8.15470703e-05,   3.95391980e-04,  -3.00775166e-04,\n",
       "        -1.28531276e-04,  -3.31903102e-05,   3.26128618e-04,\n",
       "         5.27121119e-05,   4.26562678e-04,   7.15545393e-05,\n",
       "         1.17639960e-04,   5.74938713e-05,   2.29865051e-04,\n",
       "        -5.10868304e-05,   1.34886985e-04,   4.55161535e-05,\n",
       "         2.13059597e-04,   2.12556028e-04,   1.36785704e-04,\n",
       "        -1.77369177e-04,  -8.32434466e-07,  -2.40686553e-04,\n",
       "        -6.58045683e-05,  -2.08171783e-04,  -4.35308903e-05,\n",
       "         8.30375429e-05,   3.20305349e-04,   6.77475182e-05,\n",
       "        -3.67902481e-04,   1.24969127e-04,  -4.17983683e-04,\n",
       "        -8.86088965e-05,  -2.42949081e-05,   2.99073698e-04,\n",
       "        -2.58349028e-05,   1.19954020e-04,   2.22260700e-04,\n",
       "        -1.02871250e-04,   2.20779330e-04,  -1.37924420e-04,\n",
       "         1.74199871e-04,   4.24781365e-06,  -9.76960200e-06,\n",
       "        -2.21910697e-04,   9.76866650e-05,   2.91121309e-04,\n",
       "        -1.85505633e-04,   4.52972599e-04,  -3.31918927e-05,\n",
       "         3.13812270e-05,  -1.27966530e-04,   1.97920526e-05,\n",
       "         1.90258448e-04,  -9.22913168e-05,   1.28327432e-04,\n",
       "        -1.00575882e-04,  -2.04628945e-04,   4.52630047e-04,\n",
       "         2.58989166e-04,  -2.87634582e-04,   3.43653577e-04,\n",
       "         1.66256068e-04,   1.01405516e-04,   1.44488426e-04])"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(articles_embeddings[0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "article_sim_matrix = cosine_similarity(articles_embeddings,articles_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1051, 1051)\n",
      "[[ 1.          0.89260991  0.85136431 ...,  0.90637616  0.83340432\n",
      "   0.91839827]\n",
      " [ 0.89260991  1.          0.82532192 ...,  0.86487499  0.77310817\n",
      "   0.91136227]\n",
      " [ 0.85136431  0.82532192  1.         ...,  0.73795058  0.83964449\n",
      "   0.82942558]\n",
      " ..., \n",
      " [ 0.90637616  0.86487499  0.73795058 ...,  1.          0.73814724\n",
      "   0.84457736]\n",
      " [ 0.83340432  0.77310817  0.83964449 ...,  0.73814724  1.          0.78341064]\n",
      " [ 0.91839827  0.91136227  0.82942558 ...,  0.84457736  0.78341064  1.        ]]\n"
     ]
    }
   ],
   "source": [
    "print(article_sim_matrix.shape)\n",
    "print(article_sim_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "article_id = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 324,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article_index = articles_tokens[articles_tokens['article_id'] == article_id].index.values[0]\n",
    "article_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.91099456,  0.92043368,  0.85107259, ...,  0.85049503,\n",
       "        0.85126576,  0.93771875])"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article_sim_row = article_sim_matrix[article_index,]\n",
    "article_sim_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.91099456,  0.92043368,  0.85107259,  1.        ,  0.9489999 ,\n",
       "        0.81747738,  0.77441643,  0.94891866,  0.91817132,  0.90954981])"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article_sim_row[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   3,   18,   82,  307,  333,  428,  524,  535,  555,  689,  743,\n",
       "        752,  754,  970,  997, 1031, 1043])"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similar_articles = (article_sim_row >= 0.95).nonzero()[0]\n",
    "similar_articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:1: DeprecationWarning: using a non-integer array as obj in delete will result in an error in the future\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([  82,  307,  333,  428,  524,  535,  555,  689,  743,  752,  754,\n",
       "        970,  997, 1031, 1043])"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.delete((article_sim_row >= 0.95).nonzero()[0],article_sim_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  3, 689, 524, ..., 354, 916, 765])"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article_sim_row.argsort()[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False, ..., False, False, False], dtype=bool)"
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = (article_sim_row > 0.95)\n",
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "sort_idx = article_sim_row.argsort()[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = sort_idx[mask[sort_idx]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   3,  689,  524,  428,   18,  333,  970, 1043,  754,  555,   82,\n",
       "        307,  752,  743, 1031,  535,  997])"
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 689,  524,  428,   18,  333,  970, 1043,  754,  555,   82,  307,\n",
       "        752,  743, 1031,  535,  997])"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out[out != article_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>interaction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>45993.000000</td>\n",
       "      <td>45993.000000</td>\n",
       "      <td>45993.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>908.846477</td>\n",
       "      <td>2300.918314</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>486.647866</td>\n",
       "      <td>1712.658385</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>460.000000</td>\n",
       "      <td>621.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1151.000000</td>\n",
       "      <td>2330.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1336.000000</td>\n",
       "      <td>3835.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1444.000000</td>\n",
       "      <td>5149.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         article_id       user_id  interaction\n",
       "count  45993.000000  45993.000000      45993.0\n",
       "mean     908.846477   2300.918314          1.0\n",
       "std      486.647866   1712.658385          0.0\n",
       "min        0.000000      1.000000          1.0\n",
       "25%      460.000000    621.000000          1.0\n",
       "50%     1151.000000   2330.000000          1.0\n",
       "75%     1336.000000   3835.000000          1.0\n",
       "max     1444.000000   5149.000000          1.0"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>doc_description</th>\n",
       "      <th>tokens_str</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Detect bad readings in real time using Python ...</td>\n",
       "      <td>detect bad reading real time using python stre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>See the forest, see the trees. Here lies the c...</td>\n",
       "      <td>see forest see tree lie challenge performing p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Here’s this week’s news in Data Science and Bi...</td>\n",
       "      <td>week news data science big data</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Learn how distributed DBs solve the problem of...</td>\n",
       "      <td>learn distributed db solve problem scaling per...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>This video demonstrates the power of IBM DataS...</td>\n",
       "      <td>video demonstrates power ibm datascience exper...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>Using Compose's PostgreSQL data browser.</td>\n",
       "      <td>using compose postgresql data browser</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>Upgrading your PostgreSQL deployment to versio...</td>\n",
       "      <td>upgrading postgresql deployment version 9 5 po...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>For a company like Slack that strives to be as...</td>\n",
       "      <td>company like slack strives data driven possibl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>Kaggle is your home for data science. Learn ne...</td>\n",
       "      <td>kaggle home data science learn new skill build...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>[A version of this post appears on the O’Reill...</td>\n",
       "      <td>version post appears reilly radar reilly data ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>Apple's sample app, Food Tracker, taught you i...</td>\n",
       "      <td>apple sample app food tracker taught io take s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>Replicating data to a relational dashDB databa...</td>\n",
       "      <td>replicating data relational dashdb database gr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    article_id                                    doc_description  \\\n",
       "0            0  Detect bad readings in real time using Python ...   \n",
       "1            1  See the forest, see the trees. Here lies the c...   \n",
       "2            2  Here’s this week’s news in Data Science and Bi...   \n",
       "3            3  Learn how distributed DBs solve the problem of...   \n",
       "4            4  This video demonstrates the power of IBM DataS...   \n",
       "5            5           Using Compose's PostgreSQL data browser.   \n",
       "6            6  Upgrading your PostgreSQL deployment to versio...   \n",
       "7            7  For a company like Slack that strives to be as...   \n",
       "8            8  Kaggle is your home for data science. Learn ne...   \n",
       "9            9  [A version of this post appears on the O’Reill...   \n",
       "10          10  Apple's sample app, Food Tracker, taught you i...   \n",
       "11          11  Replicating data to a relational dashDB databa...   \n",
       "\n",
       "                                           tokens_str  \n",
       "0   detect bad reading real time using python stre...  \n",
       "1   see forest see tree lie challenge performing p...  \n",
       "2                     week news data science big data  \n",
       "3   learn distributed db solve problem scaling per...  \n",
       "4   video demonstrates power ibm datascience exper...  \n",
       "5               using compose postgresql data browser  \n",
       "6   upgrading postgresql deployment version 9 5 po...  \n",
       "7   company like slack strives data driven possibl...  \n",
       "8   kaggle home data science learn new skill build...  \n",
       "9   version post appears reilly radar reilly data ...  \n",
       "10  apple sample app food tracker taught io take s...  \n",
       "11  replicating data relational dashdb database gr...  "
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles_tokens.head(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_articles_similarity_matrix():\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_similar_articles(article_id, min_similarity_threshold=0.95):\n",
    "    '''\n",
    "    INPUT\n",
    "    article_id - an article_id \n",
    "    OUTPUT\n",
    "    similar_articles - an array of the most similar articles by id\n",
    "    '''\n",
    "    \n",
    "    try:\n",
    "        # find the row of the article id\n",
    "        article_index = articles_tokens[articles_tokens['article_id'] == article_id].index.values[0]\n",
    "\n",
    "        # find the most similar article indices using similarity_threshold\n",
    "        article_sim_row = article_sim_matrix[article_index,]\n",
    "        mask = (article_sim_row > min_similarity_threshold)\n",
    "        sort_idx = article_sim_row.argsort()[::-1]\n",
    "        sim_articles_indices = sort_idx[mask[sort_idx]]\n",
    "\n",
    "        # remove the actual article index from the similar articles list\n",
    "        sim_articles_indices = sim_articles_indices[sim_articles_indices != article_index]\n",
    "\n",
    "        similar_articles = sim_articles_indices\n",
    "    \n",
    "        return similar_articles\n",
    "    \n",
    "    except IndexError:\n",
    "        print('Article ID {} not found in database'.format(article_id))\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_content_recs(user_id, user_articles_interactions=user_articles_interactions, num_recs=10):\n",
    "    '''\n",
    "    INPUT:\n",
    "    \n",
    "    OUTPUT:\n",
    "    \n",
    "    '''\n",
    "    # Pull only the articles the user has seen\n",
    "    user_seen_articles = user_articles_interactions[user_articles_interactions['user_id'] == user_id].article_id.values\n",
    "    # Look at each of the user_seen_articles (higher interactions first)\n",
    "    user_recs = []\n",
    "    for seen_article_id in user_seen_articles:\n",
    "        # pull the articles the user hasn't seen that are most similar\n",
    "        seen_article_similar_articles = find_similar_articles(seen_article_id)\n",
    "        \n",
    "        # if no similar article could be found, skip\n",
    "        if len(seen_article_similar_articles) == 0:\n",
    "            continue\n",
    "        \n",
    "        seen_article_similar_recs = np.setdiff1d(seen_article_similar_articles,\n",
    "                                                 user_seen_articles,\n",
    "                                                 assume_unique=True)\n",
    "        user_recs = np.unique(np.concatenate([user_recs,seen_article_similar_recs]))\n",
    "\n",
    "        # These will be the recommendations - continue until num_recs \n",
    "        # or you have depleted the movie list for the user\n",
    "        if user_recs.shape[0] > num_recs:\n",
    "            user_recs = user_recs[:num_recs]\n",
    "            break\n",
    "\n",
    "    return user_recs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 122.,  234.,  333.,  396.,  423.,  535.,  563.,  576.,  600.,  786.])"
      ]
     },
     "execution_count": 355,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "make_content_recs(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Article ID 1330.0 not found in database\n",
      "Article ID 1185.0 not found in database\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([  95.,  104.,  122.,  125.,  234.,  333.,  396.,  406.,  423.,  535.])"
      ]
     },
     "execution_count": 356,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "make_content_recs(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(714,)"
      ]
     },
     "execution_count": 357,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.unique(df.article_id).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`2.` Now that you have put together your content-based recommendation system, use the cell below to write a summary explaining how your content based recommender works.  Do you see any possible improvements that could be made to your function?  Is there anything novel about your content based recommender?\n",
    "\n",
    "### This part is NOT REQUIRED to pass this project.  However, you may choose to take this on as an extra way to show off your skills."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First I needed to create a similarity matrix for the articles. I trained a Word2Vec Model which generated 300 features using TF-IDF as feature weights. Then, I used this model to generate the features for all articles in df_content dataset.\n",
    "\n",
    "Having computed the embeddings for all articles, I gerated a similarity matrix by computing the cosine similarity between every pair of articles.\n",
    "\n",
    "Then, finding the articles similar to a given article was just a matter of ordering the article row in the similarity matrix. I also used a min similarity threshold equal to 0.95.\n",
    "\n",
    "In order to generate the content based recommendations, I loop through the articles the user has already seen, retrieve an ordered list of the most similar articles to the seen ones, and remove the ones which the user has already seen.\n",
    "\n",
    "If I cannot find the article the user has seen within my similarity matrix, I skip to the next one.\n",
    "\n",
    "A way to improve my function would be to add to the df_content articles the ones which can only be found in df, and use their title to extract the tokens for further processing.\n",
    "\n",
    "For users with no seen articles, I could recommend the top seen articles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`3.` Use your content-recommendation system to make recommendations for the below scenarios based on the comments.  Again no tests are provided here, because there isn't one right answer that could be used to find these content based recommendations.\n",
    "\n",
    "### This part is NOT REQUIRED to pass this project.  However, you may choose to take this on as an extra way to show off your skills."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_content_recs2(user_id, user_articles_interactions=user_articles_interactions, num_recs=10):\n",
    "    '''\n",
    "    INPUT:\n",
    "    \n",
    "    OUTPUT:\n",
    "    \n",
    "    '''\n",
    "    # Pull only the articles the user has seen\n",
    "    user_seen_articles = user_articles_interactions[user_articles_interactions['user_id'] == user_id].article_id.values\n",
    "    # Look at each of the user_seen_articles (higher interactions first)\n",
    "    user_recs = []\n",
    "    \n",
    "    if len(user_seen_articles) == 0:\n",
    "        user_recs = get_top_article_ids(num_recs)\n",
    "    \n",
    "    else:    \n",
    "        for seen_article_id in user_seen_articles:\n",
    "            # pull the articles the user hasn't seen that are most similar\n",
    "            seen_article_similar_articles = find_similar_articles(seen_article_id)\n",
    "\n",
    "            # if no similar article could be found, skip\n",
    "            if len(seen_article_similar_articles) == 0:\n",
    "                continue\n",
    "\n",
    "            seen_article_similar_recs = np.setdiff1d(seen_article_similar_articles,\n",
    "                                                     user_seen_articles,\n",
    "                                                     assume_unique=True)\n",
    "            user_recs = np.unique(np.concatenate([user_recs,seen_article_similar_recs]))\n",
    "\n",
    "            # These will be the recommendations - continue until num_recs \n",
    "            # or you have depleted the movie list for the user\n",
    "            if user_recs.shape[0] > num_recs:\n",
    "                user_recs = user_recs[:num_recs]\n",
    "                break\n",
    "\n",
    "    return user_recs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make recommendations for a brand new user\n",
    "# Choose from the top-articles\n",
    "recs_new_user = make_content_recs2(399999)\n",
    "\n",
    "# make a recommendations for a user who only has interacted with article id '1427.0'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1429.0',\n",
       " '1330.0',\n",
       " '1431.0',\n",
       " '1427.0',\n",
       " '1364.0',\n",
       " '1314.0',\n",
       " '1293.0',\n",
       " '1170.0',\n",
       " '1162.0',\n",
       " '1304.0']"
      ]
     },
     "execution_count": 363,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recs_new_user"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a class=\"anchor\" id=\"Matrix-Fact\">Part V: Matrix Factorization</a>\n",
    "\n",
    "In this part of the notebook, you will build use matrix factorization to make article recommendations to the users on the IBM Watson Studio platform.\n",
    "\n",
    "`1.` You should have already created a **user_item** matrix above in **question 1** of **Part III** above.  This first question here will just require that you run the cells to get things set up for the rest of **Part V** of the notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the matrix here\n",
    "user_item_matrix = pd.read_pickle('user_item_matrix.p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>article_id</th>\n",
       "      <th>0.0</th>\n",
       "      <th>100.0</th>\n",
       "      <th>1000.0</th>\n",
       "      <th>1004.0</th>\n",
       "      <th>1006.0</th>\n",
       "      <th>1008.0</th>\n",
       "      <th>101.0</th>\n",
       "      <th>1014.0</th>\n",
       "      <th>1015.0</th>\n",
       "      <th>1016.0</th>\n",
       "      <th>...</th>\n",
       "      <th>977.0</th>\n",
       "      <th>98.0</th>\n",
       "      <th>981.0</th>\n",
       "      <th>984.0</th>\n",
       "      <th>985.0</th>\n",
       "      <th>986.0</th>\n",
       "      <th>990.0</th>\n",
       "      <th>993.0</th>\n",
       "      <th>996.0</th>\n",
       "      <th>997.0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 714 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "article_id  0.0  100.0  1000.0  1004.0  1006.0  1008.0  101.0  1014.0  1015.0  \\\n",
       "user_id                                                                         \n",
       "1           0.0    0.0     0.0     0.0     0.0     0.0    0.0     0.0     0.0   \n",
       "2           0.0    0.0     0.0     0.0     0.0     0.0    0.0     0.0     0.0   \n",
       "3           0.0    0.0     0.0     0.0     0.0     0.0    0.0     0.0     0.0   \n",
       "4           0.0    0.0     0.0     0.0     0.0     0.0    0.0     0.0     0.0   \n",
       "5           0.0    0.0     0.0     0.0     0.0     0.0    0.0     0.0     0.0   \n",
       "\n",
       "article_id  1016.0  ...    977.0  98.0  981.0  984.0  985.0  986.0  990.0  \\\n",
       "user_id             ...                                                     \n",
       "1              0.0  ...      0.0   0.0    1.0    0.0    0.0    0.0    0.0   \n",
       "2              0.0  ...      0.0   0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "3              0.0  ...      1.0   0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "4              0.0  ...      0.0   0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "5              0.0  ...      0.0   0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "\n",
       "article_id  993.0  996.0  997.0  \n",
       "user_id                          \n",
       "1             0.0    0.0    0.0  \n",
       "2             0.0    0.0    0.0  \n",
       "3             0.0    0.0    0.0  \n",
       "4             0.0    0.0    0.0  \n",
       "5             0.0    0.0    0.0  \n",
       "\n",
       "[5 rows x 714 columns]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# quick look at the matrix\n",
    "user_item_matrix.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`2.` In this situation, you can use Singular Value Decomposition from [numpy](https://docs.scipy.org/doc/numpy-1.14.0/reference/generated/numpy.linalg.svd.html) on the user-item matrix.  Use the cell to perform SVD, and explain why this is different than in the lesson."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform SVD on the User-Item Matrix Here\n",
    "\n",
    "u, s, vt = np.linalg.svd(user_item_matrix)# use the built in to get the three matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standard SVD algorithm can be run on the user_item matrix as there is no Null value - all cells with no interactions are set as 0. Thus, it is possible to perform the computation for the whole matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`3.` Now for the tricky part, how do we choose the number of latent features to use?  Running the below cell, you can see that as the number of latent features increases, we obtain a lower error rate on making predictions for the 1 and 0 values in the user-item matrix.  Run the cell below to get an idea of how the accuracy improves as we increase the number of latent features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f1c8d4e3dd8>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_latent_feats = np.arange(10,700+10,20)\n",
    "sum_errs = []\n",
    "\n",
    "for k in num_latent_feats:\n",
    "    # restructure with k latent features\n",
    "    s_new, u_new, vt_new = np.diag(s[:k]), u[:, :k], vt[:k, :]\n",
    "    \n",
    "    # take dot product\n",
    "    user_item_est = np.around(np.dot(np.dot(u_new, s_new), vt_new))\n",
    "    \n",
    "    # compute error for each prediction to actual value\n",
    "    diffs = np.subtract(user_item_matrix, user_item_est)\n",
    "    \n",
    "    # total errors and keep track of them\n",
    "    err = np.sum(np.sum(np.abs(diffs)))\n",
    "    sum_errs.append(err)\n",
    "    \n",
    "    \n",
    "plt.plot(num_latent_feats, 1 - np.array(sum_errs)/df.shape[0]);\n",
    "plt.xlabel('Number of Latent Features');\n",
    "plt.ylabel('Accuracy');\n",
    "plt.title('Accuracy vs. Number of Latent Features');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`4.` From the above, we can't really be sure how many features to use, because simply having a better way to predict the 1's and 0's of the matrix doesn't exactly give us an indication of if we are able to make good recommendations.  Instead, we might split our dataset into a training and test set of data, as shown in the cell below.  \n",
    "\n",
    "Use the code from question 3 to understand the impact on accuracy of the training and test sets of data with different numbers of latent features. Using the split below: \n",
    "\n",
    "* How many users can we make predictions for in the test set?  \n",
    "* How many users are we not able to make predictions for because of the cold start problem?\n",
    "* How many articles can we make predictions for in the test set?  \n",
    "* How many articles are we not able to make predictions for because of the cold start problem?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    }
   ],
   "source": [
    "df_train = df.head(40000)\n",
    "df_test = df.tail(5993)\n",
    "\n",
    "def create_test_and_train_user_item(df_train, df_test):\n",
    "    '''\n",
    "    INPUT:\n",
    "    df_train - training dataframe\n",
    "    df_test - test dataframe\n",
    "    \n",
    "    OUTPUT:\n",
    "    user_item_train - a user-item matrix of the training dataframe \n",
    "                      (unique users for each row and unique articles for each column)\n",
    "    user_item_test - a user-item matrix of the testing dataframe \n",
    "                    (unique users for each row and unique articles for each column)\n",
    "    test_idx - all of the test user ids\n",
    "    test_arts - all of the test article ids\n",
    "    \n",
    "    '''\n",
    "    user_item_train = create_user_item_matrix(df_train)\n",
    "    user_item_test = create_user_item_matrix(df_test)\n",
    "    \n",
    "    test_idx = user_item_test.index.values\n",
    "    test_arts = user_item_test.columns.values\n",
    "    \n",
    "    return user_item_train, user_item_test, test_idx, test_arts\n",
    "\n",
    "user_item_train, user_item_test, test_idx, test_arts = create_test_and_train_user_item(df_train, df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_users_not_in_train = np.setdiff1d(test_idx,user_item_train.index.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(662,)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_users_not_in_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_idx.shape[0] - test_users_not_in_train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_articles_not_in_train = np.setdiff1d(test_arts,user_item_train.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0,)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_articles_not_in_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "574"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_arts.shape[0] - test_articles_not_in_train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Awesome job!  That's right!  All of the test movies are in the training data, but there are only 20 test users that were also in the training set.  All of the other users that are in the test set we have no data on.  Therefore, we cannot make predictions for these users using SVD.\n"
     ]
    }
   ],
   "source": [
    "# Replace the values in the dictionary below\n",
    "a = 662 \n",
    "b = 574 \n",
    "c = 20 \n",
    "d = 0 \n",
    "\n",
    "\n",
    "sol_4_dict = {\n",
    "    'How many users can we make predictions for in the test set?': c,# letter here, \n",
    "    'How many users in the test set are we not able to make predictions for because of the cold start problem?': a,# letter here, \n",
    "    'How many movies can we make predictions for in the test set?': b,# letter here,\n",
    "    'How many movies in the test set are we not able to make predictions for because of the cold start problem?': d# letter here\n",
    "}\n",
    "\n",
    "t.sol_4_test(sol_4_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`5.` Now use the **user_item_train** dataset from above to find U, S, and V transpose using SVD. Then find the subset of rows in the **user_item_test** dataset that you can predict using this matrix decomposition with different numbers of latent features to see how many features makes sense to keep based on the accuracy on the test data. This will require combining what was done in questions `2` - `4`.\n",
    "\n",
    "Use the cells below to explore how well SVD works towards making predictions for recommendations on the test data.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit SVD on the user_item_train matrix\n",
    "u_train, s_train, vt_train = np.linalg.svd(user_item_train)# fit svd similar to above then use the cells below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4487, 4487) (714,) (714, 714)\n"
     ]
    }
   ],
   "source": [
    "print(u_train.shape, s_train.shape, vt_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>article_id</th>\n",
       "      <th>0.0</th>\n",
       "      <th>2.0</th>\n",
       "      <th>4.0</th>\n",
       "      <th>8.0</th>\n",
       "      <th>9.0</th>\n",
       "      <th>12.0</th>\n",
       "      <th>14.0</th>\n",
       "      <th>15.0</th>\n",
       "      <th>16.0</th>\n",
       "      <th>18.0</th>\n",
       "      <th>...</th>\n",
       "      <th>1434.0</th>\n",
       "      <th>1435.0</th>\n",
       "      <th>1436.0</th>\n",
       "      <th>1437.0</th>\n",
       "      <th>1439.0</th>\n",
       "      <th>1440.0</th>\n",
       "      <th>1441.0</th>\n",
       "      <th>1442.0</th>\n",
       "      <th>1443.0</th>\n",
       "      <th>1444.0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4483</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4484</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4485</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4486</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4487</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 714 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "article_id  0.0     2.0     4.0     8.0     9.0     12.0    14.0    15.0    \\\n",
       "user_id                                                                      \n",
       "4483           0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "4484           0.0     1.0     0.0     1.0     0.0     0.0     0.0     0.0   \n",
       "4485           0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "4486           0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "4487           0.0     0.0     0.0     1.0     0.0     0.0     0.0     0.0   \n",
       "\n",
       "article_id  16.0    18.0     ...    1434.0  1435.0  1436.0  1437.0  1439.0  \\\n",
       "user_id                      ...                                             \n",
       "4483           0.0     0.0   ...       0.0     0.0     0.0     0.0     0.0   \n",
       "4484           0.0     0.0   ...       0.0     0.0     0.0     0.0     0.0   \n",
       "4485           0.0     0.0   ...       0.0     0.0     0.0     0.0     0.0   \n",
       "4486           0.0     0.0   ...       0.0     0.0     0.0     0.0     0.0   \n",
       "4487           0.0     0.0   ...       0.0     0.0     0.0     0.0     0.0   \n",
       "\n",
       "article_id  1440.0  1441.0  1442.0  1443.0  1444.0  \n",
       "user_id                                             \n",
       "4483           0.0     0.0     0.0     0.0     0.0  \n",
       "4484           0.0     0.0     0.0     0.0     0.0  \n",
       "4485           0.0     0.0     0.0     0.0     0.0  \n",
       "4486           0.0     0.0     0.0     0.0     0.0  \n",
       "4487           0.0     0.0     0.0     0.0     0.0  \n",
       "\n",
       "[5 rows x 714 columns]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_item_train.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4487, 714)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_item_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_users_in_train = np.intersect1d(test_idx,user_item_train.index.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2917, 3024, 3093, 3193, 3527, 3532, 3684, 3740, 3777, 3801, 3968,\n",
       "       3989, 3990, 3998, 4002, 4204, 4231, 4274, 4293, 4487])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_users_in_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 4487)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u_train[test_users_in_train-1,:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4487, 714)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_item_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>article_id</th>\n",
       "      <th>0.0</th>\n",
       "      <th>2.0</th>\n",
       "      <th>4.0</th>\n",
       "      <th>8.0</th>\n",
       "      <th>9.0</th>\n",
       "      <th>12.0</th>\n",
       "      <th>14.0</th>\n",
       "      <th>15.0</th>\n",
       "      <th>16.0</th>\n",
       "      <th>18.0</th>\n",
       "      <th>...</th>\n",
       "      <th>1432.0</th>\n",
       "      <th>1433.0</th>\n",
       "      <th>1434.0</th>\n",
       "      <th>1435.0</th>\n",
       "      <th>1436.0</th>\n",
       "      <th>1437.0</th>\n",
       "      <th>1439.0</th>\n",
       "      <th>1440.0</th>\n",
       "      <th>1441.0</th>\n",
       "      <th>1443.0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2917</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3024</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3093</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3193</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3527</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3532</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3684</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3740</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3777</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3801</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3968</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3989</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3990</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3998</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4002</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4204</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4231</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4274</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4293</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4487</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20 rows × 574 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "article_id  0.0     2.0     4.0     8.0     9.0     12.0    14.0    15.0    \\\n",
       "user_id                                                                      \n",
       "2917           0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "3024           0.0     0.0     0.0     0.0     0.0     1.0     0.0     0.0   \n",
       "3093           0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "3193           0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "3527           0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "3532           0.0     0.0     0.0     0.0     0.0     1.0     0.0     0.0   \n",
       "3684           0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "3740           0.0     0.0     0.0     0.0     0.0     1.0     0.0     0.0   \n",
       "3777           0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "3801           0.0     0.0     0.0     0.0     0.0     1.0     0.0     0.0   \n",
       "3968           0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "3989           0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "3990           0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "3998           0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "4002           0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "4204           0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "4231           0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "4274           0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "4293           0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "4487           0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "\n",
       "article_id  16.0    18.0     ...    1432.0  1433.0  1434.0  1435.0  1436.0  \\\n",
       "user_id                      ...                                             \n",
       "2917           0.0     0.0   ...       0.0     0.0     0.0     0.0     0.0   \n",
       "3024           0.0     0.0   ...       0.0     0.0     0.0     0.0     0.0   \n",
       "3093           0.0     0.0   ...       0.0     0.0     0.0     0.0     1.0   \n",
       "3193           0.0     0.0   ...       0.0     0.0     0.0     0.0     0.0   \n",
       "3527           0.0     0.0   ...       0.0     0.0     0.0     0.0     0.0   \n",
       "3532           0.0     0.0   ...       0.0     0.0     0.0     0.0     1.0   \n",
       "3684           0.0     0.0   ...       0.0     0.0     0.0     0.0     0.0   \n",
       "3740           0.0     0.0   ...       0.0     0.0     0.0     0.0     1.0   \n",
       "3777           0.0     0.0   ...       0.0     0.0     0.0     0.0     0.0   \n",
       "3801           0.0     0.0   ...       0.0     0.0     0.0     0.0     0.0   \n",
       "3968           0.0     0.0   ...       0.0     0.0     0.0     0.0     0.0   \n",
       "3989           0.0     0.0   ...       0.0     0.0     0.0     0.0     0.0   \n",
       "3990           0.0     0.0   ...       0.0     0.0     0.0     0.0     0.0   \n",
       "3998           0.0     0.0   ...       0.0     0.0     0.0     0.0     0.0   \n",
       "4002           0.0     0.0   ...       0.0     0.0     0.0     0.0     0.0   \n",
       "4204           0.0     0.0   ...       0.0     0.0     0.0     0.0     0.0   \n",
       "4231           0.0     0.0   ...       0.0     0.0     0.0     0.0     1.0   \n",
       "4274           0.0     0.0   ...       0.0     0.0     0.0     0.0     0.0   \n",
       "4293           0.0     0.0   ...       0.0     0.0     0.0     0.0     1.0   \n",
       "4487           0.0     0.0   ...       0.0     0.0     0.0     0.0     0.0   \n",
       "\n",
       "article_id  1437.0  1439.0  1440.0  1441.0  1443.0  \n",
       "user_id                                             \n",
       "2917           0.0     0.0     0.0     0.0     0.0  \n",
       "3024           0.0     0.0     0.0     0.0     0.0  \n",
       "3093           0.0     0.0     0.0     0.0     0.0  \n",
       "3193           0.0     0.0     0.0     0.0     0.0  \n",
       "3527           0.0     0.0     0.0     0.0     0.0  \n",
       "3532           0.0     0.0     0.0     0.0     0.0  \n",
       "3684           0.0     0.0     0.0     0.0     0.0  \n",
       "3740           0.0     0.0     0.0     0.0     0.0  \n",
       "3777           0.0     0.0     0.0     0.0     0.0  \n",
       "3801           0.0     0.0     0.0     0.0     0.0  \n",
       "3968           0.0     0.0     0.0     0.0     0.0  \n",
       "3989           0.0     0.0     0.0     0.0     0.0  \n",
       "3990           0.0     0.0     0.0     0.0     0.0  \n",
       "3998           0.0     0.0     0.0     0.0     0.0  \n",
       "4002           0.0     0.0     0.0     0.0     0.0  \n",
       "4204           0.0     0.0     0.0     0.0     0.0  \n",
       "4231           0.0     0.0     0.0     0.0     0.0  \n",
       "4274           0.0     0.0     0.0     0.0     0.0  \n",
       "4293           0.0     0.0     0.0     0.0     0.0  \n",
       "4487           0.0     0.0     0.0     0.0     0.0  \n",
       "\n",
       "[20 rows x 574 columns]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_item_test.loc[test_users_in_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(test_users_not_in_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "k=10\n",
    "s_new, u_new, vt_new = np.diag(s_train[:k]), u_train[:, :k], vt_train[:k, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4487, 10) (10, 10) (10, 714)\n"
     ]
    }
   ],
   "source": [
    "print(u_new.shape, s_new.shape, vt_new.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_item_est = np.around(np.dot(np.dot(u_new, s_new), vt_new))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4487, 714)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0., ..., -0.,  0.,  0.],\n",
       "       [ 0.,  0., -0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0., -0., ...,  0.,  0., -0.],\n",
       "       ..., \n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [-0.,  0., -0., ..., -0.,  0.,  0.],\n",
       "       [ 0.,  0., -0., ...,  0.,  0., -0.]])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(user_item_est.shape)\n",
    "user_item_est"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_user_items_in_train = np.in1d(user_item_train.columns.values, user_item_test.columns.values).nonzero()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(574,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n",
       "        13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,\n",
       "        26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,\n",
       "        39,  40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,\n",
       "        52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,\n",
       "        65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
       "        78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,\n",
       "        91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103,\n",
       "       104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116,\n",
       "       117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129,\n",
       "       130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142,\n",
       "       143, 145, 146, 147, 149, 150, 151, 152, 153, 154, 155, 156, 157,\n",
       "       158, 159, 160, 161, 162, 163, 167, 168, 169, 171, 172, 173, 174,\n",
       "       175, 176, 177, 178, 179, 180, 181, 183, 184, 185, 186, 187, 190,\n",
       "       191, 192, 193, 197, 198, 200, 202, 203, 204, 205, 206, 207, 208,\n",
       "       209, 210, 211, 213, 214, 216, 217, 218, 219, 220, 222, 223, 224,\n",
       "       225, 228, 229, 230, 232, 233, 234, 235, 236, 239, 240, 241, 242,\n",
       "       245, 246, 247, 248, 249, 250, 253, 255, 256, 257, 258, 259, 260,\n",
       "       261, 263, 264, 265, 266, 268, 269, 270, 272, 274, 275, 276, 278,\n",
       "       279, 280, 281, 283, 284, 286, 287, 288, 291, 293, 294, 295, 296,\n",
       "       298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 311,\n",
       "       312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 323, 325, 326,\n",
       "       327, 328, 329, 333, 334, 335, 336, 337, 340, 341, 342, 343, 344,\n",
       "       345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357,\n",
       "       358, 359, 360, 361, 362, 363, 364, 365, 367, 368, 370, 371, 372,\n",
       "       373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 386,\n",
       "       387, 390, 391, 392, 393, 394, 395, 396, 398, 399, 400, 401, 402,\n",
       "       403, 404, 406, 407, 408, 411, 412, 413, 414, 415, 416, 418, 419,\n",
       "       420, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 433, 434,\n",
       "       435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 451,\n",
       "       454, 456, 457, 459, 460, 462, 464, 465, 466, 482, 483, 485, 486,\n",
       "       487, 493, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505,\n",
       "       506, 507, 508, 509, 510, 511, 513, 514, 515, 516, 517, 518, 519,\n",
       "       520, 521, 522, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534,\n",
       "       535, 536, 537, 538, 539, 540, 541, 542, 544, 545, 546, 547, 549,\n",
       "       551, 559, 561, 566, 576, 579, 580, 582, 583, 584, 585, 586, 587,\n",
       "       588, 589, 590, 592, 593, 594, 595, 596, 597, 598, 599, 600, 603,\n",
       "       604, 605, 606, 608, 609, 610, 611, 613, 614, 615, 616, 617, 618,\n",
       "       619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 631, 632, 633,\n",
       "       635, 639, 640, 641, 642, 644, 645, 646, 647, 648, 649, 650, 652,\n",
       "       653, 654, 655, 656, 660, 661, 662, 663, 665, 666, 667, 668, 669,\n",
       "       670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682,\n",
       "       683, 684, 685, 686, 687, 688, 689, 690, 692, 693, 694, 695, 696,\n",
       "       697, 698, 699, 700, 701, 702, 703, 704, 705, 706, 707, 708, 709,\n",
       "       710, 712])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(test_user_items_in_train.shape)\n",
    "test_user_items_in_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_user_item_est = user_item_est[(test_users_in_train-1)[:, None],test_user_items_in_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 574)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-0.,  0.,  0., ..., -0., -0.,  0.],\n",
       "       [ 0.,  0.,  0., ..., -0., -0., -0.],\n",
       "       [-0.,  0.,  0., ..., -0., -0., -0.],\n",
       "       ..., \n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0., -0., ...,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(test_user_item_est.shape)\n",
    "test_user_item_est"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f1c8d586278>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Use these cells to see how well you can use the training \n",
    "# decomposition to predict on test data\n",
    "num_latent_feats = np.arange(10,700+10,20)\n",
    "sum_errs = []\n",
    "test_users_in_train_indices = np.intersect1d(test_idx,user_item_train.index.values)\n",
    "test_user_articles_in_train = np.in1d(user_item_train.columns.values, user_item_test.columns.values).nonzero()[0]\n",
    "filtered_user_item_test = user_item_test.loc[test_users_in_train_indices,:]\n",
    "\n",
    "for k in num_latent_feats:\n",
    "    # restructure with k latent features\n",
    "    s_new, u_new, vt_new = np.diag(s_train[:k]), u_train[:, :k], vt_train[:k, :]\n",
    "    \n",
    "    # take dot product\n",
    "    user_item_est = np.around(np.dot(np.dot(u_new, s_new), vt_new))\n",
    "    \n",
    "    # select subset of estimation matrix which comprises test intersection users/articles\n",
    "    test_user_item_est = user_item_est[(test_users_in_train_indices-1)[:, None],test_user_articles_in_train]\n",
    "    \n",
    "    # compute error for each prediction to actual value\n",
    "    diffs = np.subtract(filtered_user_item_test, test_user_item_est)\n",
    "    \n",
    "    # total errors and keep track of them\n",
    "    err = np.sum(np.sum(np.abs(diffs)))\n",
    "    sum_errs.append(err)\n",
    "    \n",
    "    \n",
    "plt.plot(num_latent_feats, 1 - np.array(sum_errs)/df.shape[0]);\n",
    "plt.xlabel('Number of Latent Features');\n",
    "plt.ylabel('Accuracy');\n",
    "plt.title('Accuracy vs. Number of Latent Features');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "`6.` Use the cell below to comment on the results you found in the previous question. Given the circumstances of your results, discuss what you might do to determine if the recommendations you make with any of the above recommendation systems are an improvement to how users currently find articles? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see in the above plot, the accuracy for the prediction of interactions between users and articles in the test set (considering only the subset which intersects with train set), the accuracy is always very high (over 99%) and the number of latent features does not influence that much. Thus, we could just keep the lower amount of the tested range (10).\n",
    "\n",
    "In order to evaluate the actual improvement the recommendations developed in this notebook will have on how users currently find articles, we could design an A/B Testing, and check if the users receiving recommendations using the above techniques interact with the recommended articles, and if their overall level of interaction increases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<a id='conclusions'></a>\n",
    "### Extras\n",
    "Using your workbook, you could now save your recommendations for each user, develop a class to make new predictions and update your results, and make a flask app to deploy your results.  These tasks are beyond what is required for this project.  However, from what you learned in the lessons, you certainly capable of taking these tasks on to improve upon your work here!\n",
    "\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "> Congratulations!  You have reached the end of the Recommendations with IBM project! \n",
    "\n",
    "> **Tip**: Once you are satisfied with your work here, check over your report to make sure that it is satisfies all the areas of the [rubric](https://review.udacity.com/#!/rubrics/2322/view). You should also probably remove all of the \"Tips\" like this one so that the presentation is as polished as possible.\n",
    "\n",
    "\n",
    "## Directions to Submit\n",
    "\n",
    "> Before you submit your project, you need to create a .html or .pdf version of this notebook in the workspace here. To do that, run the code cell below. If it worked correctly, you should get a return code of 0, and you should see the generated .html file in the workspace directory (click on the orange Jupyter icon in the upper left).\n",
    "\n",
    "> Alternatively, you can download this report as .html via the **File** > **Download as** submenu, and then manually upload it into the workspace directory by clicking on the orange Jupyter icon in the upper left, then using the Upload button.\n",
    "\n",
    "> Once you've done this, you can submit your project by clicking on the \"Submit Project\" button in the lower right here. This will create and submit a zip file with this .ipynb doc and the .html or .pdf version you created. Congratulations! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from subprocess import call\n",
    "call(['python', '-m', 'nbconvert', 'Recommendations_with_IBM.ipynb'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
